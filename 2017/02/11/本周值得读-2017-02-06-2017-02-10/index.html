<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>本周值得读(2017.02.06-2017.02.10) | PaperWeekly</title>
  
  
  <meta name="description" content="All-but-the-Top: Simple and Effective Postprocessing for Word Representations【词表示】本文提出了一种对已有的词向量进行预处理的方法，用来对学习到的词向量降噪。基于词向量自身的几何结构 — 均值非零以及各项不同性，本文提出了">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="本周值得读(2017.02.06-2017.02.10)"/>
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-11T14:45:32.000Z"><a href="/2017/02/11/本周值得读-2017-02-06-2017-02-10/">2017-02-11</a></time>
      
      
  
    <h1 class="title">本周值得读(2017.02.06-2017.02.10)</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="All-but-the-Top-Simple-and-Effective-Postprocessing-for-Word-Representations"><a href="#All-but-the-Top-Simple-and-Effective-Postprocessing-for-Word-Representations" class="headerlink" title="All-but-the-Top: Simple and Effective Postprocessing for Word Representations"></a><a href="http://t.cn/RJUfnMQ" target="_blank" rel="external">All-but-the-Top: Simple and Effective Postprocessing for Word Representations</a></h2><p>【词表示】本文提出了一种对已有的词向量进行预处理的方法，用来对学习到的词向量降噪。基于词向量自身的几何结构 — 均值非零以及各项不同性，本文提出了一个反直观的处理方法：从所有的词向量中移除均值，以及移除部分导致各项不同性的方向。虽然这种处理方式忽略了词向量中的部分信息，但是它可以使多种通过不同方式训练出来的词向量加强词向量中包含的语义信息。经过预处理之后的词向量在一系列intrinsic衡量方式上（similarity, analogy, concept categorization）得到了一致性地提高。同时，我们通过了不同的应用上进行了测试，试验结果表明该预处理已经在诸多neural network中有所体现，进一步证实了对词向量进行预处理的重要性。本文工作来自UIUC NLP组的Jiaqi Mu，她也是Paperweekly的作者团队成员之一。</p>
<h2 id="Structured-Attention-Networks"><a href="#Structured-Attention-Networks" class="headerlink" title="Structured Attention Networks"></a><a href="http://t.cn/RJwoVJw" target="_blank" rel="external">Structured Attention Networks</a></h2><p>【注意力模型】 本文的工作是将Attention模型进行了structure的扩展，考虑了结构上的依赖，提出了所谓的Structured Attention Networks，测试了两种模型的效果，linear-chain CRF和基于图的parsing模型，比传统的attention效果要好。工作来自HarvardNLP组，代码已开源在<a href="https://github.com/harvardnlp/struct-attn" target="_blank" rel="external">https://github.com/harvardnlp/struct-attn</a></p>
<h2 id="Opinion-Recommendation-using-Neural-Memory-Model"><a href="#Opinion-Recommendation-using-Neural-Memory-Model" class="headerlink" title="Opinion Recommendation using Neural Memory Model"></a><a href="https://arxiv.org/abs/1702.01517v1" target="_blank" rel="external">Opinion Recommendation using Neural Memory Model</a></h2><p>【推荐系统】本文研究的问题是如何给用户推荐合适的产品评论。推荐的问题关键在于计算user和target的相似度，这里的target是指product review或者opinion。模型新意并无太多，所解决的问题比较有意思。 </p>
<h2 id="Comparative-Study-of-CNN-and-RNN-for-Natural-Language-Processing"><a href="#Comparative-Study-of-CNN-and-RNN-for-Natural-Language-Processing" class="headerlink" title="Comparative Study of CNN and RNN for Natural Language Processing"></a><a href="http://t.cn/RJ4wOZF" target="_blank" rel="external">Comparative Study of CNN and RNN for Natural Language Processing</a></h2><p>【CNN or RNN】 本文系统地对比了CNN和RNN在NLP各大任务上的表现，包括：情感分类、关系分类、文本蕴含、答案选择、问题关系匹配、PQA、词性标注等。RNN在大部分任务上都表现的更好，除了在关键词匹配和识别这类任务不如CNN。这篇文章有很多不错的结论，值得一读！ </p>
<h2 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a><a href="http://t.cn/RJ4bciJ" target="_blank" rel="external">A Knowledge-Grounded Neural Conversation Model</a></h2><p>【对话系统】【基于知识】 本文研究的问题是用完全数据驱动的模型生成带有知识的对话内容，在原有seq2seq模型的基础上增加了一个fact encoder来生成对话。解决方案很实用，也很有启发性，建议研读。本文工作来自Information Sciences Institute和微软研究院。 </p>
<h2 id="Fast-and-Accurate-Sequence-Labeling-with-Iterated-Dilated-Convolutions"><a href="#Fast-and-Accurate-Sequence-Labeling-with-Iterated-Dilated-Convolutions" class="headerlink" title="Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions"></a><a href="http://t.cn/RJ4qelM" target="_blank" rel="external">Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions</a></h2><p>【序列标注】 本文针对RNN对GPU并行计算性能利用不够的弱点，用了一种改进版的CNN模型Iterated Dilated Convolutions来代替Bi LSTM作为CRF的feature extractor，实验结果证明该方法更快更准。</p>
<h2 id="Semi-Supervised-QA-with-Generative-Domain-Adaptive-Nets"><a href="#Semi-Supervised-QA-with-Generative-Domain-Adaptive-Nets" class="headerlink" title="Semi-Supervised QA with Generative Domain-Adaptive Nets"></a><a href="http://t.cn/RJfadL4" target="_blank" rel="external">Semi-Supervised QA with Generative Domain-Adaptive Nets</a></h2><p>【问答系统】 本文研究的问题很有意思，用半监督方法来做问答系统，用无标签的文本来生成问题，通过联合人工给出的问题和生成的问题来一起训练问答模型，同时利用增强学习算法来尽量减小算法生成问题概率分布和人工给定问题概率分布之间的差异。 </p>
<h2 id="Trainable-Greedy-Decoding-for-Neural-Machine-Translation"><a href="#Trainable-Greedy-Decoding-for-Neural-Machine-Translation" class="headerlink" title="Trainable Greedy Decoding for Neural Machine Translation"></a><a href="http://t.cn/RJtEvwE" target="_blank" rel="external">Trainable Greedy Decoding for Neural Machine Translation</a></h2><p>【机器翻译】【解码算法】 本文研究的是机器翻译中一个不太被重视的方向，解码算法，创新点在于用增强学习算法对解码目标函数进行优化求解。</p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/nlp/">nlp</a>, <a href="/tags/PaperWeekly/">PaperWeekly</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">留言</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://rsarxiv.github.io/2017/02/11/本周值得读-2017-02-06-2017-02-10/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>110</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>128</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/创业/">创业</a><small>1</small></li>
  
    <li><a href="/tags/招聘/">招聘</a><small>1</small></li>
  
    <li><a href="/tags/推荐系统/">推荐系统</a><small>2</small></li>
  
    <li><a href="/tags/综述/">综述</a><small>1</small></li>
  
    <li><a href="/tags/自动文摘/">自动文摘</a><small>16</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>