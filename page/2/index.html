<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>第 2 页 | PaperWeekly</title>
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-16T03:14:40.000Z"><a href="/2016/09/16/PaperWeekly-第五期/">2016-09-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/16/PaperWeekly-第五期/">PaperWeekly 第五期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>Word2Vec从提出至今，已经成为了深度学习在自然语言处理中的基础部件，大大小小、形形色色的DL模型在表示词、短语、句子、段落等文本要素时都需要用word2vec来做word-level的embedding。Word2Vec的作者Tomas Mikolov是一位产出多篇高质量paper的学者，从RNNLM、Word2Vec再到最近流行的FastText都与他息息相关。一个人对同一个问题的研究可能会持续很多年，而每一年的研究成果都可能会给同行带来新的启发，本期的PaperWeekly将会分享其中三篇代表作，分别是：</p>
<p>1、Efficient Estimation of Word Representation in Vector Space, 2013<br>2、Distributed Representations of Sentences and Documents, 2014<br>3、Enriching Word Vectors with Subword Information, 2016</p>
<h1 id="Efficient-Estimation-of-Word-Representation-in-Vector-Space"><a href="#Efficient-Estimation-of-Word-Representation-in-Vector-Space" class="headerlink" title="Efficient Estimation of Word Representation in Vector Space"></a><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="external">Efficient Estimation of Word Representation in Vector Space</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>Google Inc., Mountain View, CA</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Word Representation, Word Embedding, Neural Network, Syntactic Similarity, and Semantic Similarity</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201309</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何在一个大型数据集上快速、准确地学习出词表示？</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>传统的NNLM模型包含四层，即输入层、映射层、隐含层和输出层，计算复杂度很大程度上依赖于映射层到隐含层之间的计算，而且需要指定上下文的长度。RNNLM模型被提出用来改进NNLM模型，去掉了映射层，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算。</p>
<p>本文提出的两个模型CBOW (Continuous Bag-of-Words Model)和Skip-gram (Continuous Skip-gram Model)结合了上面两个模型的特点，都是只有三层，即输入层、映射层和输出层。CBOW模型与NNLM模型类似，用上下文的词向量作为输入，映射层在所有的词间共享，输出层为一个分类器，目标是使当前词的概率最大。Skip-gram模型与CBOW的输入跟输出恰好相反，输入层为当前词向量，输出层是使得上下文的预测概率最大，如下图所示。训练采用SGD。<br><img src="media/14740499814306.jpg" alt=""></p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>Code: <a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="external">C++代码</a><br>Dataset: <a href="https://sites.google.com/site/semeval2012task2/" target="_blank" rel="external">SemEval-2012</a>,用来评估语义相关性。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>Bengio[1]在2003年就提出了language model的思路，同样是三层（输入层，隐含层和输出层）用上下文的词向量来预测中间词，但是计算复杂度较高，对于较大的数据集运行效率低；实验中也发现将上下文的n-gram出现的频率结合进去会提高性能，这个优点体现在CBOW和Skip-gram模型的输出层中，用hierarchical softmax（with huffman trees）来计算词概率。</p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的实验结果显示CBOW比NNLM在syntactic和semantic上的预测都要好，而Skip-gram在semantic上的性能要优于CBOW，但是其计算速度要低于CBOW。结果显示用较大的数据集和较少的epoch，可以取得较好的效果，并且在速度上有所提升。与LSI和LDA相比，word2vec利用了词的上下文，语义信息更加丰富。基于word2vec，出现了phrase2vec, sentence2vec和doc2vec，仿佛一下子进入了embedding的世界。NLP的这些思想也在用于recommendation等方面，并且与image结合，将image跟text之间进行转换。</p>
<h1 id="Distributed-Representations-of-Sentences-and-Documents"><a href="#Distributed-Representations-of-Sentences-and-Documents" class="headerlink" title="Distributed Representations of Sentences and Documents"></a><a href="http://120.52.73.76/arxiv.org/pdf/1405.4053v2.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Quoc V. Le, Tomas Mikolov</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>Google Inc, Mountain View, CA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>sentence representation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ICML 2014</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>基于word2vec的思路，如何表示sentence和document？</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p><img src="media/14740512129190.jpg" alt=""><br>利用one-hot的表示方法作为网络的输入，乘以词矩阵W，然后将得到的每个向量通过平均或者拼接的方法得到整个句子的表示，最后根据任务要求做一分类，而这过程中得到的W就是词向量矩阵，基本上还是word2vec的思路。</p>
<p>接下来是段落的向量表示方法：<br><img src="media/14740512491434.jpg" alt=""><br>依旧是相同的方法，只是在这里加上了一个段落矩阵，用以表示每个段落，当这些词输入第i个段落时，通过段落id就可以从这个矩阵中得到相对应的段落表示方法。需要说明的是，在相同的段落中，段落的表示是相同的。文中这样表示的动机就是段落矩阵D可以作为一个memory记住在词的context中遗失的东西，相当于增加了一个额外的信息。这样经过训练之后，我们的就得到了段落表示D，当然这个段落就可以是一段或者一篇文章。</p>
<p>最后一种就是没有词序的段落向量表示方法：<br><img src="media/14740512902836.jpg" alt=""><br>从图中就可以感觉到这个方法明显和skip-gram非常相似，这里只是把重点放在了段落的表示中，通过段落的表示，来预测相应的context 词的表示。最后我们依然可以得到段落矩阵D，这样就可以对段落进行向量化表示了。但是输入起码是句子级别的表示，而输出则是词的向量表示，因此个人比较怀疑这种方法的合理性。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>这篇文章是word2vec的方法提出一年后提出的方法，因此本文并没有使用目前非常流行的word2vec的训练方法来训练词向量，而是利用word2vec的思路，提出了一种更加简单的网络结构来训练任意长度的文本表示方法。这样一方面好训练，另一方面减少了参数，避免模型过拟合。优点就是在训练paragraph vector的时候加入了一个paragraph matrix，这样在训练过程中保留了一部分段落或者文档信息。这点在目前看来也是有一定优势的。但是目前深度学习发展迅速，可以处理非常大的计算量，同时word2vec以及其变种被应用得非常普遍，因此该文章提出的方法思路大于模型，思路我们可以借鉴，模型就不具有优势了。</p>
<h1 id="Enriching-Word-Vectors-with-Subword-Information"><a href="#Enriching-Word-Vectors-with-Subword-Information" class="headerlink" title="Enriching Word Vectors with Subword Information"></a><a href="http://120.52.73.80/arxiv.org/pdf/1607.04606v1.pdf" target="_blank" rel="external">Enriching Word Vectors with Subword Information</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>Facebook AI Research</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Word embedding, morphological, character n-gram</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv, 201607</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何解决word2vec方法中罕见词效果不佳的问题，以及如何提升词形态丰富语言的性能？</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>word2vec在词汇建模方面产生了巨大的贡献，然而其依赖于大量的文本数据进行学习，如果一个word出现次数较少那么学到的vector质量也不理想。针对这一问题作者提出使用subword信息来弥补这一问题，简单来说就是通过词缀的vector来表示词。比如unofficial是个低频词，其数据量不足以训练出高质量的vector，但是可以通过un+official这两个高频的词缀学习到不错的vector。</p>
<p>方法上，本文沿用了word2vec的skip-gram模型，主要区别体现在特征上。word2vec使用word作为最基本的单位，即通过中心词预测其上下文中的其他词汇。而subword model使用字母n-gram作为单位，本文n取值为3~6。这样每个词汇就可以表示成一串字母n-gram，一个词的embedding表示为其所有n-gram的和。这样我们训练也从用中心词的embedding预测目标词，转变成用中心词的n-gram embedding预测目标词。</p>
<p>实验分为三个部分，分别是（1）计算两个词之间的语义相似度，与人类标注的相似度进行相关性比较；（2）与word2vec一样的词类比实验；（3）与其他考虑morphology的方法比较。结果是本文方法在语言形态丰富的语言（土耳其语，法语等）及小数据集上表现优异，与预期一致。</p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>源码公布在Facebook的fastText项目中： <a href="https://github.com/facebookresearch/fastText" target="_blank" rel="external">https://github.com/facebookresearch/fastText</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>利用语言形态学来改进nlp的研究源远流长，本文提及的许多关于character-level和morphology的有趣工作值得参考。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>文章中提出的思路对于morphologically rich languages（例如土耳其语，词缀的使用极为普遍而有趣）来说十分有意义。词缀作为字母与单词之间的中层单位，本身具有一定的语义信息。通过充分利用这种中层语义来表征罕见词汇，直观上讲思路十分合理，也是应用了compositionality的思想。</p>
<p>利用形态学改进word embedding的工作十分丰富，但中文NLP似乎很难利用这一思路。其实个人感觉中文中也有类似于词缀的单位，比如偏旁部首等等，只不过不像使用字母系统的语言那样容易处理。期待今后也有闪光的工作出现在中文环境中。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从Word2Vec到FastText，从word representation到sentence classification，Tomas Mikolov的工作影响了很多人。虽然有个别模型和实验结果曾遭受质疑，但终究瑕不掩瑜。word2vec对NLP的研究起到了极大地推动作用，其实不仅仅是在NLP领域中，在其他很多领域中都可以看到word2vec的思想和作用，也正是从word2vec开始，这个世界变得都被vector化了，person2vec，sentence2vec，paragraph2vec，anything2vec，world2vec。</p>
<p>以上为本期Paperweekly的主要内容，感谢memray、zhkun、gcyydxf、jell四位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"><br>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-10T04:38:13.000Z"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">2016-09-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/10/cs-CL-weekly-2016-09-05-2016-09-09/">cs.CL weekly 2016.09.05-2016.09.09</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本周（2016.09.05-2016.09.09）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level"><a href="#Convolutional-Neural-Networks-for-Text-Categorization-Shallow-Word-level-vs-Deep-Character-level" class="headerlink" title="Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00718v1.pdf" target="_blank" rel="external">Convolutional Neural Networks for Text Categorization: Shallow Word-level vs. Deep Character-level</a></h1><p>张潼老师的文章，通过实验对比了shallow word-level CNN（本文工作）和deep char-level CNN模型在而文本分类任务上的表现，结论是本文工作又快又准。</p>
<p>（这篇文章对于选择char-level还是word-level做文本分类非常有指导意义）</p>
<h1 id="Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering"><a href="#Skipping-Word-A-Character-Sequential-Representation-based-Framework-for-Question-Answering" class="headerlink" title="Skipping Word: A Character-Sequential Representation based Framework for Question Answering"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00565v1.pdf" target="_blank" rel="external">Skipping Word: A Character-Sequential Representation based Framework for Question Answering</a></h1><p>本文用char-level CNN模型来做句子表示，然后进行question和answer之间的相关匹配学习，CIKM2016 short paper accepted。</p>
<h1 id="End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access"><a href="#End-to-End-Reinforcement-Learning-of-Dialogue-Agents-for-Information-Access" class="headerlink" title="End-to-End Reinforcement Learning of Dialogue Agents for Information Access"></a><a href="http://120.52.73.78/arxiv.org/pdf/1609.00777v1.pdf" target="_blank" rel="external">End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a></h1><p>本文是微软研究软邓力老师的文章，构建了一种从知识图谱中形成response的聊天机器人KB-InfoBot，并且提出了一种端到端的增强学习训练方案。</p>
<p>（本文对于构建一个端到端的KB + task-oriented chatbot非常有启发和指导意义）</p>
<h1 id="Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks"><a href="#Joint-Online-Spoken-Language-Understanding-and-Language-Modeling-with-Recurrent-Neural-Networks" class="headerlink" title="Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01462v1.pdf" target="_blank" rel="external">Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks</a></h1><p>本文提出一种模型，将intent detection、slot filling和language modeling融合在一起进行学习，用于解决对话系统中的SLU task。本文是SIGDIAL 2016 paper。</p>
<p>用到的数据集在Dropbox有一份<a href="http://t.cn/Rcbcpfl" target="_blank" rel="external">copy</a></p>
<h1 id="Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling"><a href="#Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling" class="headerlink" title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.01454v1.pdf" target="_blank" rel="external">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</a></h1><p>和上一篇paper是同一个作者，解决的是同一个问题。将RNN换成了attention-based RNN，被另外一个会议录取。(有点灌水的意思)</p>
<h1 id="Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations"><a href="#Ask-the-GRU-Multi-task-Learning-for-Deep-Text-Recommendations" class="headerlink" title="Ask the GRU: Multi-task Learning for Deep Text Recommendations"></a><a href="http://120.52.73.77/arxiv.org/pdf/1609.02116v1.pdf" target="_blank" rel="external">Ask the GRU: Multi-task Learning for Deep Text Recommendations</a></h1><p>本文提出了用端到端的解决方案来做paper的推荐任务，用GRU将文本序列（标题、摘要等）encode到一个latent vector中。并且通过多任务学习来完成内容推荐和条目预测两个task，取得了不错的效果。</p>
<p>以下内容为arXiv外的<b>优质内容</b>：</p>
<h1 id="Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems"><a href="#Discriminative-Methods-for-Statistical-Spoken-Dialogue-Systems" class="headerlink" title="Discriminative Methods for Statistical Spoken Dialogue Systems"></a><a href="http://www.matthen.com/research/papers/Discriminative_Methods_for_Statistical_Spoken_Dialogue_Systems_Matthew_Henderson_PhD_Thesis.pdf" target="_blank" rel="external">Discriminative Methods for Statistical Spoken Dialogue Systems</a></h1><p>剑桥大学Spoken Dialogue System组毕业的Matthew Henderson博士，师从于Steve Young教授，研究领域是对话系统中的Dialogue State Tracking，主要特色是用transfer learning来解决discriminative model的扩展性和通用性。</p>
<p>如果你对chatbot感兴趣，强烈建议好好研读一下这篇博士论文。</p>
<h1 id="CONNECTING-IMAGES-AND-NATURAL-LANGUAGE"><a href="#CONNECTING-IMAGES-AND-NATURAL-LANGUAGE" class="headerlink" title="CONNECTING IMAGES AND NATURAL LANGUAGE"></a><a href="http://cs.stanford.edu/people/karpathy/main.pdf" target="_blank" rel="external">CONNECTING IMAGES AND NATURAL LANGUAGE</a></h1><p>斯坦福大学Feifei Li的博士生Andrej Karpathy的PhD thesis，Karpathy维护着几个非常流行的开源代码库，并且有着一个影响力非常大的博客。名师出高徒，这篇博士博士论文值得一看！</p>
<p>最近，他更新了一篇博客，谈论了一些自己对读博的思考和建议。 <a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank" rel="external">A Survival Guide to a PhD</a></p>
<h1 id="Mendeley-Docs"><a href="#Mendeley-Docs" class="headerlink" title="Mendeley Docs"></a><a href="https://pan.baidu.com/share/link?shareid=317480&amp;uk=1594817379" target="_blank" rel="external">Mendeley Docs</a></h1><p>paper越看越多，一个优秀的paper管理工具就变得非常必要了，Mendeley是其中最优秀的代表之一。</p>
<p>Easily organize your papers, read &amp; annotate your PDFs, collaborate in private or open groups, and securely access your research from everywhere.</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-09T04:48:42.000Z"><a href="/2016/09/09/PaperWeekly第四期/">2016-09-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/09/PaperWeekly第四期/">PaperWeekly第四期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>2013年以来Deep mind团队相继在NIPS和Natures上发表了用深度增强（强化）学习玩Atari游戏，并取得良好的效果，随后Alpha go与李世乭的一战更使得深度增强学习家喻户晓。在游戏上取得了不错的成果后，深度增强学习也逐渐被引入NLP领域。本期介绍目前NLP领域较为热点的研究方向，基于强化学习的文本生成技术（NLG），共选择了三篇文章，分别为：</p>
<p>(1)《Generating Text with Deep Reinforcement Learning》<br>应用Deep Q-Network作为生成模型用于改善seq2seq模型</p>
<p>(2)    《Deep Reinforcement Learning for Dialogue Generation》<br>应用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<p>(3)《Hierarchical Reinforcement Learning for Adaptive Text Generation_lshowway》<br>以任务为导向的户内导航对话系统用分层强化学习进行文本生成</p>
<p>以下为三篇文章的主要信息：</p>
<h1 id="Generating-Text-with-Deep-Reinforcement-Learning"><a href="#Generating-Text-with-Deep-Reinforcement-Learning" class="headerlink" title="Generating Text with Deep Reinforcement Learning"></a><a href="http://120.52.73.76/arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a></h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>Hongyu Guo</p>
<h2 id="单位"><a href="#单位" class="headerlink" title="单位"></a>单位</h2><p>National Research Council Canada</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>NIPS2015 Workshop (2015.10.30)</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>本文提出将Deep Q-Network作为生成模型用于改善seq2seq模型，将decoding修改为迭代式的过程，实验表明本模型具有更好的泛化性。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>对seq2seq模型改进的论文层出不穷，本文率先引入深度强化学习的思想，将DQN用于文本生成。对DQN还不了解的同学可以先阅读DeepMind的论文Playing Atari with Deep Reinforcement Learning。本文的模型如下：</p>
<p><img src="media/14734508069657.jpg" alt=""></p>
<p>如同一般的神经网络，我们也可以把DQN当做一个黑盒来使用。只需要准备好DQN需要的四个元素s(i),a(i),r(i),s(i+1)，分别代表i时刻下state,action,reword和i+1时刻的state。</p>
<p>对照上图我们把算法解剖分为4个步骤：</p>
<p>Step 1: 先是传统的seq2seq模型。通过LSTM先把输入序列encode为一个定长向量EnSen(i)，然后作为decode阶段的初始状态依次生成新的序列DeSen(i)（decoding search使用beam search算法来 expand next words）。经过第一步我们得到初始state：(EnSen(i), DeSen(i))和action集合：每个位置的hypotheses。</p>
<p>Step 2: 接下来从hypotheses（actions）中选择一个可以获得最大reward的单词（action）作为该位置新生成的词，用新单词来代替之前的旧词，于是生成新的state：(EnSen(i), DeSen(i+1))。</p>
<p>Step 3: 接着就是标准的DQN的部分，计算Loss函数并对其应用梯度下降。</p>
<p>Step 4: 回到Step 2，对得到的state继续迭代，每一次迭代都只生成一个新词来代替旧词，直到迭代次数达到设好的值（作者将次数定为句子长度的两倍，同学们可以思考一下理由）。</p>
<p>总结DQN所需的四个元素对应如下：<br>(1) i时刻下的state：(EnSen(i), DeSen(i))；<br>(2) i时刻下的action：beam search得到的每个位置的hypotheses；<br>(3) i时刻下的reword：target sentence和DeSen(i+1)的相似度（BLEU score）；<br>(4) i+1时刻下的state：(EnSen(i), DeSen(i+1))；</p>
<p>为了更好的提取句子的特征，作者在decode阶段使用了双向LSTM。同时还在reinforcement learning中加入attention机制，可以达到先decode比较简单的部分再处理困难部分的效果。最后在生成相似句子的实验中得到了比只用LSTM decoder效果更好的结论：</p>
<p><img src="media/14734509263452.jpg" alt=""></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734510298695.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>本文的思想其实非常符合写作的一种情况，就像贾岛推敲的故事，回想小时候刚学习写句子时，也不能一次写好，总会不断对一些词语进行修改。Google DeepMind的文章《DRAW：A Recurrent Neural Network For Image》也和本文异曲同工：画画也不是一次画好，也要不断的完善。不同之处在于本文率先引入DQN做文本生成。在机器学习各个分支下，强化学习和人类与环境的交互方式非常相似，在许多领域开始初露头角，期待看到更多将强化学习结合语言模型的应用。</p>
<h1 id="Deep-Reinforcement-Learning-for-Dialogue-Generation"><a href="#Deep-Reinforcement-Learning-for-Dialogue-Generation" class="headerlink" title="Deep Reinforcement Learning for Dialogue Generation"></a><a href="http://120.52.73.76/arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></h1><h2 id="作者-1"><a href="#作者-1" class="headerlink" title="作者"></a>作者</h2><p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky</p>
<h2 id="单位-1"><a href="#单位-1" class="headerlink" title="单位"></a>单位</h2><p>(1) Stanford University, Stanford, CA, USA<br>(2) Microsoft Research, Redmond, WA, USA<br>(3) Ohio State University, OH, USA</p>
<h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Reinforcement Learning、Seq2Seq、Text Generation</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv.org(2016.06.25)</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>本文提出利用强化学习进行开放领域的文本生成任务，并对比了有监督的seq2seq加attention模型和基于最大互信息的模型</p>
<h2 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h2><p>强化学习中的reward</p>
<p><img src="media/14734512073402.jpg" alt=""></p>
<p>易被响应（Ease of answering），不容易出现对话僵局，其中 S 是无意义回答合集，s是某一时刻的响应</p>
<p><img src="media/14734512278456.jpg" alt=""></p>
<p>信息流，若开辟新的话题，有利于对话的继续发展，隐层表示 hpi 和 hpi+1 的夹角余弦</p>
<p><img src="media/14734512443645.jpg" alt=""></p>
<p>语义连贯性，减少与对话无关问题的影响，其中，pseq2seq(a|pi,qi) 是由上一轮状态得到响应的概率，后一项是由当前产生响应通过网络生成之前的 qi 的概率。</p>
<p><img src="media/14734512828474.jpg" alt=""></p>
<p>最终的reward是对三者加权求和，系数分别为：0.25、0.25、0.5.</p>
<p>对比试验：<br>(1) 对话初始状态为一个SEQ2SEQ加attention的模型作为强化学习的初始状态。</p>
<p>(2) 在前面的基础上将最大互信息加入其中作为reward，对于一个给定的输入[pi,qi]，可以根据模型生成一个候选回答集合A。对于A中的每一个回答a,从预训练模型中得到的概率分布上可以计算出互信息的值 m(a,[pi,qi])。</p>
<p>(3) 将互信息训练过的模型作为初始模型，用策略梯度更新参数并加入课程学习策略，最终最多限定五轮对话。</p>
<p><img src="media/14734513584870.jpg" alt=""></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14734513827800.jpg" alt=""></p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文作者提出了一个强化学习框架，模拟两个agent让其自动对话训练神经网络SEQ2SEQ模型，将Encoder-Decoder模型和强化学习整合，从而能保证使对话轮数增加。文中使用的模型非常简洁，reward函数定义清晰，评价指标也较为科学，可以生成信息更为丰富、易于响应的对话系统。</p>
<h1 id="Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation"><a href="#Hierarchical-Reinforcement-Learning-for-Adaptive-Text-Generation" class="headerlink" title="Hierarchical Reinforcement Learning for Adaptive Text Generation"></a><a href="http://www.aclweb.org/anthology/W10-4204" target="_blank" rel="external">Hierarchical Reinforcement Learning for Adaptive Text Generation</a></h1><h2 id="作者-2"><a href="#作者-2" class="headerlink" title="作者"></a>作者</h2><p>Nina Dethlefs, Heriberto Cuay´ahuitl</p>
<h2 id="单位-2"><a href="#单位-2" class="headerlink" title="单位"></a>单位</h2><p>University of Bremen, Germany</p>
<h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>NLG, 分层强化学习, 文本生成, wayfinding</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>国际自然语言生成会议INLG(2010)</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>在wayfinding（户内导航对话系统）领域利用分层强化学习进行文本生成。该方法的目标是对wayfinding的NLG任务整合进行优化，并在模拟系统中验证该方法的有效性。</p>
<h2 id="模型-2"><a href="#模型-2" class="headerlink" title="模型"></a>模型</h2><p>本文任务在wayfinding中的NLG任务有多个，且各个任务之间并非独立。从而提出应该根据用户类型，导航距离， 环境条件等作出不同的导航策略，介绍了分层强化学习。</p>
<p>文章将户内导航对话系统的文本生成问题分为四块：</p>
<p>(1) Content Selection：给不熟悉环境的用户的导航要比熟悉环境的用户的导航更细致<br>(2) Text Structure：根据导航距离以及用户熟悉环境程度给予不同类型的导航，如大白话的，以fisrt， second…表达或者示意性的。<br>(3) Referring Expression Generation：一间房间可以叫“A203”，也可以叫“办公室”或者“小白楼”<br>(4) Surface Realisation：往前走可以用“go”也可以用“walk”等。</p>
<p>强化学习示意图如下，分层强化学习的思想与强化学习类似，但在强化学习的基础上加上层次，不同层次的模型处理不同层次的问题。<br><img src="media/14734516131737.jpg" alt=""></p>
<p>agent根据当前状态，执行动作a与环境交互，之后环境产生一个新的状态s并返回给agent一个奖赏r（可正可负），强化学习的目标函数便是使agent获得奖赏r最大。</p>
<p>分层增强学习包含L个层，每层N个模型，如Figure 1是有15个agents的hierarchy，其中不同的agent负责不同的层次。</p>
<p><img src="media/14734516802648.jpg" alt=""></p>
<p>每个agent定义为半马尔科夫决策过程，可以表示成一个四元组</p>
<p><img src="media/14734517382304.jpg" alt=""></p>
<p>分别为状态集，动作集，转换函数，奖励函数。</p>
<p>奖励函数表示agent在时间t状态s是执行动作a转换到新的状态s’所获得的奖励。半马尔科夫的目标是找到policy π*，</p>
<p><img src="media/14734524023811.jpg" alt=""></p>
<p>使得在从当前状态转换到新的状态获得的累计奖励最多。</p>
<p>本文使用两种奖励函数，一种着重在 interaction length， 另一种着重在alignment and variation之间的平衡（具体公式可见论文）。</p>
<p>本文是在模拟环境中进行试验，其中模拟环境包括user type（熟悉环境，不熟悉环境）， information need（高，低），length of the current route（短，中长，长），next action to perform（转，直走），current focus of attention（继续走，关注标识）。baseline为为部分agent随机选择action，即不考虑用户类型，导航距离等因素。经与baseline比较，效果较好。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>词性标注工具：<a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">http://nlp.stanford.edu/software/tagger.shtml</a></p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>将来的工作：将分层强化学习应用于其他NLG任务<br>不足之处：实验是在模拟环境下进行的，未来应该在真实环境进行评估。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这三篇文章皆是强化学习在NLP领域的应用，第一篇主要侧重点在于应用DQN进行文本生成，并用BLUE指标进行评价，对比传统的LSTM-decoder和加入DQN之后的结果；第二篇文章侧重点在于虚拟两个Agent，在传统Seq2Seq的基础上加入强化学习从而使得聊天能够持续下去；第三篇文章侧重点在于任务驱动的对话系统应用分层强化学习，针对不同情况进行分层处理。</p>
<p>以上为本期Paperweekly的主要内容，感谢lshowway、美好时光海苔、Tonya三位同学的整理。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-2-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -2-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-03T02:02:40.000Z"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">2016-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/03/cs-CL-weekly-2016-08-29-2016-09-02/">cs.CL weekly 2016.08.29-2016.09.02</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本周（2016.08.29-2016.09.02）质量较高的arXiv cs.CL的paper如下：<br>（点击标题可看原文）</p>
<h1 id="Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond"><a href="#Abstractive-Text-Summarization-Using-Sequence-to-Sequence-RNNs-and-Beyond" class="headerlink" title="Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond"></a><a href="http://120.52.73.75/arxiv.org/pdf/1602.06023v5.pdf" target="_blank" rel="external">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a></h1><p>一篇老文的update，seq2seq+attention的机制来解决abstractive text summarization，针对文本摘要的关键问题在基础模型中增加了对关键词、词句层次性和低频词的处理。</p>
<h1 id="Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer"><a href="#Machine-Comprehension-Using-Match-LSTM-and-Answer-Pointer" class="headerlink" title="Machine Comprehension Using Match-LSTM and Answer Pointer"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.07905v1.pdf" target="_blank" rel="external">Machine Comprehension Using Match-LSTM and Answer Pointer</a></h1><p>本文基于Match-LSTM和Answer Pointer两个模型在Stanford Question Answering Dataset (SQuAD)上得到了state-of-the-art的结果。 </p>
<h1 id="Measuring-Machine-Intelligence-Through-Visual-Question-Answering"><a href="#Measuring-Machine-Intelligence-Through-Visual-Question-Answering" class="headerlink" title="Measuring Machine Intelligence Through Visual Question Answering"></a><a href="http://120.52.73.75/arxiv.org/pdf/1608.08716v1.pdf" target="_blank" rel="external">Measuring Machine Intelligence Through Visual Question Answering</a></h1><p>本文指出了image caption作为评测AI效果的任务存在的缺陷，同时提出用visual QA作为评测任务更加有效，并且给出了一个大型Visual QA的数据集。数据集地址：www.visualqa.org.</p>
<h1 id="How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions"><a href="#How-Much-is-131-Million-Dollars-Putting-Numbers-in-Perspective-with-Compositional-Descriptions" class="headerlink" title="How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions"></a><a href="http://120.52.73.79/arxiv.org/pdf/1609.00070v1.pdf" target="_blank" rel="external">How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions</a></h1><p>文章提出了一个好玩的任务，以一个统计数字作为上下文来生成一段简短的描述，描述的内容是一种带有这个数字的观点。整个过程分为两步：公式的构建和观点的生成。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/qrcode_for_gh_5138cebd4585_430%20-1-.jpg" alt="qrcode_for_gh_5138cebd4585_430 -1-"></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ），每天会发布arXiv cs.CL高质量paper和简评。<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-09-01T06:58:14.000Z"><a href="/2016/09/01/PaperWeekly-第三期/">2016-09-01</a></time>
      
      
  
    <h1 class="title"><a href="/2016/09/01/PaperWeekly-第三期/">PaperWeekly 第三期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>历经半个月时间终于发布了新一期PaperWeekly，大家久等了。在这个半个月里，PaperWeekly发生了一些明显的变化。维护和运营从我一个人变成了一个十人左右的团队来一起做，小伙伴们来自全球各地，颠倒着黑夜和白天进行沟通。团队中的每个人都有一颗热爱知识和分享知识的心，都认为分享是一种美德，是一种付出，更是一种回报。可能我们不完美，但我们相信我们正在追求完美的路上坚定地走着。</p>
<p>有了更多的同学加入，PaperWeekly会更加多元化，不再受限于我个人感兴趣的方向和阅读、写作习惯。PaperWeekly会坚持每周发布一期文章，每一期的文章尽量围绕同一个topic展开，在微信公众号、官方微博和知乎专栏会同步更新，除了这一篇文章，我们还会坚持在微博上提供一个新的服务，cs.CL daily，帮助大家过滤掉arXiv cs.CL上比较水的paper，留下质量高的paper，并且用简评的方式分享在微博上，每周末会更新一篇cs.CL weekly出来，将一周值得读的cs.CL paper汇总发布。</p>
<p>PaperWeekly组织了一个高质量的NLP讨论群，只要有你相关的问题，群里的高手会第一时间站出来解答或者讨论你的问题，有的时候会给出一些开源code和相关的paper，提问者、讨论者和潜水者都会有很大的收获。分享paper导读的意义在于讨论，大家一起来讨论，才能更加充分地吸收paper里的营养，这也是我为什么组织一个讨论群的原因。</p>
<p>寒暄的话就说到这里，本期分享的topic是ACL 2016，一共10篇文章，涉及的内容包括：Logic Form、NMT、Summarization、QA、Chatbot等。</p>
<h1 id="Sentence-Rewriting-for-Semantic-Parsing"><a href="#Sentence-Rewriting-for-Semantic-Parsing" class="headerlink" title="Sentence Rewriting for Semantic Parsing"></a><a href="http://aclweb.org/anthology/P/P16/P16-1073.pdf" target="_blank" rel="external">Sentence Rewriting for Semantic Parsing</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>Semantic Parsing、Sentence Rewriting</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>语义分析的表现形式是将自然语言（natural language）转化成逻辑形式（logic form）。因语言表达多样性的问题导致两者间存在mismatch problem。</p>
<h2 id="文章思路"><a href="#文章思路" class="headerlink" title="文章思路"></a>文章思路</h2><p>先给出一个语义分析的例子：</p>
<p><img src="media/14727920453411.jpg" alt=""></p>
<p>给句子换个表达（How many people live in Berlin?），对应的逻辑形式就变得复杂很多(count(λx.person(x)∧live(x,Berlin)))。</p>
<p>作者认为，原句子和逻辑形式之间存在的结构不匹配导致了语义分析的困难，而结构不匹配的核心是词汇的不匹配。作者率先提出先把句子重写再转成目标逻辑形式的语义分析方案，如下图：</p>
<p><img src="media/14727921250895.jpg" alt=""></p>
<p>针对词汇不匹配问题的两种情况分别给出基于字典和基于模板两种方法。</p>
<p>1）问题一：1-N mismatch<br>是指一个单词（word）对应一个复合的逻辑形式（compound formula）。</p>
<p>例如daughter对应 child ∩ female。但在开放域的知识体系下，制定这些规则十分困难。于是作者提出将句子中的常用名词替换为字典（Wiktionary）中的解释，比如先把刚才的daughter转换为female child，接着再转换为逻辑形式child ∩ female就十分自然了。</p>
<p>2）问题二：N-1 mismatch<br>是指将复杂的自然语言表达对应为单个逻辑表达。</p>
<p>例如将How many people live in Berlin?转化为λx.population(Berlin,x)的分析过程中，How many people live in被对应为逻辑式常量population。如同问题一，这样的规则实在过多，作者的思路是将复杂的表达式转化为简单的形式。</p>
<p>沿用之前的句子来了解算法流程。</p>
<p><img src="media/14727921375652.jpg" alt=""></p>
<p>Step 1 替换实体生成候选template，例如得到模板how many people live in #y。<br>Step 2 检索template pairs来替换模板，例如找到(a：how many people live in #y, b：what is the population of #y)的模板对，于是将b作为新模板，<br>Step 3 把实体替换回去得到容易生成逻辑形式的what is the population of Berlin。 </p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727925154995.jpg" alt=""></p>
<h2 id="简评"><a href="#简评" class="headerlink" title="简评"></a>简评</h2><p>如今深度学习在自然语言处理领域大红大紫，也给语义分析的方法带来更多的思考。比如ACL2016另外一篇文章Language to Logical Form with Neural Attention，就把语义分析转换为seq2seq问题，进而使用深度学习的方法来解决。如果我们把词向量这样的表示形式比喻为粗糙的连结主义，那么逻辑表达就好比精细的形式主义。两者各有优势，希望以后会有更多结合两种思想的工作出现。</p>
<h1 id="Language-to-Logical-Form-with-Neural-Attention"><a href="#Language-to-Logical-Form-with-Neural-Attention" class="headerlink" title="Language to Logical Form with Neural Attention"></a><a href="http://aclweb.org/anthology/P/P16/P16-1004.pdf" target="_blank" rel="external">Language to Logical Form with Neural Attention</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>Logical Forms, Sequence to Sequence</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>如何把自然语言转化成Structured Logical Forms？</p>
<h2 id="文章思路-1"><a href="#文章思路-1" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727925632141.jpg" alt=""></p>
<p>模型总体是一个encoder-decoder架构，input sequence首先通过LSTM encoder转化成一个vector，然后这个vector通过LSTM decoder被转化成Logical Forms。在decode过程中用到了一个attention layer去获取context信息。</p>
<p><img src="media/14727705332596.jpg" alt=""></p>
<p>和encoder-decoder模型类似，作者提出了一种hierarchical decoder。与普通的decoder不同，首先，decode之后的sequence中存在一个特殊字符<n>代表nonterminal。在nonterminal的基础上，decoder可以继续进行下一个layer的decoding。每一次decoding的输入不仅包含current hidden state,还包含这一个parent nonterminal的hidden state。</n></p>
<p><img src="media/14727925854664.jpg" alt=""></p>
<p>作者还使用了一种attention机制，在构建current hidden state的时候将hidden state与所有encoder中的hidden state进行对比，给每一个encoder hidden state一个weight。</p>
<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="external">https://github.com/donglixp/lang2logic</a><br>Jobs和GEO数据集：<a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf" target="_blank" rel="external">http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf</a></p>
<h2 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前的大部分工作都采用一些parsing models，string-to-tree transformation rules，文中没有提到之前有人采用seq2seq/deep learning的方法。本文中使用的seq2seq方法主要来自Kalchbrenner, Blunsom, Cho, Sutskever 在machine translation中提出的模型。</p>
<h2 id="简评-1"><a href="#简评-1" class="headerlink" title="简评"></a>简评</h2><p>本文解决的是一个非常有趣的问题，将自然语言转换成结构化的Logical Forms。试想如果此模型能够很好的解决这个问题，那么将来的各种query language甚至programming languages都可以由自然语言转换而成。</p>
<h1 id="Neural-Summarization-by-Extracting-Sentences-and-Words"><a href="#Neural-Summarization-by-Extracting-Sentences-and-Words" class="headerlink" title="Neural Summarization by Extracting Sentences and Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1046.pdf" target="_blank" rel="external">Neural Summarization by Extracting Sentences and Words</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>Summarization、Hierarchical Document Encoder、Attention-based Extractor</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>如何使用数据驱动的方法来做提取式摘要？</p>
<h2 id="文章思路-2"><a href="#文章思路-2" class="headerlink" title="文章思路"></a>文章思路</h2><p>本文针对的任务分为sentence和word两个level的summarization。sentence level是一个序列标签问题，每个句子有0或1两个标签，为1表示需要提取该句作为总结。而word level则是一个限定词典规模下的生成问题，词典规模限定为原文档中所有出现的词。</p>
<p>使用的模型也比较有特点，首先在encoder端将document分为word和sentence来encode，word使用CNN encode得到句子表示，接着将句子表示输入RNN得到encoder端隐藏层状态。从word到sentence的encode体现了本文的hierarchical document encoder的概念。</p>
<p><img src="media/14727709292807.jpg" alt=""></p>
<p>在decoder端根据任务的不同使用不同网络结构，sentence任务就是一个简单的有监督下二分类问题，使用RNN网络结构更新decoder端隐藏层状态， decoder端隐藏层状态串联encoder端隐藏层状态后接入一个MLP层再接sigmoid激活函数得到句子是否被extract的概率。</p>
<p>word任务则是使用传统的attention-based的方法来计算每个词的概率。但要注意本文的计算的attention不是word-level attention，而是encoder端sentence-level attention。</p>
<p><img src="media/14727709957739.jpg" alt=""></p>
<h2 id="资源-1"><a href="#资源-1" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://homepages.inf.ed.ac.uk/s1537177/resources.html" target="_blank" rel="external">http://homepages.inf.ed.ac.uk/s1537177/resources.html</a></p>
<h2 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h2><p>之前大多数extractive methods都基于human-engineered特征来给句子建模，通常会对每个句子计算一个分数，然后再使用诸如binary classifiers，hidden Markov模型，graph-based算法或integer linear programming等方法来选择句子构成总结。</p>
<h2 id="简评-2"><a href="#简评-2" class="headerlink" title="简评"></a>简评</h2><p>之前基于data-driven的seq2seq模型在abstractive summarization任务上大放异彩，本文提出了使用类似的模型来解决extractive summarization任务。不过针对的依旧是single-document summarization任务，未来需要将工作拓展至multi-document summarization任务上。</p>
<h1 id="Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings"><a href="#Sequence-to-Sequence-Generation-for-Spoken-Dialogue-via-Deep-Syntax-Trees-and-Strings" class="headerlink" title="Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings"></a><a href="http://aclweb.org/anthology/P/P16/P16-2008.pdf" target="_blank" rel="external">Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings</a></h1><h2 id="关键词-3"><a href="#关键词-3" class="headerlink" title="关键词"></a>关键词</h2><p>Sequence to Sequence、Natural Language Generation、Chatbot</p>
<h2 id="来源-3"><a href="#来源-3" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-3"><a href="#问题-3" class="headerlink" title="问题"></a>问题</h2><p>如何通过小规模、未对齐语料生成对话语句？</p>
<h2 id="文章思路-3"><a href="#文章思路-3" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者介绍了两个模型:</p>
<p>1、通过DA(diglogue acts)生成句法依赖树，再利用external surface realizer，生成语句。（如下图）</p>
<p><img src="media/14727713613292.jpg" alt=""></p>
<p>2、将两部分结合起来，直接生成语句。步骤如下：</p>
<p>Step 1 将DA(dialogue acts)中的每个slot(表示特定信息)表示成三元组(DA type,slot,value)并结合(下图左)</p>
<p><img src="media/14727714252636.jpg" alt=""></p>
<p>Step 2 基于seq2seq generation technique生出语句或句法依赖树。<br>Step 3 结合beam search和n-best列表重排序（list reranker）以减少输出中的不相关信息。</p>
<h2 id="资源-2"><a href="#资源-2" class="headerlink" title="资源"></a>资源</h2><p>代码: <a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">https://github.com/UFAL-DSG/tgen</a></p>
<h2 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h2><p><img src="media/14727926849132.jpg" alt=""></p>
<h2 id="简评-3"><a href="#简评-3" class="headerlink" title="简评"></a>简评</h2><p>该方法基于广泛使用的seq2seq模型，可以用未对齐的MR对(pair of  meaning representation)和句子进行训练，且只要小规模的语料就可以有很好的效果。生成器可以从数据中学会slot的对齐和值，生成流利的domain style)语句，虽然语义错误还是很频繁，但还是取得了不错的成绩。</p>
<h1 id="On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems"><a href="#On-line-Active-Reward-Learning-for-Policy-Optimisation-in-Spoken-Dialogue-Systems" class="headerlink" title="On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems"></a><a href="http://aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="external">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a></h1><h2 id="关键词-4"><a href="#关键词-4" class="headerlink" title="关键词"></a>关键词</h2><p>Dialogue System、Reinforcement Learning、Online Active Reward Learning</p>
<h2 id="来源-4"><a href="#来源-4" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-4"><a href="#问题-4" class="headerlink" title="问题"></a>问题</h2><p>文章提出一种在线学习框架，通过高斯过程分类模型进行主动学习，训练对话策略和奖励模型，减少数据标注的花费和用户反馈中的噪声。</p>
<h2 id="文章思路-4"><a href="#文章思路-4" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727785168705.jpg" alt=""></p>
<p>框架分为三部分：对话策略、对话嵌入函数、用户反馈主动奖励模型。</p>
<p>无监督学习输入为双向LSTM，通过Encoder-Decoder模型表征用户意图，将对话的成功与否看做高斯过程的一个二元分类问题，当模型对当前结果不能评判时，主动学习，通过reward模型决定是否询问用户反馈，当模型不确定时，生成增强信号来训练策略。</p>
<h2 id="资源-3"><a href="#资源-3" class="headerlink" title="资源"></a>资源</h2><p>数据集：<a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="external">http://camdial.org/~mh521/dstc/</a></p>
<h2 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、之前的工作有用任务完成度和对话持续情况做Reward，但任务完成度不好衡量<br>2、用协同过滤表征用户偏好<br>3、用逆强化学习从行为中推出reward</p>
<h2 id="简评-4"><a href="#简评-4" class="headerlink" title="简评"></a>简评</h2><p>用lSTM Encoder-Decoder表征用户意图，无需大规模标注语料和构建用户模拟器来进行训练，在较小的训练语料中取得了不错的效果，率先实现了在真实场景中的应用。但Reward函数只关心对话任务是否成功，模型过于简单。</p>
<h1 id="Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a><a href="http://aclweb.org/anthology/P/P16/P16-1100.pdf" target="_blank" rel="external">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h1><h2 id="关键词-5"><a href="#关键词-5" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-5"><a href="#来源-5" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-5"><a href="#问题-5" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-5"><a href="#文章思路-5" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章提出了一个混合（层次）模型。该模型由两部分组成，分别为：<br>a. 传统的基于词（word level）的seq2seq模型；<br>b. 基于字母级别（character level）的LSTM模型，由一个将字母encode成单词的encoder和一个根据状态生成低频词的decoder组成。其中a部分负责进行翻译，b部分负责处理低频词（unk）。</p>
<p><img src="media/14727723863213.jpg" alt=""></p>
<p>具体地，a部分的encoder遇到unk时，会使用character level对该低频词进行encode，并使用encode出的representation作为输入。而decoder遇到unk时，会利用attention机制将当前上下文和LSTM状态初始化character level decoder。此处的初始化采用的是文章提出的separate path模式，即利用一个MLP作为character level decoder的初始化网络。值得注意的是此处word level decoder仍会选择用<unk>作为下一步的输入。</unk></p>
<h2 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h2><p>Unk问题属于NMT中长期存在问题。目前多是采取后处理的方法。今年ACL有两篇paper，分别是李航老师实验室的copynet和Bengio实验室的pointing the unknown words，但对机器翻译任务参考意义有限。<br>另外一种思路则是加大词典，比较知名工作有On Using Very Large Target Vocabulary for Neural Machine Translation。此外该工作还借鉴了Jiwei Li的hierarchical auto encoder。</p>
<h2 id="简评-5"><a href="#简评-5" class="headerlink" title="简评"></a>简评</h2><p>文章思路新颖且简单明了。因为NMT中存在unk的问题，作者直接利用character level RNN来生成一个词替代unk。该工作对拼音文字有一定意义，对中日韩文的参考意义有限。</p>
<h1 id="Pointing-the-Unknown-Words"><a href="#Pointing-the-Unknown-Words" class="headerlink" title="Pointing the Unknown Words"></a><a href="http://aclweb.org/anthology/P/P16/P16-1014.pdf" target="_blank" rel="external">Pointing the Unknown Words</a></h1><h2 id="关键词-6"><a href="#关键词-6" class="headerlink" title="关键词"></a>关键词</h2><p>Neural Machine Translation、UNK Words</p>
<h2 id="来源-6"><a href="#来源-6" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-6"><a href="#问题-6" class="headerlink" title="问题"></a>问题</h2><p>如何解决机器翻译中的未登录词问题？</p>
<h2 id="文章思路-6"><a href="#文章思路-6" class="headerlink" title="文章思路"></a>文章思路</h2><p>作者在有注意力的机器翻译模型上增加了一个开关来判断和是否复制原文。</p>
<p>1、Attention-based机器翻译模型<br><img src="media/14727726836085.jpg" alt=""><br>经典的attention model这里不再赘述。</p>
<p>2、Pointer Softmax模型<br><img src="media/14727727829495.jpg" alt=""></p>
<p>两个问题有待解决解决：<br>a. 是否进行copy？<br>b. copy的位置在哪？</p>
<p>先说第二个问题，作者先引入shortlist softmax和location softmax。前者来确定要从shortlist中选取哪一个单词作为输出，后者确定在哪个位置要进行copy操作。</p>
<p>再看第一个问题，作者引入一个二值变量（可以想象为一个开关）来选择使用shortlist softmax还是location softmax。当值为1的时候不进行copy操作，使用shortlist softmax来从shortlist中选一个词作为输出。当值为0的时候进行copy操作，使用location softmax，将原文的词直接copy到指定位置。</p>
<h2 id="资源-4"><a href="#资源-4" class="headerlink" title="资源"></a>资源</h2><p>代码：<a href="https://github.com/caglar/pointer_softmax" target="_blank" rel="external">https://github.com/caglar/pointer_softmax</a></p>
<h2 id="简评-6"><a href="#简评-6" class="headerlink" title="简评"></a>简评</h2><p>本文的想法很有趣，直接从原文照抄罕见词和未知词很符合日常生活中人类的处理方法。从文中实验结果来看，该模型有一定的提升效果。注意力模型的提出与对人类行为的观察密不可分，而copy机制也是从生活中提炼出来的一种有效模型，我们可以借鉴的是从人类解决问题的具体方式中进行总结和归纳不失为一种有效的解决方案。</p>
<h1 id="Harnessing-Deep-Neural-Networks-with-Logic-Rules"><a href="#Harnessing-Deep-Neural-Networks-with-Logic-Rules" class="headerlink" title="Harnessing Deep Neural Networks with Logic Rules"></a><a href="http://aclweb.org/anthology/P/P16/P16-1228.pdf" target="_blank" rel="external">Harnessing Deep Neural Networks with Logic Rules</a></h1><h2 id="关键词-7"><a href="#关键词-7" class="headerlink" title="关键词"></a>关键词</h2><p>CNN、RNN、First-order Logic, Iterative Distillation Method</p>
<h2 id="来源-7"><a href="#来源-7" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-7"><a href="#问题-7" class="headerlink" title="问题"></a>问题</h2><p>如何将深度学习与逻辑规则结合使用？</p>
<h2 id="文章思路-7"><a href="#文章思路-7" class="headerlink" title="文章思路"></a>文章思路</h2><p><img src="media/14727734980533.png" alt=""></p>
<p>系统在构建正常神经网络(student)的同时，构建了一个基于逻辑规则的训练网络(teacher)。整个网络的目标还是优化神经网络的参数变量 θ，因为新的目标损失函数结合了二者的损失，通过这种方式，教师网络的逻辑信息就能够被转移到神经网络的θ上，从而加强神经网络的性能。 在这种结构里逻辑规则是用于辅助的可选项，通过调整权重，系统可以偏向某个网络。这种模型可以将监督学习扩展到无监督学习，比如图示中，无标记的数据通过教师子网之后提取有用信息，也可以用来训练监督学习的神经网络。</p>
<p>1、训练过程</p>
<p>假设输入数据为x, y。student神经网络的参数变量是θ, 输出层是softmax，对输入xn，输出预测概率分布σ(xn)。对teacher网络，在第ｔ次迭代中基于逻辑规则的预测结果表示为sn(t)，那么新的优化目标变成了</p>
<p><img src="media/14727735567000.png" alt=""></p>
<p>可以看出来自教师网络的反馈作为regularization加到了目标函数里，通过这种方式两个网络的信息就结合在了一起。注意教师网络在每次训练迭代中都要构建，因此整个过程被称之为iterative knowledge distillation.</p>
<p>2、教师网络</p>
<p>教师网络使用软逻辑(soft logic)来编码first-order logic的信息。soft logic在[0,1]之间的连续取值，而不是二元值{0, 1}。逻辑运算也用max, min, sum代替原来的与或非。</p>
<p>神经网络数学模型为pθ(y|x) 教师网络数学模型假设为q(y|x)。我们实际上是用基于逻辑规则的教师网络来模拟神经网络输出，因此我们希望能找到一个最优的q，使得输入尽可能满足逻辑规则的要求，同时q要尽可能接近pθ。详细推导可以参见原文，最后的优化结果就是</p>
<p><img src="media/14727736225787.png" alt=""></p>
<p>λl 是每个规则的自信度(confidence)，而rl, gl 是某个规则应用于某一输入时的逻辑结果，介于0,1之间。可以看到自信度比较高的规则可以使输入更容易通过规则。</p>
<p>3、应用</p>
<p>a. 基于CNN的情感分析<br>b. 基于BLSTM-CNN的NER任务</p>
<h2 id="相关工作-6"><a href="#相关工作-6" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Neural-symbolic systems (Garcez et al., 2012) 从给定的规则构建推理网络<br>2、(Collobert 2011)， 利用领域知识domain knowledge提取额外特征，增强原始数据<br>3、Knowledge distillation (Hinton et al., 2015) (Bucilu et al. 2006)<br>4、Posterior regularization (PR) method (Ganchev et al., 2010)</p>
<h2 id="简评-7"><a href="#简评-7" class="headerlink" title="简评"></a>简评</h2><p>创新点在于将逻辑规则与神经网络结合，可以利用人已知的知识去引导机器学习。当数据量不足的，或者对数据进行补充时，可以将人类的知识用逻辑语言表达出来，然后通过本文提出的框架进行增强训练。本文的两个例子中都提到只用了少量规则，优化的结果虽然显示要比当前其他模型好，但是没有大幅度的提高。需要进一步验证如果使用更多的规则，能不能大幅度提高准确率。</p>
<h1 id="Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering"><a href="#Easy-Questions-First-A-Case-Study-on-Curriculum-Learning-for-Question-Answering" class="headerlink" title="Easy Questions First? A Case Study on Curriculum Learning for Question Answering"></a><a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf" target="_blank" rel="external">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</a></h1><h2 id="关键词-8"><a href="#关键词-8" class="headerlink" title="关键词"></a>关键词</h2><p>Curriculum Learning、Self-paced Learning、Question Answering</p>
<h2 id="来源-8"><a href="#来源-8" class="headerlink" title="来源"></a>来源</h2><p>ACL2016</p>
<h2 id="问题-8"><a href="#问题-8" class="headerlink" title="问题"></a>问题</h2><p>文章讨论了Curriculum Learning在NLP领域, 尤其是在QA task里应用的可行性。</p>
<h2 id="文章思路-8"><a href="#文章思路-8" class="headerlink" title="文章思路"></a>文章思路</h2><p>文章首先对QA类型的task给出了比较general的定义: 我们可以把QA问题看做是一个经验风险最小化(ERM)问题, 我们需要最小化:</p>
<p><img src="media/14727739856834.jpg" alt=""></p>
<p>其中是a正确答案, f是给定背景知识以及问题, 模型选择出的最佳答案,Ω是regularizer. </p>
<p>之后, 作者对于Curriculum Learning, 尤其是Self-paced Learning做了介绍, 并且将其引入QA task, 进而将之前的ERM问题变为:</p>
<p><img src="media/14727740344982.jpg" alt=""></p>
<p>其中v是对问题进行采样时候的权值, g是self-paced regularizer, 其中λ代表’age’, 或者说’pace’. 训练初期, 模型趋向于对简单的问题进行训练, 而随着’age’的增加, 模型越来越多地加入更复杂的问题一起训练。</p>
<p>文章给出并分析了四种流行的self-paced regularizer如Table 1:</p>
<p><img src="media/14727745747996.jpg" alt=""></p>
<p>之后提出了7种新的heuristics:</p>
<p>1)    Greedy Optimal (GO): 将已有的Q和一系列新的Q一起训练, 选回答正确并且loss最低的。<br>2)    Change in Objective (CiO): 将已有的Q和一系列新的Q一起训练, 选择令loss改变最小的。<br>3)    Mini-max (M2 ): 当某个新的Q与其loss最大的一个candidate answer配对时, loss最小的. (通俗地讲, 就是最差情况都没有那么糟糕的一个)。<br>4)    Expected Change in Objective (ECiO): 只拿新的Q训练, 和之前的loss改变最小的. (相比于第二种的将已有的Q和新Q一起训练)。<br>5)    Change in Objective-Expected Change in Objective (CiO - ECiO): 2)和4)的值最接近的, 按照作者的意思, 这个值反应了model见到某个新Q时surprise的程度。<br>6)    Correctly Answered (CA): 将一系列新Q在当前model上测试, 选择用最小的loss正确回答的。<br>7)    Farthest from Decision Boundary (FfDB): 只用在latent structural SVMs上, 选择答案与decision boundary最远的一个新Q。</p>
<h2 id="资源-5"><a href="#资源-5" class="headerlink" title="资源"></a>资源</h2><p>MCTest: <a href="http://research.microsoft.com/en-us/um/redmond/projects/mctest/" target="_blank" rel="external">http://research.microsoft.com/en-us/um/redmond/projects/mctest/</a><br>Science Textbook: <a href="http://http://www.ck12.org/" target="_blank" rel="external">http://http://www.ck12.org/</a><br>Science question answering: <a href="http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip" target="_blank" rel="external">http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip</a><br>Simple English Wikipedia: <a href="https://dumps.wikimedia.org/simplewiki/20151102/" target="_blank" rel="external">https://dumps.wikimedia.org/simplewiki/20151102/</a><br>QANTA: <a href="https://cs.umd.edu/~miyyer/qblearn/" target="_blank" rel="external">https://cs.umd.edu/~miyyer/qblearn/</a></p>
<h2 id="相关工作-7"><a href="#相关工作-7" class="headerlink" title="相关工作"></a>相关工作</h2><p>1、Curriculum Learning: </p>
<p>早在1958年[1], 就有认知科学的相关学者意识到, 对于人类学习过程, 相对于提供随机的知识,由浅及深的地给予有计划的训练样本, 可以得到更好的效果. 之后这一Curriculum Learning的想法也被引入到机器学习中[2], 其中Self-paced learning (SPL)[3][4][5]是比较常用的方法。 </p>
<p>2、QA:</p>
<p>Jurafsky和Martin[6]对于QA系列问题有一个非常好的叙述, 而这篇文章突出讨论Curriculum Learning在non-convex的QA模型上的应用, 着重介绍了基于配对的模型[7][8][9]和基于深度学习的模型[10][11].<br>基于配对的模型将每一个问题和问题附带的多个备选答案组成若干个QA对, 我们称之为假设, 然后在给定相关文章的情况下, 寻找有最可能是正确的一个假设作为答案. 基于深度学习的模型可以使用依赖关系树结构的递归神经网络, 对句子level的QA模型的结果取平均[10]; 也可以用RNN构建”长期”存储器, 通过学习对存储器进行读/写操作, 模拟一个动态的知识构建过程[11]。</p>
<h2 id="简评-8"><a href="#简评-8" class="headerlink" title="简评"></a>简评</h2><p>在QA task中引入Curriculum Learning旨在在训练过程中, 启发式地对于提供给模型的数据出现的顺序进行一些调整, 从而让模型从简单的, 易于学习的样本开始, 随着模型对数据的表述愈加成熟, 逐渐加入更复杂的样本. 理想状况下这会指导模型从得到一个普通的local minima, 变成得到一个”更”好的local minima, 进而利用全部数据得到一个”更更”好的local minima。</p>
<p>通常来说, 我们给予模型的heuristic并不一定能够真正帮助模型, 因为通常我们都在猜测数据以及模型的latent representation是什么, 但是这篇文章通过了一系列的实验验证, 本文阐述的heuristic确实可以帮助QA model获得更好的准确率. 这证明了引导模型由浅及深的这种思路是可行的, 我们也许可以思考一些更复杂的heuristic, 或者将其应用到其他的一些NLP tasks。</p>
<p>然而本文给出的大部分heuristic在新问题的选择上都需要比较大的时间复杂度, 对于类似MCTest这种总共只有660个文章的小型数据集来说还算比较现实, 但是对于更大更长的数据集(比如CNN数据集, 38万个文章, 很多文章都超过了一千五百个单词, 而且备选答案数量也远超MCTest的四个)时, 就显得不那么轻松了. 最简单的Attention Sum Reader[1] 在CNN数据集上, 每个epoch都需要10个多小时, 就更别说其他基于AS Reader的模型了。</p>
<p>总体来说, 相对于实用性, 这篇文章更多在于提供了一种新的思路, 也就是把Curriculum Learning相关的概念应用到QA乃至于其他NLP task中, 非常值得思考, 因此是一篇非常值得阅读的文章。</p>
<h1 id="The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context"><a href="#The-LAMBADA-dataset-Word-prediction-requiring-a-broad-discourse-context" class="headerlink" title="The LAMBADA dataset:Word prediction requiring a broad discourse context"></a><a href="http://aclweb.org/anthology/P/P16/P16-1144.pdf" target="_blank" rel="external">The LAMBADA dataset:Word prediction requiring a broad discourse context</a></h1><h2 id="关键词-9"><a href="#关键词-9" class="headerlink" title="关键词"></a>关键词</h2><p>Machine Reading Comprehension、Dataset</p>
<h2 id="来源-9"><a href="#来源-9" class="headerlink" title="来源"></a>来源</h2><p>ACL 2016</p>
<h2 id="问题-9"><a href="#问题-9" class="headerlink" title="问题"></a>问题</h2><p>构建了一个难度更大的机器阅读理解数据集。</p>
<h2 id="构建思路"><a href="#构建思路" class="headerlink" title="构建思路"></a>构建思路</h2><p>以Book Corpus的小说作为数据源，构建了10222个passages，每个passage包括平均4.6句话的context和相邻着的一句target，定义的任务是通过理解context来预测target中最后一个词，平均每个passage包括约75个tokens。其中，超过80%的passage context中包括了target中需要预测的词，48%的target words是专有名词（proper nouns），37%的词是一般名词（common nouns），约7.7%的是动词。这里，专有名词和一般名词是最难猜出来的，动词有一定的概率可以不需要context，而直接从target sentence利用语言模型猜出来。</p>
<p>在处理原始数据时，作者做了一层过滤，将容易从target sentence中直接猜出target word的passages统统丢掉，将剩下的部分放在众包网站上进行人工筛选，筛选的过程比较长，目的是让留在数据集中的数据有下面的效果：通过分析passage的context可以给出正确的target word，而如果只是给定target sentence的话，是猜不出正确的target word。</p>
<h2 id="资源-6"><a href="#资源-6" class="headerlink" title="资源"></a>资源</h2><p>本文数据集Lambada dataset: <a href="http://clic.cimec.unitn.it/lambada/" target="_blank" rel="external">http://clic.cimec.unitn.it/lambada/</a><br>众包网站Crowdflower: <a href="http://www.crowdflower.com/" target="_blank" rel="external">http://www.crowdflower.com/</a><br>原始数据集Book Corpus: <a href="http://www.cs.toronto.edu/~mbweb/" target="_blank" rel="external">http://www.cs.toronto.edu/~mbweb/</a><br>CNN/Daily Mail dataset: <a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">https://github.com/deepmind/rc-data</a><br>CBT dataset: <a href="http://fb.ai/babi/" target="_blank" rel="external">http://fb.ai/babi/</a><br>MSRCC dataset:  <a href="https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/" target="_blank" rel="external">https://www.microsoft.com/en-us/research/publication/the-microsoft-research-sentence-completion-challenge/</a></p>
<h2 id="相关数据集"><a href="#相关数据集" class="headerlink" title="相关数据集"></a>相关数据集</h2><p><img src="media/1.png" alt="1"></p>
<h2 id="简评-9"><a href="#简评-9" class="headerlink" title="简评"></a>简评</h2><p>大型数据集是深度学习技术发展的重要基础，数据集的质量和难度也直接关系着模型的质量和实用性。机器阅读理解的数据集有很多，包括中文和英文的数据集，每一个的构建都会带来模型的创新，随着难度不断增加，对模型也提出了更高的要求。本文在构建数据集过程中为了保证任务的难度所采取的方法是值得借鉴的。</p>
<h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>本期的10篇文章由以下同学完成：</p>
<p>苏辉、Xiaoyu、胡小明、赵越、周青宇、韩晓伟、Eric Yuan、Zewei Chu、tonya、张俊。</p>
<p>感谢大家地辛勤付出。</p>
<h1 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h1><p>PaperWeekly是一个分享知识和交流学问的民间组织，关注的领域是NLP的各个方向。如果你也经常读paper，也喜欢分享知识，也喜欢和大家一起讨论和学习的话，请速速来加入我们吧。</p>
<p>微信公众号：PaperWeekly<br><img src="media/14727755950469.jpg" alt=""></p>
<p>微博账号：PaperWeekly（<a href="http://weibo.com/u/2678093863" target="_blank" rel="external">http://weibo.com/u/2678093863</a> ）<br>知乎专栏：PaperWeekly（<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">https://zhuanlan.zhihu.com/paperweekly</a> ）<br>微信交流群：微信+ zhangjun168305（请备注：加群 or 加入paperweekly）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-26T01:20:19.000Z"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">2016-08-26</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/26/cs-CL-weekly-2016-08-22-2016-08-26/">cs.CL weekly 2016.08.22-2016.08.26</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这个栏目是将一周内arxiv cs.CL刷出的好文进行一个简单的汇总，并配有一句话总结，旨在帮助大家过滤掉cs.CL上的水文，并且为PaperWeekly团队选文提供高质量paper。</p>
<h1 id="Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views"><a href="#Learning-Word-Embeddings-from-Intrinsic-and-Extrinsic-Views" class="headerlink" title="Learning Word Embeddings from Intrinsic and Extrinsic Views"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.05852v1.pdf" target="_blank" rel="external">Learning Word Embeddings from Intrinsic and Extrinsic Views</a></h1><p>本文提出了一种依靠intrinsic (descriptive) and extrinsic (contextual) information来学习词向量的方法，有效解决了传统方法中对低频词学习存在的问题。 </p>
<h1 id="Context-Gates-for-Neural-Machine-Translation"><a href="#Context-Gates-for-Neural-Machine-Translation" class="headerlink" title="Context Gates for Neural Machine Translation"></a><a href="http://120.52.73.78/arxiv.org/pdf/1608.06043v1.pdf" target="_blank" rel="external">Context Gates for Neural Machine Translation</a></h1><p>本文提出了一种context gate来动态地控制机器翻译中source、target context对word generation的影响，实验证明在BLEU指标下比attention-based的方法提高了2.3。</p>
<h1 id="Topic-Sensitive-Neural-Headline-Generation"><a href="#Topic-Sensitive-Neural-Headline-Generation" class="headerlink" title="Topic Sensitive Neural Headline Generation"></a><a href="http://120.52.73.80/arxiv.org/pdf/1608.05777v1.pdf" target="_blank" rel="external">Topic Sensitive Neural Headline Generation</a></h1><p>本文针对传统模型中忽略topical similarities和differences of documents的问题，提出了一种新方案，先将documents按照topics分类，每一类中的pattern比较接近，然后再做sentence level summary，得到了更好的效果。 </p>
<h1 id="Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine"><a href="#Towards-Machine-Comprehension-of-Spoken-Content-Initial-TOEFL-Listening-Comprehension-Test-by-Machine" class="headerlink" title="Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine"></a><a href="http://120.52.73.77/arxiv.org/pdf/1608.06378v1.pdf" target="_blank" rel="external">Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</a></h1><p>本文以托福听力题作为数据集，尝试对多媒体信息进行理解。听力问题是听完一段话，理解之后，进行4选1，而不是之前常见的cloze-style理解任务。</p>
<h1 id="A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems"><a href="#A-Context-aware-Natural-Language-Generator-for-Dialogue-Systems" class="headerlink" title="A Context-aware Natural Language Generator for Dialogue Systems"></a><a href="http://120.52.73.79/arxiv.org/pdf/1608.07076v1.pdf" target="_blank" rel="external">A Context-aware Natural Language Generator for Dialogue Systems</a></h1><p>本文的模型是一种端到端的模型，根据上下文和用户说话的方式来生成对话。是一篇SIGDIAL 2016 short paper。配套的代码已发布于<a href="https://github.com/UFAL-DSG/tgen" target="_blank" rel="external">Github</a></p>
<h1 id="About"><a href="#About" class="headerlink" title="About"></a>About</h1><p>对NLP高质量原创内容和讨论感兴趣的你，赶快来关注：</p>
<p>1、PaperWeekly<a href="http://weibo.com/2678093863/" target="_blank" rel="external">官方微博</a></p>
<p>2、PaperWeekly官方微信</p>
<p><img src="media/qrcode_for_gh_5138cebd4585_430.jpg" alt="qrcode_for_gh_5138cebd4585_430"></p>
<p>3、PaperWeekly<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">知乎专栏</a></p>
<p>4、PaperWeekly微信交流群（+微信zhangjun168305入群）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-21T11:05:52.000Z"><a href="/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/">2016-08-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/21/从api-ai工作原理来看构建简单场景chatbot的一般方法/">从api.ai工作原理来看构建简单场景chatbot的一般方法</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot无疑是当前非常火的一个研究领域和产品方向，简单地可以分为两类，开放域bot和封闭域bot，开放域bot倾向于解决所有的事情，而封闭域bot倾向于解决某一个细分领域中的事情，旨在用AI技术提高效率，提高生产力。现阶段的开放域bot我个人感觉更像是多个常用封闭域bot的叠加，当用户发起一个请求，系统会判断出属于哪个细分领域，然后转到相应的程序中去执行并给出反馈，顺着这个逻辑来看，研究简单场景下的chatbot是个重要的基础工作，这类研究或者产品的质量直接决定了复杂场景或者开放域bot的质量。当然逗乐型的bot并不属于本文讨论的范围。<br><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>chatbot是场交互革命，也是一个多技术融合的平台。上图给出了构建一个chatbot需要具备的组件，简单地说chatbot = NLU(Natural Language Understanding) + NLG(Natural Language Generation).(本文只关注NLP相关的技术，对语音识别并无讨论)</p>
<p>对于封闭域的chatbot，NLU的工作就是DST(Dialog State Tracker)，用户给出输入之后，系统可以给出下面的形式作为state：</p>
<p><b>Act(Slot=Value)</b></p>
<p>Act表示用户行为的类型，比如请求、查询、打招呼等等；Slot表示用户输入中包含的某种Act下的Entity，比如查询酒店的位置、价格这些实体；Value是指Slot中Entity对应的值，比如位置在北边，价格在500-800之间等等。每一句话中可能包括多个Act-Slot-Value对，chatbot需要做的事情就是准确地识别出Act，并且抽取出相应的Slot和Value。</p>
<p>紧接着是NLG的部分，前几天在<a href="http://rsarxiv.github.io/2016/08/16/PaperWeekly-%E7%AC%AC%E4%BA%8C%E6%9C%9F/">PaperWeekly第二期</a>中分享了三篇paper，其中两篇正是研究基于DST的NLG问题。</p>
<p>本文首先从<a href="api.ai">api.ai</a>这家企业提供的服务说起，通过研究其提供的封闭域bot构建技术，来提炼构建简单场景chatbot的一般方法，为构建复杂场景或者找出现有chatbot存在的技术问题和面临的技术难点打下基础。</p>
<h1 id="api-ai"><a href="#api-ai" class="headerlink" title="api.ai"></a>api.ai</h1><h2 id="api-ai公司介绍"><a href="#api-ai公司介绍" class="headerlink" title="api.ai公司介绍"></a>api.ai公司介绍</h2><blockquote>
<p>Api.ai provides developers and companies with the advanced tools they need to build conversational user interfaces for apps and hardware devices.</p>
</blockquote>
<p>这家公司是一家典型的B2D公司，提供了一些工具帮助开发者轻松地开发一款bot，并且可以轻松地发布到各种message平台上。商业模式也非常简单，免费用户有一定次数的调用权限，需要大量调用的话，则付费购买，不同的权限有不同的价格，该公司也提供高级定制化服务。</p>
<p>api.ai公司成立于2010年（数据来自<a href="https://www.crunchbase.com/organization/api-ai#/entity" target="_blank" rel="external">CrunchBase</a>），其早期业务不清楚，但可以从提供的服务中推断出早期攒了大量的用户数据，而且涉及的领域非常多，比如：<br><img src="media/2.png" alt="2"></p>
<p>每个领域都有一个知识库，如果你要开发某个常用领域内的chatbot，那么这个知识库将会非常有用。</p>
<h2 id="重要概念和工作原理"><a href="#重要概念和工作原理" class="headerlink" title="重要概念和工作原理"></a>重要概念和工作原理</h2><h3 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h3><p>1、Agents。这个是一个对外接口，与其他应用程序或你的app进行整合的部分。如下图：<br><img src="media/3.png" alt="3"></p>
<p>2、Entities。这里的实体和引言中提到的Slot类似，是指某个特定领域内的实体，是一类东西的抽象概括，比如HotelName这一实体，对应着很多的酒店名字，凯宾斯基、如家等等。有Entity，就一定有value，chatbot中重要的一步正是从user input中抽取出对应预先设定好entity的value，是一个典型的Named Entity Recognition任务。</p>
<p>这里经典的NER任务是识别出user input中的person、time、place等等几个基本元素，api.ai将这些常见的entity定义为system级的，即默认提供了训练好的识别器，当然不仅仅限于这几类基本的；而特定领域知识库的重要作用也正是在于识别该领域内的entity。除了system level的NER之外，需要developer自定义一些entity，比如菜名，而且要给定具体的菜名和相似的表达作为samples进行训练。</p>
<p>3、Intents。这个相当于是从user input到chatbot执行某个action之间的一个映射关系，用户输入一句话之后，chatbot就可以理解其意图，是在打招呼，还是查询，还是做些别的事情。这部分api.ai提供了训练器，但是需要developer定义一些标注好的examples，标注的形式如下：<br><img src="media/4.png" alt="4"></p>
<p>这里用户输入是book a ticket to Los Angeles on Monday，所谓标注包括两个level，一个是entity标注，一个是intent标注，前一个是为了训练NER工具，后一个是为了识别intent。这里因为LA是地名，Monday是时间，所以都会被api.ai的系统自动标注出来。</p>
<p>4、Actions。这个是由intents进行trigger的，actions就和引言中的Act类似，是一个具体的动作，比如说查询，但执行动作的时候一般都要带上具体的参数value，用户输入：“三里屯最近的阿迪达斯店在什么位置？”，chatbot首先会提取出place-&gt;三里屯，query-&gt;阿迪达斯店，然后转换为json丢给后台的查询服务，查询到结果后给出答案。这里的value抽取其实就是第二个概念提到的entity value。</p>
<p>5、Contexts。上下文是一个非常重要但却解决不是很好的点，api.ai提供的方式是自定义一些context condition，当condition满足时，自动trigger出context关联内容template，然后filling slots，生成response。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>以RSarXiv chatbot为例，简单介绍下工作原理。<br>（注：RSarXiv是我之前写的一个arxiv paper推荐系统）</p>
<p>step 1 自定义Entity，这里我定义了两个entities，一个是keywords和subject。keywords是为search功能提供value，而subject是为update new papers功能提供value。<br><img src="media/5.png" alt="5"><br>定义好subject entity之后，我给出了几个examples，同时也包括其synonyms，keywords entity类似。</p>
<p>step 2  自定义Intents，这里我定义了两个Intents，分别是update和search。下图是update的examples，是我自定义的几个例子。api.ai会根据我定义好的entity进行自动标注，比如cs.CL，today是系统默认的entity所以也进行了自动标注。自动标注是为了后台的机器学习算法对标注好的examples进行学习，以提高chatbot的NLU准确率。<br><img src="media/6.png" alt="6"></p>
<p>接下来，我需要定义下Actions，如下图：<br><img src="media/7.png" alt="7"><br>Action被称为update，必须包含的参数是subject，也就是我们上面讲到的一个entity，date参数并不是必须的。所以，这里如果用户的input被识别出是update intents的话，就必须包括subject参数，否则chatbot会trigger一个response，类似“请用户输入subject”这样的话。</p>
<p>step 3 简单测试，在界面的右侧有一个console，用来测试当前chatbot的效果，我输入update cs.CL，得到下面的效果：<br><img src="media/8.png" alt="8"><br>chatbot识别出Intent是Update，Action是update，Parameter是date和subject，并且subject的值是cs.CL，下面的Show JSON是api.ai为developer生成的，用来与developer自己的web service进行数据交换。</p>
<p>step 4 训练。训练包括两个部分，一是训练NER，二是训练Intent Classification。训练器是api.ai提供的，但是标注数据是developer自己提供的，当然训练数据越多，标注越准，分类器的准确率就越高，chatbot的NLU准确率越高。至于训练方法，docs中没有细说，我简单猜测一下，NER可以当做Sequence Labeling任务，和Intent Recognition类似，都可以看作是多分类问题，不管是传统的分类方法还是当下流行的deep learning方法都能得到不错的准确率。随着user logs的增多，训练数据会越来越多，chatbot通过学习就会变得越来越“聪明”。但这里有个问题，training data越多，需要标注或者修改标注的数据就会越多，也是一个麻烦事儿。</p>
<p>step 5 整合、发布。api.ai支持的平台非常多，包括当下流行的message平台，还有各种操作系统平台。在message平台上提供了一键整合的功能，在操作系统上提供了SDK。这里我用了slack平台，api.ai打通了和slack的接口，也提供了webhook，连接了我之前写好的web service，只需要按照它给定的消息接口进行定义即可。</p>
<h3 id="demo"><a href="#demo" class="headerlink" title="demo"></a>demo</h3><p>目前RSarXiv只提供两个简单的功能，一个是update今天最新的arxiv paper，你可以通过show me new papers in cs.CL等类似的话来获取cs.CL这个领域中最新的paper；一个是search功能，你可以通过search LSTM等类似的话来获取包括LSTM这个关键词的paper。由于是一个测试用的demo，就没做什么复杂的功能。<br><img src="media/10.png" alt="10"></p>
<p>大家如果感兴趣的话，可以留言给我或者发邮件给我(mcgrady150318@gmail.com/mcgrady150318@163.com)，我邀请大家到这个slack team中。</p>
<h1 id="简单场景chatbot构建方法"><a href="#简单场景chatbot构建方法" class="headerlink" title="简单场景chatbot构建方法"></a>简单场景chatbot构建方法</h1><p>介绍了下api.ai提供的服务，下面简单地提炼一下。</p>
<p>chatbot = NLU + NLG</p>
<p>api.ai解决的重点问题是NLU的问题，NLU也是Dialogue State Tracker(DST)的核心和基础，而DST是chatbot的核心。这里的NLU包括两个问题：</p>
<p>1、从user inputs中识别出user intent和对应的action。</p>
<p>2、从user inputs中抽取出预先设定好的entity value，作为action的parameter。</p>
<p>NLG在api.ai这里基本上通过developer在Intent中设定response，当识别出是哪个intent之后，response自然就有了，最多空一些slot，用结果进行填充。如果developer选择了webhook，即需要从自定义的web service中给定response。如下图：<br><img src="media/9.png" alt="9"></p>
<p>跑了一个简单场景的chatbot demo之后，简单归纳下构建方法：</p>
<p>1、从特定任务中归纳出Intents、Actions、Entities。</p>
<p>2、分别编写Intents、Entities的examples，两类examples是做DST的基础，用来训练chatbot准确地识别user intents和entity parameters，至于算法，自己写也可以，用api.ai也可以。</p>
<p>3、做好DST之后，chatbot就知道用户的意图和相应的参数，丢给后台的web service去执行，并得到执行的结果，然后填充预先定义好的templates，生成response，返回给用户。</p>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>简单场景的chatbot关键之处在于做好DST，有一个叫Dialogue State Tracking Challenge的比赛正式为了解决这个问题而举办的。我们说，封闭域的chatbot涉及两个方面，一是NLU，一是NLG，前者通过大量的examples来学习一个分类器和抽取器，得到Dialogue State，而后者根据Dialogue State，生成合适的response。</p>
<p>NLU不是一个简单的事情，尤其是标注大量的examples不是那么容易；NLG同样也不是一个好解决的问题，预先定义的template会让chatbot受限制于template的多少，手工痕迹太重，需要一种更牛的解决方案来代替。（其实挺多paper都在做这件事情，PaperWeekly也分享过几篇相关的paper，data driven的NLG方案同样需要大量的examples做训练。）</p>
<p>Context是个挺难的事情，现有的、成熟的解决方案仍是手工来定义条件，然后根据条件来trigger。我在想，能否构建一个动态的DST，可以是一张动态hash table，也可以是一个动态graph，记录着某一个user方方面面的状态，而不仅仅是某一轮对话中抽取出的信息，而是多轮对话中的信息，不仅在intent识别中可以用到context，在生成response时也可以用到，多轮对话和个性化对话都将不是什么问题了。或者，用现在流行的表示学习思维来想这个问题的话，也许context可以是一个分布式表示，user profile也是一个表示，NLG时以context distribution为condition来做generatation。</p>
<p>本文介绍了构建简单场景下chatbot的一般方法，用api.ai确实很容易做一个chatbot，而对于复杂场景，我觉得用api.ai来开发也没有太大问题，最费时的可能是构建context trigger。api.ai因为是面向developer的，所以对于普通的用户并不适合，但对于有一定经验的developer来说，使用起来就非常简单，提供的web界面也很好用，如果说chatbot是一个平台的话，那么api.ai正像是一个开发工具，提高了开发chatbot的效率，虽然NLG和context这两个问题可以做的更好，但整体来说降低了开发chatbot的门槛，是个很有意义和钱景的服务。</p>
<h1 id="PaperWeekly招人广告"><a href="#PaperWeekly招人广告" class="headerlink" title="PaperWeekly招人广告"></a>PaperWeekly招人广告</h1><p>PaperWeekly每周会分享N篇当下最流行、最有趣的NLP paper，旨在用最精炼的话说明白paper的贡献和创新。目前运营在公众号和知乎专栏两个平台上，现在的形式是每周分享一篇NLP Paper周报，偶尔也会写一些NLP相关的博客，由于本人精力和水平有限，现邀请各位对NLP技术、NLP Paper感兴趣的童鞋加入一同运营，在推进国内NLP技术发展的路上贡献一份自己的力量。</p>
<p>微信公众号：PaperWeekly</p>
<p><img src="media/qrcode.jpg" alt="qrcode"></p>
<p>知乎专栏：<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a></p>
<p>微信交流群：</p>
<p><img src="media/paperweekly.jpg" alt="paperweekly"></p>
<p>群已满100人，无法扫码加群，大家加zhangjun168305，我拉大家入群。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T08:53:50.000Z"><a href="/2016/08/16/PaperWeekly-第二期/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/PaperWeekly-第二期/">PaperWeekly 第二期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p><img src="media/1.png" alt="1"><br>图片来自paper <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/williams2016dstc_overview-1.pdf" target="_blank" rel="external">The Dialog State Tracking Challenge Series- A Review</a></p>
<p>人机对话系统通常包括上面的几个部分，task-oriented chatbot重点关注的是DST和NLG问题，其中DST是核心问题，没有太多关注这个比赛，但个人理解DST的作用类似于一张user conversation logs状态表，记录着用户当前的状态，以订机票为例，这张表的key是预先设定好的slots，比如目的地、出发地、出发时间等等，与系统背后的业务数据表中的attributes相关联，不断地从user conversation中抽取相应的values来填充这个表格，或者将其定义为一个多分类任务，不断地从对话中判断这句话中包括哪些slots和values（这里的values是多个分类结果），当状态表中的信息存在空白时，bot会根据空白的slots来提问并获取values，直到获取到足够的slots，给出用户suggestion，或者进行相应的服务。</p>
<p>DST的问题解决之后，就是NLG的问题。传统的NLG采用rule-based或者template-based的方法，需要很多的手动设置，横向扩展性较差，维护成本高。最近流行的end-to-end方案很适合解决这个问题，给定用户的query，结合着当前DST，自动生成response，完全的data driven，不需要什么人工干预。</p>
<p>生成response除了rule-based和end-to-end的方法之外，工业界中更加常见的是retrieve-based的方法，即从庞大的example base中进行retrieve，一方面避免了NLG生成response时常遇到的grammatical问题，另一方面当前的IR技术很容易集成到此类bot系统中，降低了门槛。</p>
<p>本期的三篇paper中前两篇都是关于task-oriented bot的NLG问题，第三篇是在retrieve-based bot的每个细小环节中应用了deep learning技术，并且将外部的非结构化文本作为数据源，从中select responses。</p>
<h1 id="Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems"><a href="#Semantically-Conditioned-LSTM-based-Natural-Language-Generation-for-Spoken-Dialogue-Systems" class="headerlink" title="Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems"></a><a href="http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP199.pdf" target="_blank" rel="external">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems</a></h1><h2 id="关键词：NLG、bot、自定义LSTM"><a href="#关键词：NLG、bot、自定义LSTM" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：EMNLP-2015"><a href="#来源：EMNLP-2015" class="headerlink" title="来源：EMNLP 2015"></a>来源：EMNLP 2015</h2><h2 id="问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？"><a href="#问题：task-oriented-bot-NLG问题，给定了user-query和DST，如何生成一个更好的response？" class="headerlink" title="问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？"></a>问题：task-oriented bot NLG问题，给定了user query和DST，如何生成一个更好的response？</h2><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><p>首先定义了两个概念delexicalisation和lexicalisation，前一个的意思是将句子中的slot-value用特定的token来替换，像是一种抽象，比如用food来代替对话中的各种食物名称；后一个的意思是将句子中的特定token还原回具体的value。</p>
<p>本文最大的亮点在于将传统的LSTM重新定义，针对这个具体问题在LSTM cell部分中添加了一层，Dialogue Act Cell，通过gate机制来保留合适的信息，比如slot keywords，如下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>这一层cell更像是一个keyword detectors，整个NLG仍是采用encoder-decoder框架。</p>
<h2 id="评论："><a href="#评论：" class="headerlink" title="评论："></a>评论：</h2><p>这层Dialogue Act Cell的目的是确保在decoding部分，不会遗漏任何一个slot，所以专门增加了一层cell来encoding act、slot-value信息，在生成时作为context vector。我觉得model的这个设计与attention机制有一点类似，只是attention更加地平滑，对每个word都有一个weight，而不是本文中的gate，非0即1。整体来说，自定义的cell是一个很有启发性的思路，针对具体问题的特点，修改现有的cell结构，也许会起到非常关键的作用。</p>
<h1 id="Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data"><a href="#Natural-Language-Generation-in-Dialogue-using-Lexicalized-and-Delexicalized-Data" class="headerlink" title="Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data"></a><a href="http://101.110.118.75/128.84.21.199/pdf/1606.03632v1.pdf" target="_blank" rel="external">Natural Language Generation in Dialogue using Lexicalized and Delexicalized Data</a></h1><h2 id="关键词：NLG、bot、自定义LSTM-1"><a href="#关键词：NLG、bot、自定义LSTM-1" class="headerlink" title="关键词：NLG、bot、自定义LSTM"></a>关键词：NLG、bot、自定义LSTM</h2><h2 id="来源：arXiv-2016-06-11-cs-CL"><a href="#来源：arXiv-2016-06-11-cs-CL" class="headerlink" title="来源：arXiv 2016.06.11 cs.CL"></a>来源：arXiv 2016.06.11 cs.CL</h2><h2 id="问题：task-oriented-bot-NLG问题，是第一篇的升级版。"><a href="#问题：task-oriented-bot-NLG问题，是第一篇的升级版。" class="headerlink" title="问题：task-oriented bot NLG问题，是第一篇的升级版。"></a>问题：task-oriented bot NLG问题，是第一篇的升级版。</h2><h2 id="方法：-1"><a href="#方法：-1" class="headerlink" title="方法："></a>方法：</h2><p>本文是针对第一篇文章进行的改进版，改进的地方在于不仅仅利用了delexicalisation进行训练，而且利用了lexicalisation数据，从而提高了准确率，基本的模型框架与第一篇文章类似，不同的在于输入的处理，就是dialogue act的表示，如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>每一个act representation由两部分组成，一部分是act、slots的one-hot表示，与文章一类似的结构，另一部分是由value的每个word embedding组合而成。</p>
<p>task-oriented bot NLG存在的一个更加现实的问题是data规模太小，cover的features太少，生成质量不高，本文针对这一问题，用相似domain的、大量的reviews或者其他相关数据作为corpus预训练出一个效果不错的LM，在decoding部分采用预训练好的LM模型权重进行NLG。</p>
<h2 id="评论：-1"><a href="#评论：-1" class="headerlink" title="评论："></a>评论：</h2><p>本文中最值得借鉴的地方在于transfer learning，虽然DL效果很好，但实际应用中常常遇到data规模太小的问题，DL难以发挥作用，但如果从大量相似的domain data中学习一些表示模型，然后迁移到待解决的问题上，这是一件幸事，也就是人们常说的举一反三。混合大量的相似domain数据，会cover到更丰富的features，为DL提供了广阔的舞台。</p>
<h1 id="DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents"><a href="#DocChat-An-Information-Retrieval-Approach-for-Chatbot-Engines-Using-Unstructured-Documents" class="headerlink" title="DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents"></a><a href="http://aclweb.org/anthology/P16-1049" target="_blank" rel="external">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</a></h1><h2 id="关键词：Retrieve-Based-Bot，Unstructured-Documents"><a href="#关键词：Retrieve-Based-Bot，Unstructured-Documents" class="headerlink" title="关键词：Retrieve-Based Bot，Unstructured Documents"></a>关键词：Retrieve-Based Bot，Unstructured Documents</h2><h2 id="来源：ACL-2016"><a href="#来源：ACL-2016" class="headerlink" title="来源：ACL 2016"></a>来源：ACL 2016</h2><h2 id="问题：如何从大量非结构化文本中select出合适的response返回给用户？"><a href="#问题：如何从大量非结构化文本中select出合适的response返回给用户？" class="headerlink" title="问题：如何从大量非结构化文本中select出合适的response返回给用户？"></a>问题：如何从大量非结构化文本中select出合适的response返回给用户？</h2><h2 id="方法：-2"><a href="#方法：-2" class="headerlink" title="方法："></a>方法：</h2><p>本文研究的问题是给定大量的非结构化的documents和用户的query，从中选择并返回一个满意的response，典型的IR问题，作者将解决方案分为三步：</p>
<p>1、response检索，根据query，从documents中找到合适的N句话作为候选。</p>
<p>2、response排序，将候选中的utterances进行排序。</p>
<p>本文大多数的工作在ranking model上，提出了7种level的features来对candidate进行打分，通过实验发现sentence-level feature最有区分度。</p>
<p>3、response触发，并不是一定可以从documents找到合适的response，所以最后添加一个分类器，来判断最优的response是否合适，合适则输出，不合适则输出空。</p>
<h2 id="评论：-2"><a href="#评论：-2" class="headerlink" title="评论："></a>评论：</h2><p>本文解决的问题思路比较简单，但中间用到了很多复杂的DL model，个人感觉有点杀鸡用牛刀。本文的思路更加适合informative式的query，并不适合娱乐和闲聊。但用外部知识，尤其是大量的非结构化的、可能还带有噪声的资源来提供response，是一个很不错的思路，弥补了只用training data或者很有限的examples存在的局限性问题，如果可以将两者进行结合，是一个非常好的实用方案。</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>引起大家的讨论是一件挺难的事情，所以这一期不再提出问题。之前有同学问如何读paper，这里简单分享一个简单的tip，后续的每一期可能都会分享一个tip。</p>
<p>1、如果刚刚进入一个领域，建议读一些这个领域的survey或review类型的paper，这类型的paper基本上会将最近的方法归类进行总结，从一个较高的层次来解读每一篇paper的贡献和优缺点，对快速了解一个领域很有帮助。如果你关注的这个领域没有survey，那么恭喜你，说明你可能走到了前沿，用关键词去google一篇或者几篇相关的new paper，读Related Work那一节，相信你会有所收获。（注：这个方法是从清华大学刘知远博士那里学来的）</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-16T01:06:36.000Z"><a href="/2016/08/16/pat-baby-and-bot/">2016-08-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/16/pat-baby-and-bot/">pet,baby and bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文的想法来源于某一天对家里狗子Hare一些行为以及身边两个不到3岁的小朋友一些聪明行为的观察和思考，然后将这些行为和思考与当前流行的bot联系一下，形成了本文的内容。</p>
<p>首先，从pet聊起。我家养了一只聪明的小泰迪狗，心眼特别多，会撒娇会打滚会安慰人，非常聪明，他叫Hare。Hare从两个月大到了家里，从开始什么都不会，通过一天天地训练，学会了走、跑、跳、吃饭、喝水、上厕所、坐下、握手和哭。因为他的外婆（我的丈母娘）每天都和他说很多话，教他认识很多东西，所以他可以轻松地分辨出哪个玩具叫什么名字，可以轻松地理解我们说的很多话，不只是一些口令。当我说出门不带他玩的话，他会非常悲伤、可怜地开始哭泣（真的和小孩子哭一模一样）；当我说带他出去的时候，他就会非常兴奋地上蹿下跳；当我说我要出门办事不可以带他的时候，他就乖乖坐在门口目送你走，不哭不闹。所以，我在想Hare应该不是简单地通过观察我们的脸色和语气来识别我们的情绪，他可能真的听得明白很多的话，但一定不是全部，因为他的知识很有限，对这个世界的认识也很有限。Hare的学习绝大多数是监督学习，通过一些正例和负例进行训练，大多数的训练用正例效果非常明显，唯独训练他上厕所，用了不少负例，让他吃了不少苦头，这也带来不少的好处，监督学习很花费时间，样本的量级很重要，通过大量的训练+激励让Hare养成了良好的习惯，成为了一只听话的pet。</p>
<p>我一直在思考一个问题，pet在听主人说话的时候，是听懂了某些他可以理解的关键词还是他确实听懂了整句话，到底是字面意思还是semantic level呢？我想他应该有一定的自主学习能力，做到举一反三可能很难，但举一反二还是有可能的，而不仅仅是从大量的examples中进行学习，确实能够理解一些简单的话，同一个意思的不同说法他都可以理解。科学的解释需要做些实验来研究，这里我有一些简单的解释，第一，他有大脑，虽然没有人类发达，但智商可以和5、6岁的孩子相媲美；第二，他的监督学习不仅仅是从query-response pairs这样的examples中进行，而是更多的维度，包括每一次action之后的激励reward，做对一次动作之后赢得一个奖励，做错了受到惩罚，他不仅仅从主人的语言中来理解意思，还会结合别的因素，比如语调、语境、前一个时刻他的状态等等，而且他可以看到主人的表情和动作，这些因素都可以抽象成一种context。Hare如果前一秒刚刚犯了低级错误，这一秒如果我拿一个零食的叫他过来来吃的话，他就会明白，这其中一定有诈，他一定不会过来，虽然我并没有表现出生气的样子。</p>
<p>pet的事情我们先聊到这里，接下来聊一聊baby的事情。</p>
<p>身边正好可以接触到两个不到三岁的小宝宝，一个男孩一个女孩，他们有很多聪明的行为都让我感到吃惊。先从小男孩说起，小男孩每次来一起吃饭的时候，都会给大家表演他的绝技——认车牌。走在路上，你随意指一辆车，他几乎可以不出错地说出这辆车是本田还是丰田、还是起亚，这是一个典型的有监督多分类学习任务，他的父母有意无意地教他认识各种各样的车，经过一定时间和example的积累，他不断地将准确率提升，可能大脑的发育和将deep learning模型不断地复杂化道理类似吧。学习的过程是积累知识的过程，小男孩慢慢地认识了越来越多的车子，当然这需要不断地教和学，但无疑他本身就是一个知识库（knowledge base），而且认识很多我都不认识的车子，所以当我问他那是什么车的时候，他总是能够给我一个不错的答案。</p>
<p>说完小男孩的事情，再聊一聊小女孩的事情。小女孩语言能力很强，可以说很多的话，而且很多话都非常的funny。基本上和小女孩聊天，就是一个有趣的问答过程，这里的问答不只是我问她答，还有她问我答。小女孩经常和我妈妈在一起，妈妈会教她认识各种东西，因为妈妈信基督教，会教她做祷告，保佑自己一生平安，所以说她不仅仅可以回答一些基本的认知问题，而且有自己的特殊技能，表演“祷告”，而且做的有模有样。她是个求知欲非常强的问题宝宝，她总是指着一个东西，然后开始问我，“这是个什么东西？”，她主动学习的欲望很强，这意味着她的知识库积累地很快。以上都是比较常规的，最值得思考的是她的创造力。她认识很多的动物，也知道怎么称呼这些动物，她根据家里每一个人的名字，起了相应的动物外号，这个不是谁教她的，是她自己说出来的东西；之前提到的祷告词中，原话应该是希望上帝可以赐给她一些聪明智慧，那天在给我们“表演”的时候说出来的是“给她弄一些聪明智慧”，我想这个“弄一些”一定是其他的地方学来的，但她迁移到了这个语境中，这个迁移能力是值得思考的。我们都说理解一个东西不算厉害，如果能够掌握或者控制一个东西才算真正的厉害，她如果只是简单地重复已经学会的知识，也并不稀奇，但她偶尔会有意地装糊涂，故意地说一些错的东西看你能不能识别出来她的错误，她对一些信息的掌握程度很高。</p>
<p>小盆友的创造力让人惊奇，有很多值得思考的地方，相比于pet来说，baby的学习能力更强，带给人的惊喜度更大。chatbot，一个热门的topic，一个大家每天都在谈论的东西，确实还有很长的路要走，太多的地方不能令人满意。</p>
<p>1、最简单的一问一答现在都没有做的很好，example-based和rule-based虽然可以work，但限制太大，前者被example所限制，而后者被rule所限制，而paper中近一段时间流行的所谓generative式的bot看起来好像非常智能，读过paper之后会发现仍是基于example统计的，不管多么牛的模型，都是从example中学习features，example的规模和类型都会严重制约model，而且在生成response时面临着连贯性和语言学的问题，这也是被诟病最多的地方，也就是为什么example-based retrieve式的方法仍是主流的原因。</p>
<p>2、bot应该像人一样具有学习能力，尤其是主动学习能力。现在的bot有self-taught的能力，通常比较被动，并不具备主动学习的意识和能力。bot公司宣传的学习能力也通常是指对log的挖掘，从中找到一些有用的东西存在知识库里，丰富现有的example base。bot可以试着多提一些question，而不仅仅是做answer，主动地学习一些东西。</p>
<p>3、对context的利用和分析还有很长的路要走，context有很多种，如果是纯粹的语言bot，那么就是user之前说过的话，user的情绪，user的意图等等，如果不仅仅是语言的话，正如前面在说pet时提到的，context可以包括图像、语调等等。考虑的东西越多，bot的回答质量就会越高。</p>
<p>4、前几天看了几家科技媒体对新一代微软小冰的报道，说实话丢出挺多概念的，仔细看了下是用增强学习的思路来做，和训练pet比较类似，用一个reward作为牵引，带着bot学习programmer希望bot学习的action。</p>
<p>5、人会举一反三，聪明的动物会举一反二，迁移能力很重要，bot学习过类似的东西，就应该可以做类似的事情，而不是每次都需要重新从头开始学习，如何将已经学习到的知识迁移到新的领域也是一个非常有意义的topic。</p>
<p>从pet到baby，再到bot，从动物到人类，再到机器人，有着难以跨越的鸿沟，但pet、baby的行为可以带来启发和思考，给目前仍停留在初步阶段的bot带来一丝春风，一丝希望。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-05T03:22:47.000Z"><a href="/2016/08/05/PaperWeekly-2016-08-05-第一期/">2016-08-05</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/05/PaperWeekly-2016-08-05-第一期/">PaperWeekly 2016.08.05 第一期</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>学术界和工业界的需求和关注点不同，学术界更加注重未知领域的探索和方法的创新，研究的问题比较抽象，而工业界更加关注实际问题，方法不管是否创新，只要能够解决问题就是好方法，所面对的问题比paper中提炼出的数学问题更加具体，需要处理的细节更多。</p>
<p>paper的水平也是良莠不齐，尤其是arxiv上刷出来的paper更是水平各异。但整体来说，读paper会带来很多的启发，可以跟踪学术界对某一类问题的研究进展，不断地更新技术。关注工业界技术的应用和产品的更迭，可以不断地提炼出新的需求、新的数学问题，从而促进学术地发展，两者其实关系非常紧密。</p>
<p>本周开始，将paperweekly进行改版，从之前的每天一篇paper，改为每周一篇，内容包括多篇paper，这些paper可能相关、也可能不那么相关，但会说清每篇paper解决的问题和解决的方法，旨在拓宽视野，带来启发。本期是改版后的第一期，形式会一直不断地改进，希望工业界和学术界的朋友都能够有所收获。</p>
<h1 id="DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks"><a href="#DeepIntent-Learning-Attentions-for-Online-Advertising-with-Recurrent-Neural-Networks" class="headerlink" title="DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks"></a><a href="http://www.kdd.org/kdd2016/papers/files/rfp0289-zhaiA.pdf" target="_blank" rel="external">DeepIntent: Learning Attentions for Online Advertising with Recurrent Neural Networks</a></h1><h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><p>在线广告、RNN、Attention</p>
<h2 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h2><p>kdd2016</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如何用deep learning模型挖掘click logs来理解用户Intent？</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1.png" alt="1"></p>
<p>对于一个(query,ad)数据对，分别用LSTM encode，然后用下图的方法计算一个attention，得到最终的query和ad vector，构造loss function，取logs中(query,ad)作为正例d+，将ad替换为其他无关ad作为负例d-，训练的目标是让d+的score尽量大，让d-的score尽量小。</p>
<p><img src="media/2.png" alt="2"></p>
<h2 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h2><p>工业界有着学术界无法比拟的数据，大规模的真实数据是做deep learning的基础，大型商业搜索引擎积累了大量的ad click logs，利用好这些logs可以赚到更多的钱。attention机制在2015年开始逐渐成为一种流行趋势，借鉴于人类的注意力机制，让model将更多的注意力放在需要注意的地方，而不是每一个地方。本文并没有太多model上的创新，只是简单地将流行的model应用了自己研究的领域中，对工业界更有参考价值。</p>
<h1 id="A-Neural-Knowledge-Language-Model"><a href="#A-Neural-Knowledge-Language-Model" class="headerlink" title="A Neural Knowledge Language Model"></a><a href="http://120.52.73.76/arxiv.org/pdf/1608.00318v1.pdf" target="_blank" rel="external">A Neural Knowledge Language Model</a></h1><h2 id="关键词-1"><a href="#关键词-1" class="headerlink" title="关键词"></a>关键词</h2><p>语言模型、知识图谱</p>
<h2 id="来源-1"><a href="#来源-1" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.08.01</p>
<h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>在自然语言生成(NLG)问题中，出现次数非常少的entity该如何生成呢？</p>
<h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-2.png" alt="1"></p>
<p>四个步骤：</p>
<p>1、Input Representation<br><img src="media/2-1.png" alt="2"></p>
<p>输入由三个部分拼接而成，第一部分是上一个time step的fact表示，第二部分是上一个time step的词表中的词表示，第三部分是上一个time step的fact description表示，这里fact就是(subject,relation,object)，知识图谱中的一条事实，而后两个部分一定会有一个全为0，因为是二选一的关系，但为了保证每一次的输入都是等长向量，所以用拼接来做。得到输入之后，用LSTM来encode。</p>
<p>2、Fact Prediction</p>
<p>通过1的结果来预测当前word可能相关的fact，得到的结果是一个index，然后从topic knowledge中获得相应的表示，这里的knowledge embedding都是用transE训练好的，在整个模型训练中并不更新。</p>
<p>3、Knowledge-Copy Switch</p>
<p>根据1和2的结果，共同来预测当前要生成的词是从词表中获取的高频词还是从knowledge中获取的entity，典型的二分类问题。</p>
<p>4、Word Generation</p>
<p>根据3的结果，来生成当前time step的词。对于词表中的高频词，和之前的生成方法一致；对于fact description中的entity词，通过预测词的position来copy这个词。</p>
<h2 id="评论-1"><a href="#评论-1" class="headerlink" title="评论"></a>评论</h2><p>语言模型是一个基本问题，传统的方法都有着一个尴尬之处是，会生成大量的<unk>出来，只要是涉及到NLU的问题，基本都会遇到这个问题。本文提供了一个很有启发性的方法，借助于知识图谱这种外部知识来帮助生成效果更好的话，单纯地靠model来提升效果是一件比较困难的事情，但增加一些外部信息进来则会带来更多的可能性。由于知识图谱的构建本身就是一件不易的事情，因此本文的学术意义远大于实际应用意义，为后续这种交叉式研究（知识图谱+深度学习）打开了一扇门，大家可以尝试更多的组合和可能。</unk></p>
<h1 id="Neural-Sentence-Ordering"><a href="#Neural-Sentence-Ordering" class="headerlink" title="Neural Sentence Ordering"></a><a href="https://arxiv.org/pdf/1607.06952v1.pdf" target="_blank" rel="external">Neural Sentence Ordering</a></h1><h2 id="关键词-2"><a href="#关键词-2" class="headerlink" title="关键词"></a>关键词</h2><p>句子排序</p>
<h2 id="来源-2"><a href="#来源-2" class="headerlink" title="来源"></a>来源</h2><p>arXiv cs.CL 2016.07.23</p>
<h2 id="问题-2"><a href="#问题-2" class="headerlink" title="问题"></a>问题</h2><p>给定乱序的N句话，如何将其按照逻辑排列好？（貌似是英语考试中的一种题型）</p>
<h2 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h2><p><img src="media/1-3.png" alt="1"></p>
<p>本文定义的问题是给定n句话，找出最优排序，将这个问题降维到二维，就是如何排列两句话的顺序。上图给出了model的思路，对两句话分别进行encode，得到两个向量表示，然后进行打分，分数表示当前顺序是正确顺序的概率。这里的encode部分，分别用了每句话中word embeddings的加权平均、RNN和CNN来表示。</p>
<p>得到两两的排序之后，本文用beam search来得到整体最优的排序。</p>
<h2 id="评论-2"><a href="#评论-2" class="headerlink" title="评论"></a>评论</h2><p>多文档摘要问题中通用的一种做法是从每篇文档中都提取出一句或几句重要的话，然后进行排序。在英语考试中，有一种题型是给定你打乱顺序的几段话，然后根据逻辑将其排序。本文在学术上没有什么新的东西，但本文在构建neural model的时候，用到的数据集却非常容易构建，这意味着你在工程中应用这个方法来解决排序问题是可行的方案，所以本文更加适合有句子排序应用需求的工程人员来精读。</p>
<h1 id="提问"><a href="#提问" class="headerlink" title="提问"></a>提问</h1><p>计算机的会议非常多，各种level的都有，arXiv上每天都可以刷出一些paper，不同类型、不同level的paper适合不同需求的人来读，我觉得好东西的标准是适合而不是在某一个具体指标上达到最大，对你有用的东西才是适合你的好东西，有些特别牛逼的东西，有着极高学术价值的东西不见得适合工程人员来读，但也不应该是那种觉得学术上的东西离工程太远，没有什么具体用的态度，从各种各样的东西汲取养分，丰富和充实自己才是硬道理。读了一些paper，也该思考一些问题了，这里提出一些比较naive的问题，欢迎大家踊跃留言和讨论。</p>
<p>1、<unk>这种out-of-vocabulary的问题是一个非常常见的问题，有哪些不错的思路可以来解决这个问题呢？</unk></p>
<p>2、attention model几乎满大街都是，最早在机器翻译领域中开始用这种模型，虽然在其他nlp领域中都取得了不错的成绩，但目前的attention真的适合每一类具体问题吗？是不是有一点为了attention而attention的感觉？neural summarization和machine translation真的可以完全类比吗？或者说attention适合解决具有什么特征的问题呢？</p>
<p>3、信息越多，model的效果一定会越好。现在外部信息非常丰富，但是如何融合到当前流行的model中来呢？如何将特定领域内构建的知识图谱完美地与特定任务中的model进行结合呢？以task-oriented bot为例，能够将客户的领域知识与bot response功能结合起来，做成一个更加高级的bot呢？</p>
<p>这里，我抛个砖，引个玉，希望更多的人能够参与讨论和提出问题。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-08-02T03:54:22.000Z"><a href="/2016/08/02/旧幕落下，新幕升起/">2016-08-02</a></time>
      
      
  
    <h1 class="title"><a href="/2016/08/02/旧幕落下，新幕升起/">旧幕落下，新幕升起</a></h1>
  

    </header>
    <div class="entry">
      
        <p>从过年那会筹划一些婚礼的想法开始，到拍婚纱照、找婚庆、跟拍、摄像、化妆、服装、场地、喜宴、安排接送车辆、亲朋住宿以及最近一个月疯狂地在淘宝上购买各种所需的东西，花费的所有时间和精力随着2016.07.31这一天这一场婚礼一起完美谢幕了，整个婚礼结束之后，我带着我的新娘子坐着地铁回家，想想大概也没有谁了。</p>
<p><img src="media/1.pic.jpg" alt="1.pi"></p>
<p>两天过去了，仍然没有从7.31的那场梦里醒来。感谢各位来宾，感谢各位工作人员，感谢保障小组的几位童鞋，感谢烁哥的乐队，感谢祝福我们的每一位！</p>
<p>当时家里不建议7.31结婚，因为他们很迷信地说8.1或者7.29更加适合结婚，而且我妈提前半个月就看天气预报说31号那天有大雨（我早就断定天气预报不准，而且提前那么早看根本没用），但我们仍然坚持就是7.31，不管那天什么天气，都一定是这一天，因为2015.7.31这一天我们正式在法律层面上成为了夫妻，当时离七夕很近，但我们觉得非节日的一天更加适合作为我们的纪念日，于是就在那天领了证，当时我就对韵韵说，明年的今天就是我们大婚的日子，我们要办最有意思、最不一样的婚礼，她点头答应。我们的坚持、我们的固执证明了7.31这一天就是属于我们的，非常棒的天气让整个婚礼进行的非常顺利，非常完美。</p>
<p><img src="media/3.pic.jpg" alt="3.pi"></p>
<p>回礼的准备花费了我们太多的时间和精力，直到婚礼前三天才准备好所有的回礼。长沙这边的一般做法都是准备一盒烟、一袋槟榔和一盒喜糖，当时我们就说要做的不一样，于是韵韵开始了每天长达两小时的淘宝生涯，并且乐此不疲，一盆多肉、一盒果酱和一盒手工喜糖。150份回礼，需要种150盆花，手工装150个喜糖盒子，装150个果酱盒，多亏了几位小同学的帮忙，才能顺利地准备好这些东西，韵韵喜欢兔子，所以袋子也是兔子，多肉的包装上贴着一张兔子贴纸，是我们这次婚礼的logo，是婚庆专门设计的。其实完全可以没必要这么累，直接买现成的就好，但是韵韵坚持要手工做每一个细节，希望每一个细节都做到完美，给宾客们带来不一样的感觉。她做到了！大家都非常喜欢这份回礼。</p>
<p><img src="media/2.pic.jpg" alt="2.pi"></p>
<p>婚礼主持人希望我们两个在婚礼现场可以真情告白一下，于是婚礼前的一周就没有踏实地睡好过，有一天夜里想着我们在一起的这一年多时间，点点滴滴都历历在目，又失眠了！那一晚想了很多很多，每一件事情的每一个细节都记忆犹新，想了很多想要对她说的话，平时也不会说什么深情的话，因为我也不是一个懂浪漫的人。她一直在忙着买各种各样必须的东西，所以直到婚礼前一天晚上在酒店里等我睡着了才开始准备告白的话，2点钟才睡觉，5点就起来准备化妆了。婚礼正式开始了，我之前准备好的词基本上都忘记了，确实有些紧张，但当我看到美丽的新娘站在我的面前时，我就一点都不紧张了，很自然地说出了我内心最真实的感动，以致于第一位伴娘哭的稀里哗啦的，韵韵的台风比我好，一句一句地讲出了我们在一起的美好！</p>
<p><img src="media/4.pic.jpg" alt="4.pi"></p>
<p>我和韵韵正式在一起是在马頔的演唱会上，是在2015.03.18，是我们认识后的第十天，一切看起来都很自然而然，没有任何刻意的安排。我一直有一个心愿就是能够办一场live concert，为我心爱的人献上她最爱的歌曲。于是，我决定在婚礼结束后，安排一场民谣风live concert，邀请喜欢唱歌的同学们一起来嗨。concert很成功，氛围非常好，烁哥的现场没的说，在座的每一位都沉浸在了当时的氛围中，我唱了马頔的《南山南》，韵韵唱了hebe的《小幸运》，一切都是那么地棒！</p>
<p><img src="media/6.pic_hd.jpg" alt="6.pic_hd"></p>
<p>韵韵说她最幸福的时刻就是每天早上醒来，看到身边的我和hare正在酣睡。hare是我们家的小狗，但全家都没有把他当做狗狗来养，我和韵韵是他的爸爸和妈妈，他还有外婆、爷爷和奶奶，每个人都特别爱他，他也是全家的开心果。如果说婚礼有遗憾的话，那就是hare没能来到现场见证他爸爸妈妈最幸福的一刻了。hare之所叫这个名字，是因为他刚刚来家里那会，我正对Air Jordan的Hare球鞋痴迷，Hare本是兔八哥的名字，所以就给他取了这个名字，后来不断地有了很多的名字，张甜心、张甜甜、小黑、心心等等好多的名字，他有一阵子有一些凌乱，突然不知道自己叫什么了。</p>
<p><img src="media/6.pic.jpg" alt="6.pi"></p>
<p>伴郎和伴娘都非常地帅气和美丽，他们给了我们很多的帮助和支持。伴娘都是韵韵的好闺蜜，有陪她一起长大的，有陪她一起工作的，有一个是这个世界上的另外一个她，她们相似的经历，让她们无话不谈，婚礼现场也就是她哭的最厉害了。伴郎都是我的小兄弟，他们替我扛了很多抢亲时的折磨，替我挡了很多的酒，三位伴郎在敬酒时毫无保留，最后通通倒下，有一点遗憾，没有能够参加最后的concert。感谢你们，因为你们，我和韵韵才会更加幸福！</p>
<p><img src="media/7.pic.jpg" alt="7.pi"></p>
<p>婚礼结束了，新的生活开始了！今年27岁，也该有一份自己的事业了，不管现在困难有多少，阻碍有多大，我和韵韵都要开始为我们的事业奋斗了！我一直觉得韵韵不仅仅是生活上的伴侣，更是心灵的伴侣，她最懂我的心，也不顾一切地支持我想做的事业，也愿意和我一起来奋斗这份事业。她细心、聪明、好学、热爱生活、眼光独到，所有美好的标签贴在她身上都不为过，她让我看到了更大的世界，让我明白了生活的意义，走进了我的内心深处让我不再孤独，她的勇敢、知性、独立都让我钦佩，给了我莫大的勇气，让我可以更加自信地活在这个世界上，去勇敢地挑战一些更难的事情。人生就是一场奇遇，感谢上帝让我遇见你！谢谢你，韵韵，我爱你！</p>
<p>旧的一幕已经落下，新的一幕正在升起。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-25T09:06:49.000Z"><a href="/2016/07/25/如果我也做bot/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/如果我也做bot/">如果我也做bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>最近初步地研究了下bot这个领域，有了一点浅薄的理解，于是开始想，如果我也做bot的话，解决好哪些问题才会做好这件事情？</p>
<p>1、创业是一件严肃的事情，不是儿戏，需要做好充足的准备，调研和积累都是非常重要的，只有做好100分的准备，才可能在面对各种未知的困难时不慌乱。所以，第一步就是调研，研究bot，从方方面面，比如：</p>
<p>（1）bot为什么会火？<br>（2）国内哪些企业在做bot？他们的产品有哪些优缺点？<br>（3）国外哪些企业在做bot？有哪些优缺点？<br>（4）投资情况如何？投资人怎么看待这个方向？<br>（5）bot需要哪些技术积累？</p>
<p>2、从媒体、投资人的观点来看，bot整个大方向没有错，那么到底应该做哪个子领域呢？是客服？还是技术支持？技术平台？垂直私人助理？平台上应用？可做的事情其实很多，16年开始才井喷式地炒作bot这个概念，所以今年可以当做是bot元年，既然是刚刚起步的一个领域，就有一个天然的好处，蛋糕足够大，品类足够多，看你想吃哪一块？当然也有一个天然的坏处，就是无章可循，大家都是摸着石头过河。</p>
<p>（1）国内的情况是，客服已经有很多家企业在做了，做的模式大同小异，技术方面各有特色吧，可能起步早的现在规模大一些，晚的小一些，但整体来看差异化不大。如果选择这个方向的话，必须做出差异化，研究现有方案的缺点，之前写过一篇文章，简单剖析了现有方案的缺点和可改进的点，让目前的客服bot更进一步，要么就是做一家客服bot，产品更完美、技术更好，和大家分一杯羹；要么就是提供技术支持，帮现有的bot企业更进一步，赚他们的钱。</p>
<p>（2）如果是做技术支持，典型的SaaS+B2B，用自己的技术服务来为别的企业提供支持，response generation、user modeling、context modeling、information extraction都是不错的方向，每一个做好了都有广阔的前景，以为技术支持不直接面对业务，而是帮助改进现有企业提升算法和建模能力，应用的面比较广，可以用在各种类型的bot上以及其他应用背景上。</p>
<p>（3）平台上的应用，比如slack上的bot，做一个有趣的小功能，提高team的工作效率。这个在国外非常地火，平台也很多，就像是现在ios上开发app一样，每个app都有自己的功能。我觉得这块要是做的话，很容易做出差异化，现在已经有各式各样的startups做着各式各样的bot。但整体来说，技术门槛比较低，有一点API整合的意思，但如果你将自己的技术封装成API，在上面做一个bot提供服务也是一种不错的尝试，而且产品周期特别短，但终究卖点应该还是你的技术支持，而不是这个bot。</p>
<p>（4）技术平台的话，类似的有很多帮助企业或个人构建bot在各种平台上跑，假如微信现在开放了这一块，技术平台一定大有用处，这个属于基础的工具类产品，将很复杂的技术做成人人可以轻松使用的工具是一件很有意义的事情，像是IDE的感觉，不管什么背景，只要是有想法，就可以通过这个工具来实现一个bot，如果复杂的，可能需要定制。</p>
<p>（5）特定任务的私人助理，比如帮忙管理日程、制定旅行计划之类的，术业有专攻嘛，这个最好是之前在其他平台上做类似功能的企业转型到bot这里来，有着足够的积淀，融入一些新的交互和技术来提升产品体验。</p>
<p>上面的每个子领域在国外都有模板可以参考，国内的话还比较少，所以是很大的机会，关键在于判断，在于具体情况具体分析。因为有些东西并不适合做成bot这种聊天式的交互方式，简单的几个按钮操作就可以轻松完成的事情，为什么非要打很多的字来做呢？</p>
<p>3、壁垒。你的核心竞争力是什么？什么是你会别人不会的？如果腾讯也做这个事情，你们该怎么办？你的企业增长点在哪里？如何做大？</p>
<p>这些问题是投资人最关注的问题，其实也是创业前最应该想明白的问题，如果自己都想不明白，或者很多问题难以回答的话，说明现在的情况还不适合创业或者拿投资。我认为，无论什么时候人都是最核心的竞争力，技术和交互形式日新月异，更迭很快，团队只要具有很强的学习能力，永远都不会落于下风。没有什么技术一定是只有你一人才会的，工程上的技术壁垒不应是你提出了一个举世无双、天下无敌的算法，而是你在这个领域内实践各种各样算法的经验积累。为什么说一定要专注地做好一个事情，只做这一件事情，将这件事情做到精，因为对这么细小的领域理解地如此之深的人没有几个，这是你的技术壁垒，也是企业的生存之道，也是其他大公司难以抄袭的重要原因。这个问题一定要想清楚，最重要的是人，在技术层面上，不要想着找到一个独门秘籍来打天下，而是对你所研究的问题有非常深入地理解和见解，这是最基本的也是最核心的；接下来才是如何发展和壮大的问题，这个问题需要讲故事的能力，描绘出一幅美好画面的能力。</p>
<p>我觉得人的能力是最根本的壁垒，当然会有不同看法。有的企业快速扩张，积累客户，可能觉得积累的数据和客户资源是壁垒，但我觉得如果一个新的更好用的技术出来了，而你的企业技术却没跟上的话，很容易就会被取代的，不管你是5w+，还是10w+的客户。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-25T08:12:32.000Z"><a href="/2016/07/25/bot-bot/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/bot-bot/">bot,bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>科技媒体的文章有一个明显的好处，就是会报道很多不易被人发现、但却非常有意思的startups，帮助大家拓宽视野；同时也有一个明显的坏处，文章容易标题党，不够专业的编辑容易写出一些极端的结论，比如xxx一定会取代yyy，炒作概念。所以，这里借助了科技类媒体的优势，考察了下国外的bot startups所覆盖的业务和现状，总结如下：</p>
<p>1、外国的月亮比较圆。有一种常见的误区，也是由来很久的一种偏见，那就是国外的东西一定优质于国内的东西，单纯地从startups的主页来看，国外的风格整体更加清爽和小清新一点，而国内的主页整体来说，充满了一种网站模板没用心选的既视感，有些startups充满了乡土气息。但并不意味着，背后的技术一定比国内好，只是门脸做的不错，slogan喊得不错，每一个startup都有一个改变人类现有生活的理想，仔细看有可能只是一个驻扎在slack或者messenger平台上的小bot。</p>
<p>2、国外的bot startups种类比较多，各个level的企业都有，从最上面的应用层来说，slack、messenger、telegram、kik等各个message平台上都有大量的bot，包括各种各样的服务。这类bot门槛较低，缺乏核心技术，通常是一个idea来支撑整个企业，容易同质化，来源可能是各种bot比赛的产物，域名都是.ai，稍微大一点的支持多个平台，很多都是只在slack上使用，有一种bot成海的感觉，什么样的服务都可以用bot来做，强行改变交互方式。有的slack bot服务于team，有的是将slack与其他服务，比如google analytics，以bot的形式进行桥接。</p>
<p>3、有挺多的startups都在做app store的事情，聚合了大量不同类别的bot，统一进行管理，开发者开发好的bot都放在store中进行展示和销售。这类企业也是平台的性质，但没有自己独立的平台，所以做各大平台的聚合。</p>
<p>4、有的startups做的是降低开发bot门槛的事情，和平台提供接入服务不同，这类企业更具有技术性，将bot开发封装成简单的接口或者界面，供“开发者”甚至是小白来开发属于自己的bot，不管是新闻app还是天气、还是旅游都是几分钟配置的事情，完全没有难度。这类公司相比于平台上的简单bot来说，更加底层一些，也更有技术门槛，但结果却是让bot变得没有技术门槛了。</p>
<p>5、有的startups是独立于几大平台的，提供一种私人助理服务，包括会议、日程、旅行、金融各种服务，为了保证服务质量，常常采用AI+人工的模式。这类公司通常都有核心的技术和垂直领域的经验，对该领域地理解比较深，而且跟得上时代的潮流，用chat作为交互是一个大趋势，索性就早一点进入，确立市场地位。</p>
<p>6、有的startups专门做B2B的技术支持服务，提供NLP、知识抽取方面的服务，为上述的各类企业提供技术支撑，没有直接参与bot，但保证了bot的质量。</p>
<p>7、从各个startups成立时间和融资情况来看，平台上的bot都是2015年底或者2016年初开始热起来的，而2013、2014年就开始朝着这个方向做的企业，基本都是做技术平台、企业客服bot或者私人助理app的，相对来说技术壁垒大一些，门槛高，不容易被模仿和抄袭，所以融资情况较好，当然这个只是现在还存活的企业，死掉地可能也有很多。整体来看，slack之类的平台上做个好玩的bot难度不大，数量如雨后春笋般、井喷式地增长，质量良莠不齐，核心技术少，门槛低，从目前的融资情况看不是很好。而开始早并且技术壁垒大的startups有着更好的市场前景，融资情况也比较乐观。</p>
<p>8、可能是因为考察的startups还比较少，并没有发现像国内有那么多家bot企业都挤在客服这个领域，其他领域的bot企业相对较少，（也有可能是关注的比较少）。国内的微信并没有开放这么彻底，或者说没有一个类似的平台可以做类似的事情，所以各种小bot还没有井喷式地出现，但这是一个趋势，今后一定会有类似的平台出来。</p>
<p>9、bot在全球都很火，国内和国外的侧重点感觉不是很一样，国外的形式比较丰富，各个level的蛋糕都有人在吃，简直无孔不入，反观国内，大家都忙于抢客服这块大蛋糕，其他的蛋糕没有太多的人来吃，这样看来可能也是国内的一个机会，只要不做客服bot，做一些别的业务可能都会有几乎吧。</p>
<p>10、不是什么场景都适合用chatbot来解决的，很多时候我们简单操作下软件比和一个不怎么聪明的bot聊半天效率要高很多的，做bot的话，应该首先分析用哪个场景chat会比操作更加简单，而不是盲目地什么都搞成bot。这一点很重要，媒体的炒作，以及大公司的PR都容易蒙蔽双眼，失去理性判断，清醒地分析一下哪些方向是适合做bot的，而不是一味地去为了bot而bot。</p>
<p>注：所有的数据都是来自于<a href="https://www.crunchbase.com/" target="_blank" rel="external">CrouchBase</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-25T03:39:04.000Z"><a href="/2016/07/25/bot-startups/">2016-07-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/25/bot-startups/">bot startups</a></h1>
  

    </header>
    <div class="entry">
      
        <p>罗列下各种媒体上提到的bot startups，包括：业务范围和融资情况。</p>
<h1 id="motion-ai"><a href="#motion-ai" class="headerlink" title="motion.ai"></a><a href="motion.ai">motion.ai</a></h1><p>用可视化地手段进行构建、训练和发布一个bot。喊出的口号是，只要你会画流程图，你就可以构建一个bot，可以在各种平台上搭建属于自己的bot，比如：sms、web、email、Fb Messenger、Slack等平台。</p>
<p>成立时间：2015.11.05<br>融资情况：$700k 种子轮<br>公司主页：<a href="http://motion.ai" target="_blank" rel="external">http://motion.ai</a></p>
<h1 id="CareerLark"><a href="#CareerLark" class="headerlink" title="CareerLark"></a><a href="http://www.careerlark.com/" target="_blank" rel="external">CareerLark</a></h1><p>构建于Slack平台的一家bot企业，旨在通过micro-feedback来提高生产力。</p>
<p>成立时间：未知<br>融资情况：$50k 种子轮<br>公司主页：<a href="http://www.careerlark.com/" target="_blank" rel="external">http://www.careerlark.com/</a></p>
<h1 id="Carla"><a href="#Carla" class="headerlink" title="Carla"></a><a href="http://carla.io/" target="_blank" rel="external">Carla</a></h1><p>一款虚拟助手，用于提醒自己、朋友和家人，通过自然语言添加日程和追踪自己一天的生活。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://carla.io/" target="_blank" rel="external">http://carla.io/</a></p>
<h1 id="Dexter"><a href="#Dexter" class="headerlink" title="Dexter"></a><a href="https://rundexter.com/" target="_blank" rel="external">Dexter</a></h1><p>帮助企业用户快速构建bot引擎，打造属于自己的bot。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="https://rundexter.com/" target="_blank" rel="external">https://rundexter.com/</a></p>
<h1 id="kip"><a href="#kip" class="headerlink" title="kip"></a><a href="http://kipthis.com/" target="_blank" rel="external">kip</a></h1><p>办公室团购助手，将B2C搬进bot中，方便大家购物，支持多种平台。</p>
<p>成立时间：2014.05.13<br>融资情况：$317k 两轮<br>公司主页：<a href="http://kipthis.com/" target="_blank" rel="external">http://kipthis.com/</a></p>
<h1 id="Rollio"><a href="#Rollio" class="headerlink" title="Rollio"></a><a href="https://www.rollioforce.com/" target="_blank" rel="external">Rollio</a></h1><p>CRM智能助手，将你的销售变得更加简单，用NLP技术来挖掘客户反馈来文本和声音信息，简化CRM。</p>
<p>成立时间：2014<br>融资情况：$670k 种子轮<br>公司主页：<a href="https://www.rollioforce.com/" target="_blank" rel="external">https://www.rollioforce.com/</a></p>
<h1 id="Assist"><a href="#Assist" class="headerlink" title="Assist"></a><a href="http://www.assi.st/" target="_blank" rel="external">Assist</a></h1><p>将企业现有的业务搬进文本消息平台中，用bot来帮企业做生意。</p>
<p>成立时间：未知<br>融资情况：未知<br>公司主页：<a href="http://www.assi.st/" target="_blank" rel="external">http://www.assi.st/</a></p>
<h1 id="magic"><a href="#magic" class="headerlink" title="magic"></a><a href="https://www.getmagicnow.com/" target="_blank" rel="external">magic</a></h1><p>一个基于文本信息平台的通用bot助理，涵盖的面比较广。</p>
<p>成立时间：2015<br>融资情况：$12M 两轮<br>公司主页：<a href="https://www.getmagicnow.com/" target="_blank" rel="external">https://www.getmagicnow.com/</a></p>
<h1 id="Polly"><a href="#Polly" class="headerlink" title="Polly"></a><a href="https://www.polly.ai/" target="_blank" rel="external">Polly</a></h1><p>基于slack平台的bot服务，收集和分析team的数据，提供一些服务，可定制化。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://www.polly.ai/" target="_blank" rel="external">https://www.polly.ai/</a></p>
<h1 id="StatsBot"><a href="#StatsBot" class="headerlink" title="StatsBot"></a><a href="https://statsbot.co/" target="_blank" rel="external">StatsBot</a></h1><p>基于slack平台的bot服务，提供google analytics、mixpanel、salesforce服务。</p>
<p>成立时间：2015<br>融资情况：未知<br>公司主页：<a href="https://statsbot.co/" target="_blank" rel="external">https://statsbot.co/</a></p>
<h1 id="Birdly"><a href="#Birdly" class="headerlink" title="Birdly"></a><a href="https://www.getbirdly.com/" target="_blank" rel="external">Birdly</a></h1><p>基于slack平台的bot服务，沟通team和salesforce的桥梁。</p>
<p>成立时间：2014<br>融资情况：$120k 种子轮<br>公司主页：<a href="https://www.getbirdly.com/" target="_blank" rel="external">https://www.getbirdly.com/</a></p>
<h1 id="zoom-ai"><a href="#zoom-ai" class="headerlink" title="zoom.ai"></a><a href="http://www.zoom.ai/" target="_blank" rel="external">zoom.ai</a></h1><p>企业级的智能助手，支持多个平台和多项服务。</p>
<p>成立时间：2016.02.22<br>融资情况：未知<br>公司主页：<a href="http://www.zoom.ai/" target="_blank" rel="external">http://www.zoom.ai/</a></p>
<h1 id="HeyTaco"><a href="#HeyTaco" class="headerlink" title="HeyTaco!"></a><a href="https://www.heytaco.chat/" target="_blank" rel="external">HeyTaco!</a></h1><p>基于slack平台的bot服务，当你觉得team中一个人做了一件awesome的事情，可以@username + taco emoji，然后该服务会记录下team中每个成员的taco数，攒齐N个可以换一些gift。</p>
<p>成立时间：2016.02.06<br>融资情况：未知<br>公司主页：<a href="https://www.heytaco.chat/" target="_blank" rel="external">https://www.heytaco.chat/</a></p>
<h1 id="skylar"><a href="#skylar" class="headerlink" title="skylar"></a><a href="https://skylar.ai/" target="_blank" rel="external">skylar</a></h1><p>为团队提供多种服务的bot，整合了一些在线工具API，基于slack和messenger平台。</p>
<p>成立时间：2015.11.17<br>融资情况：未知<br>公司主页：<a href="https://skylar.ai/" target="_blank" rel="external">https://skylar.ai/</a></p>
<h1 id="DigitalGenius"><a href="#DigitalGenius" class="headerlink" title="DigitalGenius"></a><a href="http://digitalgenius.com/" target="_blank" rel="external">DigitalGenius</a></h1><p>bot+人工客服服务，多平台多渠道客服。</p>
<p>成立时间：2013.12.01<br>融资情况：$8.35M 三轮<br>公司主页：<a href="http://digitalgenius.com/" target="_blank" rel="external">http://digitalgenius.com/</a></p>
<h1 id="workbot"><a href="#workbot" class="headerlink" title="workbot"></a><a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">workbot</a></h1><p>基于slack平台的bot服务，为团队提供一系列数据服务。</p>
<p>成立时间：2016.01<br>融资情况：未知<br>公司主页：<a href="https://www.workato.com/workbot-slack" target="_blank" rel="external">https://www.workato.com/workbot-slack</a></p>
<h1 id="poncho"><a href="#poncho" class="headerlink" title="poncho"></a><a href="http://poncho.is/" target="_blank" rel="external">poncho</a></h1><p>量身定做的天气和旅行助手。</p>
<p>成立时间：2013.04.01<br>融资情况：$2M 种子轮<br>公司主页：<a href="http://poncho.is/" target="_blank" rel="external">http://poncho.is/</a></p>
<h1 id="Pana"><a href="#Pana" class="headerlink" title="Pana"></a><a href="https://www.pana.com/" target="_blank" rel="external">Pana</a></h1><p>bot+AI旅行安排服务。</p>
<p>成立时间：2015<br>融资情况：$1.45M 两轮<br>公司主页：<a href="https://www.pana.com/" target="_blank" rel="external">https://www.pana.com/</a></p>
<h1 id="Penny"><a href="#Penny" class="headerlink" title="Penny"></a><a href="https://www.pennyapp.io/" target="_blank" rel="external">Penny</a></h1><p>私人财产顾问型bot。</p>
<p>成立时间：2015.07<br>融资情况：$1.2M 种子轮<br>公司主页：<a href="https://www.pennyapp.io/" target="_blank" rel="external">https://www.pennyapp.io/</a></p>
<h1 id="x-ai"><a href="#x-ai" class="headerlink" title="x.ai"></a><a href="https://x.ai" target="_blank" rel="external">x.ai</a></h1><p>帮你安排会议的私人助手。</p>
<p>成立时间：2014.04.14<br>融资情况：$34.3M 三轮<br>公司主页：<a href="https://x.ai" target="_blank" rel="external">https://x.ai</a></p>
<h1 id="viv-ai"><a href="#viv-ai" class="headerlink" title="viv.ai"></a><a href="http://viv.ai/" target="_blank" rel="external">viv.ai</a></h1><p>一个帮助开发者快速开发bot的技术平台，涵盖的面比较广。</p>
<p>成立时间：未知<br>融资情况：30M 三轮<br>公司主页：<a href="http://viv.ai/" target="_blank" rel="external">http://viv.ai/</a></p>
<h1 id="Kasisto"><a href="#Kasisto" class="headerlink" title="Kasisto"></a><a href="http://kasisto.com/kai/" target="_blank" rel="external">Kasisto</a></h1><p>bot技术平台，帮助开发者轻松搭建一个bot。</p>
<p>成立时间：2013<br>融资情况：$2.25M<br>公司主页：<a href="http://kasisto.com/kai/" target="_blank" rel="external">http://kasisto.com/kai/</a></p>
<p>startups信息来自<a href="crunchbase.com">CrunchBase</a>。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-24T05:20:12.000Z"><a href="/2016/07/24/再谈bot/">2016-07-24</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/24/再谈bot/">再谈bot</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是一个TechCrunch最近一年有关bot新闻报道的survey，从原文中提炼了些核心观点，来研究下国外bot的发展。</p>
<h1 id="Forget-Apps-Now-The-Bots-Take-Over"><a href="#Forget-Apps-Now-The-Bots-Take-Over" class="headerlink" title="Forget Apps, Now The Bots Take Over"></a><a href="https://techcrunch.com/2015/09/29/forget-apps-now-the-bots-take-over/" target="_blank" rel="external">Forget Apps, Now The Bots Take Over</a></h1><p>Sep 29, 2015 TechCrunch</p>
<p>正如浏览器取代了操作系统的地位作为新的平台，网站取代了应用程序的地位，bots将会取代移动app的地位，今后将会是bot store，各种各样的bot，而不再是app store。</p>
<p>类似于微信、Line、Facebook、Slack这样的message平台，将会成为一个新的入口。在message平台上有各种各样的bot，用户通过message与各种bot进行交互，来体会之前在手机各种app上的服务。</p>
<p><img src="media/1.png" alt="1"></p>
<blockquote>
<p>It’s a brave new bot-filled world, with new possibilities and new risks.</p>
</blockquote>
<h1 id="Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger"><a href="#Check-out-the-new-AI-powered-TechCrunch-news-bot-on-Telegram-messenger" class="headerlink" title="Check out the new AI-powered TechCrunch news bot on Telegram messenger"></a><a href="https://techcrunch.com/2016/03/15/check-out-the-new-ai-powered-techcrunch-news-bot-on-telegram-messenger/" target="_blank" rel="external">Check out the new AI-powered TechCrunch news bot on Telegram messenger</a></h1><p>Mar 15, 2016 TechCrunch</p>
<p>Techcrunch在Telegram上用<a href="https://chatfuel.com/" target="_blank" rel="external">Chatfuel</a>构建了一个news bot，用户可以通过订阅不同的topic，authors和sections，bot根据订阅内容每天会推送两次trending stories digest给用户，另外也可以进行一些问答、聊天。</p>
<p><img src="media/2.gif" alt="2"></p>
<h1 id="Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else"><a href="#Microsoft-is-bringing-bots-to-Skype-—-and-everywhere-else" class="headerlink" title="Microsoft is bringing bots to Skype — and everywhere else"></a><a href="https://techcrunch.com/2016/03/30/microsoft-is-bringing-bots-to-skype-and-everywhere-else/" target="_blank" rel="external">Microsoft is bringing bots to Skype — and everywhere else</a></h1><p>Mar 30, 2016 TechCrunch</p>
<p>微软CEO Nadella说,bots是下一代应用，只需要用自然语言与bot进行talk就可以完成之前大量手机app和网站做的工作。微软在bot的研究上投入很大，成果也颇多，小冰、Tay、Cortana，和开源的bot framework，并且将很多好玩的deep learning应用与bot做了整合，比如image caption bot，bing music bot，bing news bot。</p>
<p><img src="media/3.jpg" alt="3"></p>
<h1 id="Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it"><a href="#Chat-app-Kik-launches-a-bot-store-and-anyone-can-make-bots-for-it" class="headerlink" title="Chat app Kik launches a bot store and anyone can make bots for it"></a><a href="https://techcrunch.com/2016/04/05/chat-app-kik-launches-a-bot-store-and-anyone-can-make-bots-for-it/" target="_blank" rel="external">Chat app Kik launches a bot store and anyone can make bots for it</a></h1><p>Apr 5, 2016 TechCrunch</p>
<p>Kik是一个聊天app，构建了自己的bot store，chat被认为是下一代操作系统，而聊天app则是新型的浏览器，bots是新型的网站。bot和聊天的环境类似，增加了一些特殊的trigger，用来激发一些特殊的动作。</p>
<p><img src="media/4.png" alt="4"></p>
<h1 id="Botlist-is-an-app-store-for-bots"><a href="#Botlist-is-an-app-store-for-bots" class="headerlink" title="Botlist is an app store for bots"></a><a href="https://techcrunch.com/2016/04/11/botlist-is-an-app-store-for-bots/" target="_blank" rel="external">Botlist is an app store for bots</a></h1><p>Apr 11, 2016 TechCrunch</p>
<p>Botlist是一家做bot聚合的平台，和豌豆荚是类似的概念，聚合了各种message平台上的各种bot应用。</p>
<p><img src="media/5.png" alt="5"></p>
<h1 id="TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger"><a href="#TechCrunch-launches-a-personalized-news-recommendations-bot-on-Facebook-Messenger" class="headerlink" title="TechCrunch launches a personalized news recommendations bot on Facebook Messenger"></a><a href="https://techcrunch.com/2016/04/19/all-your-bots-are-belong-to-us/" target="_blank" rel="external">TechCrunch launches a personalized news recommendations bot on Facebook Messenger</a></h1><p>Apr 19, 2016 TechCrunch</p>
<p>TechCrunch在Fb平台上的bot具备一个简单的个性化推荐的功能，根据用户的喜欢来推荐可能感兴趣的文章。</p>
<h1 id="ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots"><a href="#ToyTalk-renames-to-PullString-repositions-as-authoring-tool-for-bots" class="headerlink" title="ToyTalk renames to PullString, repositions as authoring tool for bots"></a><a href="https://techcrunch.com/2016/04/26/pullstring-bot-authoring/" target="_blank" rel="external">ToyTalk renames to PullString, repositions as authoring tool for bots</a></h1><p>Apr 26, 2016 TechCrunch</p>
<p>PullString做儿童市场，因为孩子的词汇量非常有限，而且都很容易理解，关键是孩子对那些nonsense的回答并不介意。</p>
<p><img src="media/6.gif" alt="6"></p>
<h1 id="Bots-Messenger-and-the-future-of-customer-service"><a href="#Bots-Messenger-and-the-future-of-customer-service" class="headerlink" title="Bots, Messenger and the future of customer service"></a><a href="https://techcrunch.com/2016/05/07/bots-messenger-and-the-future-of-customer-service/" target="_blank" rel="external">Bots, Messenger and the future of customer service</a></h1><p>May 7, 2016 TechCrunch</p>
<p><img src="media/7.png" alt="7"></p>
<p> 传统的客服总是给人留下低效的印象，而随着AI研究水平地不断提高，用bot来替代或者辅助人工客服将是一种趋势和潮流。</p>
<h1 id="Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot"><a href="#Penny-raises-1-2M-in-seed-funding-for-its-personal-finance-bot" class="headerlink" title="Penny raises $1.2M in seed funding for its personal finance bot"></a><a href="https://techcrunch.com/2016/05/23/penny-raises-1-2m-in-seed-funding-for-its-personal-finance-bot/" target="_blank" rel="external">Penny raises $1.2M in seed funding for its personal finance bot</a></h1><p> May 23, 2016 TechCrunch</p>
<p> Penny是一个personal finance bot，通过chat来帮助用户管理finance。不过chat只能通过pre-populated messages，而不是自然语言。尽管进入了一个bot时代，但chat的方式并不是解决所有问题的最好方法，在shopping领域，传统的电商网站比bot更好用。</p>
<p><img src="media/8.jpg" alt="8"></p>
<h1 id="Microsoft-tries-its-hand-at-a-news-bot-with-Rowe"><a href="#Microsoft-tries-its-hand-at-a-news-bot-with-Rowe" class="headerlink" title="Microsoft tries its hand at a news bot with Rowe"></a><a href="https://techcrunch.com/2016/05/24/microsoft-tries-its-hand-at-a-news-bot-with-rowe/" target="_blank" rel="external">Microsoft tries its hand at a news bot with Rowe</a></h1><p>May 24, 2016 TechCrunch</p>
<p>微软太钟爱bot了，在新闻领域开发了一款bot，整合了自家一个新闻App News Pro的功能，通过topic来获取相关news，获取今日头条，获取系统推荐的news。</p>
<p> <img src="media/9.png" alt="9"></p>
<h1 id="Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise"><a href="#Workato-unveils-Personal-Workbot-to-silence-some-of-the-Slack-bot-noise" class="headerlink" title="Workato unveils Personal Workbot to silence some of the Slack bot noise"></a><a href="https://techcrunch.com/2016/06/23/workato-unveils-personal-workbot-to-silence-some-of-the-slack-bot-noise/" target="_blank" rel="external">Workato unveils Personal Workbot to silence some of the Slack bot noise</a></h1><p>Jun 23, 2016 TechCrunch</p>
<p>Workato提供一个bot服务Personal Workbot，为slack用户过滤掉channel中无关的信息，提高效率。</p>
<p><img src="media/10.png" alt="10"></p>
<h1 id="Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload"><a href="#Zoom-ai-believes-an-automated-assistant-is-the-fix-for-a-weighty-workload" class="headerlink" title="Zoom.ai believes an automated assistant is the fix for a weighty workload"></a><a href="https://techcrunch.com/2016/07/14/zoom-ai/" target="_blank" rel="external">Zoom.ai believes an automated assistant is the fix for a weighty workload</a></h1><p>Jul 14, 2016 TechCrunch</p>
<p>Zoom.ai与之前的chat bot startups不同，目的客户是企业。创始人说，bot更像是一种UI，bot背后的技术才是真正需要解决的问题，NLP技术才是最关键的东西。</p>
<h1 id="Legion-Analytics-is-building-bots-to-automate-your-sales-pitch"><a href="#Legion-Analytics-is-building-bots-to-automate-your-sales-pitch" class="headerlink" title="Legion Analytics is building bots to automate your sales pitch"></a><a href="https://techcrunch.com/2016/07/15/legion-analytics-kylie/" target="_blank" rel="external">Legion Analytics is building bots to automate your sales pitch</a></h1><p>Jul 15, 2016 TechCrunch</p>
<p>Legion Analytics这家公司借助人工智能技术，帮助销售团队更加高效地工作。并不是说用bot来替代人工销售团队，而是帮助他们处理更加耗时的邮件咨询和demo演示。</p>
<h1 id="Bot-influencers-are-the-programmatic-future-of-conversational-advertising"><a href="#Bot-influencers-are-the-programmatic-future-of-conversational-advertising" class="headerlink" title="Bot influencers are the programmatic future of conversational advertising"></a><a href="https://techcrunch.com/2016/07/21/bot-influencers-the-programmatic-future-of-conversational-advertising/" target="_blank" rel="external">Bot influencers are the programmatic future of conversational advertising</a></h1><p>Jul 21, 2016 TechCrunch</p>
<p>conversational广告有望改善目前digital ads的缺陷，可以做的更加relevant、contextual和unobtrusive。</p>
<h1 id="Why-do-chatbots-suck"><a href="#Why-do-chatbots-suck" class="headerlink" title="Why do chatbots suck?"></a><a href="https://techcrunch.com/2016/05/29/why-do-chatbots-suck/" target="_blank" rel="external">Why do chatbots suck?</a></h1><p>May 29, 2016 TechCrunch</p>
<p>文中的观点基本同意，chatbot领域太广容易失败，不如做好特定领域内的服务。bot有智能的，比如微软的Tay，也有不智能的，比如Facebook平台上的CNN chatbot，设定一些button，绑定一些特定的事件。市面上没有一个真正好用的bot，很多领域为了bot而bot，用传统的app通过几个步骤就可以完成的事情，在bot中需要通过打很多的字才能完成，其实用户并不在意你的东西是不是智能，也不关心你产品背后的技术多牛，只在乎你的产品是不是简单好用效率高。一切以贴牌炒概念的bot产品都是耍流氓。现阶段，很多相关技术并不成熟，作者建议说在企业客服这个领域多做一些工作，比如把企业的产品FAQ bot做好，节约一些人力成本。（国内很多家做FAQ bot的公司）</p>
<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p>本文是考察国外bot文章系列的第一篇，全都来自TechCrunch。看了一天的新闻文章，从国外科技记者的角度看了下bot这个领域的发展和未来。</p>
<p>1、整体来说，比较乐观，从大公司、投资人、记者、用户多个角色来看，大家都比较看好bot的发展，相信bot是下一个app的形式，就像website取代了传统桌面程序一样，bot也会取代现在的手机app。</p>
<p>2、chat的形式就是大家来聊天，自然而然大的message平台，比如Facebook的Messenger，微信，Line，Slack，Telegram等等，就是成为bot的平台，就像现在的操作系统平台一样。</p>
<p>3、国外的bot公司很多很多，后缀带.ai多的数不清，从这些新闻中分享的bot应用，看得出大家现在还停留在一个比较初始的bot状态，有一点像arxiv上占坑的感觉，没有太多所谓的智能，只是有一个chatbot交互的UI，基本上实现具体的功能都靠事先定制好的button来trigger，更像是交互方式的革新，而非真的人工智能。</p>
<p>4、很多bot都在炒概念，往hot topic上靠，为了bot而bot，手机app用基本简单的点击操作就可以完成的任务，用bot却非要花费大量的时间来输入order或者人类语言，有点多此一举了。说白了，语义理解技术还不够成熟，大家将本该高度智能化的bot做成了step by step的引导，让用户使用了更加复杂的操作。当然，如果你的bot可以准确理解一句或几句简单的人话，然后完成复杂的业务处理，并反馈给用户结果，这样的bot才会让用户真的信服。</p>
<p>5、大伙儿基本上都把bot当成下一代app了，于是出现了很多家做bot聚合和分发的平台，类似app store，豌豆荚这种角色。一个市场雏形出来了之后，大家各自定位，各吃一块蛋糕。</p>
<p>6、客服bot是目前国内市场bot最活跃的一类，提供的功能基本上是企业产品或者业务的faq，差异化在于理解用户的query上，可能技术上略有差异。另外还有一种助手式的bot，提供了一些日常服务，比如查天气，订机票，订饭，打车等功能，基本上纯粹理解自然语言的很少，都是预先设定好套路，根据前一个context来trigger出后一个question，step by step地带着用户完成一个指定任务，因为涉及到多轮对话，context的理解和处理就显得非常重要，理解不好就显得bot非常弱智。这里，我觉得根据context做response的生成是个可以应用的点，虽然说可用的dataset规模很小，但可以考虑将已有的dataset做template化，通过template后的dataset来训练response generator。</p>
<p>今天是系列文章的第一篇，后续会读更多的news或者discussion，以及研究国外bot的产品形式和所用技术，做更多的分享，欢迎讨论。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-22T05:14:05.000Z"><a href="/2016/07/22/国内bot产品试用总结/">2016-07-22</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/22/国内bot产品试用总结/">国内bot产品试用总结</a></h1>
  

    </header>
    <div class="entry">
      
        <p>理想很丰满，现实却很骨感。用这句话来形容当前国内的bot客服机器人最合适不过。本文考察了国内规模较大的6家做bot企业客服业务的公司，从功能描述、客户范围到实际案例进行一下对比和总结。</p>
<h1 id="功能描述"><a href="#功能描述" class="headerlink" title="功能描述"></a>功能描述</h1><p>在各自的网站上都会介绍公司的优势，基本都会包括下面的字眼：</p>
<p>1、海量的知识库储备</p>
<p>2、精准的语义理解能力</p>
<p>3、快速部署能力</p>
<p>4、减轻人工客服压力，节约人力成本</p>
<p>5、无缝衔接人工客服</p>
<p>6、回答准确高极高</p>
<p>7、多渠道</p>
<p>看起来都是非常厉害，都是很牛的技术，理解语义没有任何难度，仿佛真正的bot已经实现了一样，但现实是这样的吗？可能还并不是，可能还需要多年的学术研究来推动这个行业的进步。</p>
<h1 id="客户范围"><a href="#客户范围" class="headerlink" title="客户范围"></a>客户范围</h1><p>客服是一个很大的市场，在各行各业都需要大量的客服人员来做售前和售后咨询，传统的客服面临着一个很尴尬的问题是，总是在回答大量重复的问题，效率很低。很多问题的答案其实可以在企业网站上的FAQ找到，但是消费者仍是喜欢去问客服。在这个背景下，客服bot应运而生，覆盖的行业领域包括：电子商务、游戏网站、政府网站、一般企业等等各行各业。</p>
<h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>使用了他们6家的案例，简单总结一下：</p>
<p>1、大家规模不同，但有一个共同的特点是，宣传中提到为多少多少客户提供服务，但是很多客户的网站中并不能找到相应的bot服务，而且bot公司的网站上并没有给出直接的链接过去，只是说这家客户在用他们的服务。这一点来说，我觉得水分比较大，不够透明。</p>
<p>2、采用的解决方案基本上都是example-based，即bot公司自己的通用知识库+客户的业务知识库。一个用户在使用企业的客服时，很少有无聊的人去调戏人家bot，都是来咨询相关问题的，所以一般来说，bot公司自己的知识库作用非常小，当企业的知识库回答不了现有的问题，bot公司的这种所谓“海量知识库”可以派上用场，和客户逗趣一会，但本质上没有意义。</p>
<p>example-based方案本质上就是信息检索，根据用户的query来找到最合适的example，然后将example中的response返回给用户。用这种方法做一个企业客服bot的话，核心就在构建业务知识库，主要的技术点也在这个地方，最简单的方法是将客户给的历史聊天记录和faq经过一定预处理，生成一个高可用的知识库，扯太多的新概念就有点过分了。明明“快速建知识库”才是核心技术，非要说自己拥有超强的“语义理解”能力。What a shame！</p>
<p>这种方案做出来的效果基本上是一个自动版的faq，可以回到非常有限的问题，如果是企业新遇到的问题，则需要添加知识库，编辑知识库就是个简单的数据库操作，并无高大上，在faq这个层面上，bot确实减少了人力成本。</p>
<p>大多数对用户提出的在知识库范围内的问题都是可以不错地回答，其他的都是在呵呵呵了。但如果在query的理解上有更加深入地研究，比如在语义层面上对query和example进行对比，而不是简单的keyword匹配，在某种程度上会更好地提高服务质量。</p>
<p>大多数的bot将faq写在右侧，鼓励大家选择这样的问法，这其实是一种trick，回避了自身理解query能力的欠缺。有一个网站做的不错，你每次提一个query，他会给你返回四个similar query，这四个都是example中的，让你从中选一个，4选1，正确的几率还是很大的，尤其是他的知识库做的不错的情况下。</p>
<p>3、完全依靠bot是不现实的，毕竟知识库有限，很容易遇到新的问题，每个公司bot都会和人工服务无缝衔接，用户发现bot不靠谱了，可以直接点击人工服务与人沟通。很多企业的bot客服基本上还是主要依靠人工服务，bot的作用太有限了。</p>
<p>4、大家的模式都差不多，可能有的公司技术稍微领先一点，资源多，拿到了一些大单子，行业的名气大，但实际效果来看，媒体的报道和其他一些场合的PR，只是在鼓吹，实际的体验还是很差的。虽然大家的单子很多，利润也可能不少，但能做的事情实在太有限了，一单接一单地做，都说自己是技术公司，但真正的前沿技术很难看到被应用上，用的技术和10年前的研究成果并无太大不同。比如，context的处理，是一个非常有必要但却没有一家做的很好的公司，用户和bot聊了几轮话了，什么信息量都保存和学习不到，只是做了个小型的搜索引擎就敢说是bot了？智能如何体现呢？有点讽刺啊！大家都说学术界太虚，出的paper难用，只能用10年前的技术来做，旧汤换新药而已，但学术界很多的研究都是前瞻性，也很有启发性，不能直接套用并不代表不能借鉴啊，一概而论地说paper无意义有一点短视，有一点为自己技术不过硬找借口了。如果只是这么简单、浮躁的bot解决方案，我觉得在市场上不会有太强的生命力和长远的发展，因为这点技术，大公司稍微做一下都会比这个强，SaaS的特点就是容易接入，技术但凡领先于现在的专业做bot的企业，自然就会取而代之。当然，如果只是为了赚点快钱，这样做是合理的。</p>
<p>5、关于机会，我觉得bot是一个很大的机会，很多人不看好bot的原因是目前做bot采用的技术太过陈旧，效果太差导致。这么说来，机会其实也是从这里来的，正是因为大家的技术都不是太先进，所以才有机会，专注地做好新技术的研发，改善现有bot存在的问题，带给企业客户更优质的服务。先赢都不算赢，最后赢的才是真的赢。</p>
<p>大家都很急着占一个又一个的客户，好像真的占领了这个市场一样。用了这几家的服务之后，感觉有点失望，欲速则不达。 </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-21T09:27:46.000Z"><a href="/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/">2016-07-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/21/Attention-with-Intention-for-a-Neural-Network-Conversation-Model-PaperWeekly/">Attention with Intention for a Neural Network Conversation Model #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-21T03:35:27.000Z"><a href="/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/">2016-07-21</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/21/Neural-Contextual-Conversation-Learning-with-Labeled-Question-Answering-Pairs-PaperWeekly/">Neural Contextual Conversation Learning with Labeled Question-Answering Pairs #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-18T09:21:22.000Z"><a href="/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/">2016-07-18</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/18/Attention-over-Attention-Neural-Networks-for-Reading-Comprehension-PaperWeekly/">Attention-over-Attention Neural Networks for Reading Comprehension #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的文章是arxiv今天刚刚新鲜出炉的paper，来自哈工大讯飞联合实验室。前不久，他们构建了一个大型阅读理解语料，今天也发布出来了。(<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">下载地址</a>)</p>
<p>Cloze-style Reading Comprehension这个领域竞争太过激烈了，半年时间把benchmark刷了一遍又一遍，今天的这篇paper又一次刷新了记录。如果对这个领域不太熟悉的话，可以读这篇<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。</p>
<p>本文的模型被称作Attention over Attention(AoA)，和之前的工作不同，不仅仅考虑query-to-document attention，而且考虑了document-to-query attention。模型架构示意图如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>Contextual Embedding</b> 将query和document都embedding化，用Bi-GRU将query和document分别encode，将两个方向的hidden state拼接起来作为该词的state，此时document和query可以分别用一个Dxd和Qxd的矩阵来表示，这里D是document的词数，Q是query的词数，d是embedding的维度。</p>
<p><b>Pair-wise Matching Score</b> </p>
<p><img src="media/2.png" alt="2"></p>
<p>这一步是本质上就是对两个矩阵做矩阵乘法，得到所谓的Matching Score矩阵M，这里的M矩阵的维度是DxQ，矩阵中的每个元素表示对应document和query中的词之间的matching score。</p>
<p><b>Individual Attentions</b> 对M矩阵中的每一列做softmax归一化，得到所谓的query-to-document attention，即给定一个query词，对document中每个词的attention，本文用下式进行表示：</p>
<p><img src="media/3.png" alt="3"></p>
<p><b>Attention-over-Attention</b> 前三个步骤都是很多模型采用的通用做法，这一步是本文的亮点。首先，第三步是对M矩阵的每一列做了softmax归一化，这里对M矩阵的每一行做softmax归一化，即得到所谓的document-to-query attention，用下式来表示：</p>
<p><img src="media/4.png" alt="4"></p>
<p>然后，将document-to-query attention作平均得到最终的query-level attention，如下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>最后，用每个query-to-document attention和刚刚得到的query-level attention做点乘，得到document中每个词的score。</p>
<p><b>Final Predictions</b> 将相同词的score合并，得到每个词的score，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>从而得到最终的答案。</p>
<p>实验部分用了英文语料CNN和CBT，在没用pre-trained embedding情况下，单模型得到了state-of-the-art结果。</p>
<p><img src="media/7.png" alt="7"></p>
<p>本文模型最大的特点就是不仅仅考虑query到document的attention，而且考虑了document到query的attention，即所谓的attention over attention，在Cloze-style阅读理解任务中取得了更好的结果。同时，作者在未来的工作中，准备将该模型拓展到其他任务中。</p>
<p>attention是一个非常好的机制，将很多任务的benchmark都提高到了很高的水平，是一个革命性的模型。围绕attention的变种做工作，提出各种各样的attention，虽然可以刷新各种任务，但终究不再能够将研究水平提升一个level，需要一个新的机制、新的思想来推动nlp的发展。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-17T01:57:22.000Z"><a href="/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/">2016-07-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/17/End-to-end-LSTM-based-dialog-control-optimized-with-supervised-and-reinforcement-learning-PaperWeekly/">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文介绍的paper一个实用性非常强的解决方案，作者来自于微软研究院，毕业于剑桥大学Spoken Dialogue Group，研究bot很多很多年了。paper的题目是<a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a>，最早发表于今年的6月3日。</p>
<p>文章的开头很有意思，先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服。四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。<br>2、新客服从老客服做出的good examples中模仿学习。<br>3、新客服开始试着服务客户，老客服及时纠正他的错误。<br>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>本文的框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。<br>2、由专家提供一系列example dialogues，用RNN来学习。<br>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。<br>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/1.png" alt="1"></p>
<p>一个完整的工作流程由上图描述:</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文在训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。并且文中以打电话给指定联系人为应用场景，举了一个实际的例子，来帮助理解本文的思路。</p>
<p>一般来说，很多文章提到end-to-end的模型，都是基于大量训练数据用seq2seq来做response的生成，本文并不是这样，本文的神经网络模型是用来训练action selection的，包括后面用RL policy gradient来提升效果也都是为了选择action。虽然本文不是一个纯粹的end-to-end解决方案，但确实一个非常实用的解决方案，尤其是对于task-oriented bot的业务来说，这样的解决方案更加高效，值得复现，值得在一些细节的地方进行改善，从而真正地减少人工features和人工成本。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-16T14:02:39.000Z"><a href="/2016/07/16/也说bot/">2016-07-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/16/也说bot/">也说bot</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>chatbot是最近一段时间非常火的一个词或者一个应用，不仅仅各大新闻媒体在热炒bot的概念，各大巨头也投入巨大的资源进行研发，arxiv上刷出bot相关的paper也更是家常便饭。炒作归炒作，PR归PR，不得不说一个尴尬的事实是市面上确实难以找到一个真正好用的bot。bot按照涉及的领域，分为开放域(open-domain)和面向具体任务(task-oriented)的bot。开放域要做的事情很大，更像是一个什么都能搞的平台，不管你提什么样的需求，它都能够解决，有点true AI的意思，而面向任务的bot则专注做好一件事情，订机票，订餐，办护照等等。</p>
<p>说到开放域bot，大家接触最多的也就是一些回答非常无厘头的娱乐用bot，比如很多年前活跃在各大社交网站上的小黄鸡，现在市面上活跃着很多号称掌握了bot技术，在用深度学习解决bot技术的bot公司，都是这种，解决不了什么实际问题，就是能和大家聊上两句，而且很多时候回答都是牛头不对马嘴的，十分可笑。</p>
<p>再说task-oriented bot，市面上最多的就是客服机器人，银行也好，电商也罢，不想重复性地回答用户的问题，就用一个客服机器人来应对，且不说效果如何，开发一个具体task的bot需要费不少工夫，而且后期还要大量的维护，因为太多的hand crafted features被用到，整个bot的框架横向扩展性相对来说较差，换一个场景基本上就需要重新开发一套，人力成本太高了。</p>
<p>bot的理想非常丰满，大公司描绘的场景也确实很美，但现实的bot却狠狠地浇了一盆冷水下来。期望越高，失望越大。如果媒体一味地吹捧bot，仿佛整个世界明天就会是bot的了，对bot的发展并无益处，捧杀只会带来气泡，破裂之后，一切如初。</p>
<p>功能强大的、开放域的bot在短期内是比较难实现的，但是如果降低期望，将bot不应当做是一种技术层面的革命，而应当做交互层面的革新才是理性的态度，bot作为一种入口，可能大家都不再需要一个随身携带的终端，只需要找到一个可以识别身份，可以联网的硬件，比如一面镜子，就可以执行很多的task，订机票、买东西等等等等。bot这个时候起到的是一个操作的入口和背后执行各种不同task的黑箱，我们不需要看到整个执行过程，也不需要知道原理是什么，通过一些简单的语言交互，就能完成一些复杂的task，终端要做的事情就是反馈结果和接收输入，执行的过程都在云端，各种bot云。</p>
<p>而这一切的关键是解决好task-oriented bot，用更多data driven的解决方案来代替传统的人工features和templates。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>bot是一个综合性的问题，涉及到下面三个主要问题：</p>
<p>1、response generation(selection)</p>
<p>对话生成是最后一个步骤，是输出的部分。简单总结下，有四种solutions：</p>
<p><b>solution 1</b> 直接根据context来生成对话，这方面最近的paper非常地多，尤其是seq2seq+attention框架席卷了NLP的很多任务之后，对话生成的benchmark也一次又一次地被各种model刷新着。对话生成的问题，被定义为基于某个条件下的生成模型，典型的根据context来predict words，涉及到句子生成的问题，评价问题就会是一个比较难的问题。</p>
<p><b>solution 2</b> 当然有的paper并不是将对话生成定义为语言模型问题，而是一个next utterance selection的问题，一个多选一的问题，给定一个context，给定一个utterance candidate list，从list中选择一个作为response，当然这类问题的难度会小很多，评价起来也非常容易，但是数据集准备起来要多花一些功夫，而且在实际应用中不好被借鉴。</p>
<p><b>solution 3</b> rule-based或者说template-based，response的最终形式其实是填充了一个模板而成的，大多数的东西是给定的，只有一些具体的value需要来填充。这一类解决方案很适合做task-oriented bot，但过多的人工features和templates导致了其难以移植到其他task上。</p>
<p><b>solution 4</b> query-based或者说example-based，response是来自于一个叫做知识库的数据库，里面包含了大量的、丰富的example，根据用户的query，找到最接近的example，将对应的response返回出来作为输出。这一类解决方案非常适合做娱乐、搞笑用的bot，核心技术在于找更多的数据来丰富知识库，来清洗知识库。但毕竟respnose是从别人那里拿出来的，可能会很搞笑，但大多数会牛头不对马嘴。</p>
<p>2、dialog state tracking(DST)</p>
<p>有的paper称DST为belief trackers，这个部件其实是bot的核心，它的作用在于理解或者捕捉user intention或者goal，只有当你真的知道用户需要什么，你才能做出正确的action或者response。关于这个部分，会有Dialog State Tracking Challenge比赛。一般来说都会给定一个state的范围，通过context来predict用户属于哪个state，有什么样的需求，是需要查询天气还是要查询火车票。</p>
<p>3、user modeling</p>
<p>bot面向具体的业务，都是和真实的user来打交道的，如果只是简单的FAQ bot，回答几个常见的问题可能不需要这块，但如果是其他更加复杂、细致的业务，都需要给用户建模，相同的问题，bot给每个人的response一定是不同的，这个道理非常简单。user modeling，需要涉及的不仅仅是简单的用户基本信息和用户的一些显式反馈信息，而更重要的是用户的history conversations，这些隐式的反馈信息。就像是推荐系统火起来之前，大家都是中规中矩地卖东西，但是有一些聪明人开始分析用户的行为，不仅是那些点赞行为，更多的是那些用户不经意间留下的“蛛丝马迹”，从而知道了用户对哪些东西潜在地感兴趣，也就是后来推荐系统在做的事情。对user进行建模，就是做一个个性化的bot，生成的每一个response都有这个user鲜明的特点。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>大型的语料都是用来训练开放域bot对话生成模型的，数据源一般都是来自社交网站。而对于task-oriented bot来说，客户的数据一般规模都非常地小，这也正是难以将data driven的方案直接套用到task-oriented bot上的一个主要原因。</p>
<p>[1]中给出了bot训练语料的survey，感兴趣的同学可以读一下这篇survey。</p>
<p><img src="media/1.png" alt="1"></p>
<p>图来自文章[13]，英文的语料确实比较多，Sina Weibo那个语料是华为诺亚方舟实验室release的[12]。从twitter或者微博上产生bot数据的话，“conversational in nature”效果不如从ubuntu chat logs这种聊天室产生的数据更加适合训练response生成模型，因为更加天然无公害。文章[5]也用了一个大型中文语料，数据来自百度贴吧。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p> 研究bot的paper是在太多了，这是一个非常活跃的研究领域，细分的方向也非常的多，接下来按照所针对的研究问题来分别介绍一些模型。</p>
<h2 id="seq2seq生成模型"><a href="#seq2seq生成模型" class="headerlink" title="seq2seq生成模型"></a>seq2seq生成模型</h2><p> 现在最流行的解决方案是seq2seq+attention，encoder将user query feed进来，输出一个vector representation来表示整个query，然后作为decoder的condition，而decoder本质上就是一个语言模型，一步一步地生成response，[2]采用就是这种方案，google用了海量的参数训练出这么一个模型，得到了一个不错的bot。</p>
<p><img src="media/8.png" alt="8"></p>
<p> 而典型的seq2seq存在一个问题，就是说容易生成一些“呵呵”的response，即一些非常safe，grammatical但没有实际意义的response，比如”I don’t know!”之类的。原因在于传统的seq2seq在decoding过程中都是以MLE(Maximum Likelihood Estimate)为目标函数，即生成最grammatical的话，而不是最有用的话，这些safe句子大量地出现在训练语料中，模型学习了之后，无可避免地总是生成这样的response，而文章[3]借鉴了语音识别的一些经验，在decoding的时候用MMI（Maximum Mutual Information）作为目标函数，提高了response的diversity。</p>
<p> 文章[4]认为类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p><img src="media/3.png" alt="3"></p>
<p> 在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p> 文章[5]提出了一种叫做content introducing的方法来生成短文本response。</p>
<p><img src="media/4.png" alt="4"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为response的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword.</p>
<p><b>step 2</b> [5]的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p><b>step 1</b> query + keyword =&gt; backward sequence</p>
<p><b>step 2</b> query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p><b>step 3</b> response = backward (reverse) sequence + keyword + forward sequence</p>
<h2 id="user-modeling模型"><a href="#user-modeling模型" class="headerlink" title="user modeling模型"></a>user modeling模型</h2><p>文章[6]针对的问题是多轮对话中response不一致的问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的请将中生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>[6]的模型叫Speaker Model，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说这里对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。</p>
<h2 id="reinforcement-learning模型"><a href="#reinforcement-learning模型" class="headerlink" title="reinforcement learning模型"></a>reinforcement learning模型</h2><p>用增强学习来解决人机对话问题具有很悠久的历史，只不过随着AlphaGo的炒作，deepmind公司将增强学习重新带回了舞台上面，结合着深度学习来解决一些更难的问题。</p>
<p>增强学习用long term reward作为目标函数，会使得模型通过训练之后可以predict出质量更高的response，文章[7]提出了一个模型框架，具有下面的能力：</p>
<p>1、整合开发者自定义的reward函数，来达到目标。</p>
<p>2、生成一个response之后，可以定量地描述这个response对后续阶段的影响。</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选response，依次往下进行，因为每一个input都会产生5个response，随着turn的增加，response会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的response。</p>
<p>在一个大型数据集上训练一个效果不错的seq2seq作为初始值，用增强学习来提升模型实现自定义reward函数的能力，以达到期待的效果。</p>
<p>文章[7]的模型可以生成更多轮数的对话，而不至于过早地陷入死循环中，而且生成的对话diversity非常好。</p>
<h2 id="task-oriented-seq2seq模型"><a href="#task-oriented-seq2seq模型" class="headerlink" title="task-oriented seq2seq模型"></a>task-oriented seq2seq模型</h2><p>现有的task-oriented bot多是采用rule-based、template-based或者example-based或者是综合起来用，用data driven的解决方案十分稀有。文章[8]和[9]就是尝试在bot的个别部件上采用深度学习的技术来做，并且给出了切实可行的方案。</p>
<p>文章[8]先是从一个大家熟知的场景开始介绍，一个经验丰富的客服是如何带一个新入职的客服，分为四个阶段：</p>
<p>1、告诉新客服哪些”controls”是可用的，比如：如何查找客户的信息，如何确定客户身份等等。</p>
<p>2、新客服从老客服做出的good examples中模仿学习。</p>
<p>3、新客服开始试着服务客户，老客服及时纠正他的错误。</p>
<p>4、老客服放手不管，新客服独自服务客户，不断学习，不断积累经验。</p>
<p>[8]的模型框架就是依照上面的过程进行设计的：</p>
<p>1、开发者提供一系列备选的actions，包括response模板和一些API函数，用来被bot调用。</p>
<p>2、由专家提供一系列example dialogues，用RNN来学习。</p>
<p>3、用一个模拟user随机产生query，bot进行response，专家进行纠正。</p>
<p>4、bot上线服务，与真实客户进行对话，通过反馈来提高bot服务质量。</p>
<p><img src="media/6.png" alt="6"></p>
<p>一个完整的工作流程由上图描述，具体步骤看下图：</p>
<p><img src="media/12.png" alt="12"></p>
<p>训练的时候是用一部分高质量的数据进行监督学习SL，用增强学习RL来优化模型，得到质量更高的结果。</p>
<p>文章[9]平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。</p>
<p><img src="media/10.png" alt="10"></p>
<p>一共五个组件：</p>
<p>1、 Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector。</p>
<p>2、 Belief Trackers</p>
<p>又被称为Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</li>
<li>追踪bot的state，避免去学习那些没有信息量的数据。</li>
<li>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</li>
<li>易扩展新的组件。</li>
</ul>
<p>3、 Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、 Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、 Generation Network</p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。这一步和文章[8]的step 10一样，将具体的值还原到entity上。</p>
<p>完全用end-to-end来解决task-oriented是不可能的事情，一定是在一个框架或者体系内用这种seq2seq的解决方案来做这件事情，文章[8]和[9]给出了很大的启发。</p>
<h2 id="Knowledge-Sources-based模型"><a href="#Knowledge-Sources-based模型" class="headerlink" title="Knowledge Sources based模型"></a>Knowledge Sources based模型</h2><p>纯粹的seq2seq可以解决很多问题，但如果针对具体的任务，在seq2seq的基础上增加一个相关的knowledge sources会让效果好很多。这里的knowledge可以是非结构化的文本源，比如文章[10]中的ubuntu manpages，也可以是结构化的业务数据，比如文章[9]中的database，也可以是一个从源数据和业务数据中提取出的knowledge graph。</p>
<p>文章[10]作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/11.png" alt="11"></p>
<p>模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。因为数据集采用的是ubuntu technical support相关的数据集，外部资源就选用了ubuntu manpages。</p>
<h2 id="context-sensitive模型"><a href="#context-sensitive模型" class="headerlink" title="context sensitive模型"></a>context sensitive模型</h2><p>文章[11]的模型比较简单，但考虑的问题意义很大，history information的建模对于bot在解决实际工程应用的帮助很大，也直接决定了你的bot是否能够work。作者将history context用词袋模型表示，而不是我们经常采用的rnn，然后将context和用户query经过一个简单的FNN，得到一个输出。</p>
<p><img src="media/9.png" alt="9"> </p>
<h1 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h1><p>bot response评价很难，虽然说可以借鉴机器翻译的自动评价方法BLEU来做，但效果不会太好。几乎每篇paper都是会花钱雇人来做人工评价，设计一套评价机制来打分，人工的评价更具有说服力。对于实际工程应用更是如此，用户说好才是真的好。而不是简单地拿着自己提的、有偏的指标，和几个方法或者其他公司的bot进行对比，来说明自己好。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>读了一些paper，也和一线在做bot应用的工程师交流之后，有了一点思考，总结如下：</p>
<p>1、要不要做bot？流行一种说法是市面上没有好用的bot，要解决bot的问题需要很多技术同时进步，可能还需要非常长的一段时间，现在用这个东西来做business，简直荒谬。我个人的看法是，解决具体task的bot，结合当前先进的技术，做一些框架性的工具，并不是那么遥远的事情，虽然不容易，但却非常有意义，解决了垂直领域的bot问题，才有可能解决open domain的bot问题。也正是因为不容易，提高了门槛，才会出现真正的机会，诞生一些很牛的技术公司。</p>
<p>2、open domain还是task-oriented？如果是我，我会选后者，因为前者只是一个梦想，一个遥不可及的梦想，需要更多的技术层面上的大突破。task-oriented更加具体，更加实用，针对具体的业务，提供一些解决方案，已经有很多企业在做了，虽然一个通用性或者扩展性强的解决方案还没有出现，但一定是一个趋势，也是新一代做bot的公司的机会。</p>
<p>3、task-oriented bot为什么难，该朝哪个方向来发力？end-to-end是一种理想化的模型，用深度学习模型从大量训练数据中来“捕捉”一些features，“拟合”一些函数，虽然可以得到很不错的效果，而且使用起来确实很方便，但尴尬就尴尬在具体的task中是拿不到海量数据的，数据规模小了之后，纯粹的end-to-end就变得非常鸡肋了。然而真实的场景中，很多企业又有一定的数据，也有bot的需求，所以现在成熟的解决方案就是针对你的具体业务，来设计一些features，templates和rules，当客户的业务发生更改时，需要不断地维护现有的bot系统，十分费时费力。真实的场景中往往涉及到很多结构化的业务数据，纯粹地、暴力地直接根据context生成response是不可能做到的，文章[8][9]都给出了非常有启发性的解决方案，将end-to-end应用在局部，而非整体上，配合上Information Extraction和Knowledge Graph等技术，实现一个高可用的框架体系，这个应该是task-oriented bot的发展方向。</p>
<p>4、response的生成应该与哪些因素有关呢？response质量的好坏，需要联系到这几个features：（1）user query，用户的提问，用户在这轮对话中到底在问什么，准确地理解用户的意图，这是至关重要的。（2）user modeling，对用户进行建模，包括用户的基本信息，还有更重要的是用户history conversation logs的mining，这个工作很难，但同时也很见水平，也是一家技术公司证明自己技术牛逼的一种途径。logs的挖掘现在很常见，不见得大家都做的很好，而这里的logs不是一般的设定好的、结构化的指标，而是非结构化的文本logs，挖掘起来难度更大。另外一点，也是paper种看到的，user emotion，情感分析是nlp中研究比较多的task，用户的情绪直接关系到销售的成败，如果技术足够牛，可以考虑的因素就可以足够多，对user的分析也就足够清晰。将history生挂在模型中不是一个好办法，因为history是不断增长，会导致模型在捕捉信息时出现问题，更好的办法可能是build user profile之类的东西，将history沉淀出来，作为一个vector representation，或者一种knowledge graph来表征一个user。有了这种能力的bot，说的冠冕堂皇一点就是个性化的bot。（3）knowledge，外部知识源，涉及到具体业务的时候，业务数据也是一种knowledge，如何将knowledge建模到模型中，在生成对话的时候可以更加专业和准确也是一个非常重要的问题。bot是一个综合性的难题，不仅仅是系统框架上的难，而且是建模上的难。</p>
<p>5、我一直觉得做人和看问题都不可以极端，世界并非非黑即白，而是介于两者之间的连续值。不可能说要么做成一个open-domain巨无霸的bot，要么就是一个什么具体功能都没有的bot，不能只看到现有的bot不成熟，以及幻想中的bot遥不可及，就开始黑这个领域，还嘲笑人家能够居然拿到投资。争吵这些毫无意义，真正有意义的是深挖这个领域，找到痛点和难点，逐个击破，不断地推进这个领域的发展，而不是像一些街边看热闹的人一样，简直无趣！在很多领域突破之前，仿佛都看不到曙光，但几年之后很多当时难以解决的问题不都是红海一片，满大街都是了么？做一个通用的bot可能很长一段时间内都是一件比较困难的事情，但做一个高可用、扩展性不错的bot解决方案还是有盼头的，不必过度自信，也不必妄自菲薄，踏踏实实地做就是了。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="external">A Neural Conversational Model</a></p>
<p>[3] <a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a></p>
<p>[4] <a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a></p>
<p>[6] <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a></p>
<p>[7] <a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1606.01269v1.pdf" target="_blank" rel="external">End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a></p>
<p>[10] <a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems</a></p>
<p>[11] <a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a></p>
<p>[12] <a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a></p>
<p>[13] <a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a></p>
<h1 id="研究组和研究人员"><a href="#研究组和研究人员" class="headerlink" title="研究组和研究人员"></a>研究组和研究人员</h1><p>bot是一个非常活跃的研究领域，全世界有很多的人都在做相关的研究。下面列的是最近所读paper的作者或者所在的group：</p>
<p>[1] <a href="http://mi.eng.cam.ac.uk/research/dialogue/" target="_blank" rel="external">Cambridge Dialogue Systems Group</a></p>
<p>[2] <a href="http://www.noahlab.com.hk/topics/ShortTextConversation" target="_blank" rel="external">Huawei NOAH’S ARK LAB</a></p>
<p>[3] <a href="http://web.stanford.edu/~jiweil/" target="_blank" rel="external">Jiwei Li</a></p>
<p>[4] <a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-15T07:56:35.000Z"><a href="/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/">2016-07-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/15/A-Neural-Network-Approach-to-Context-Sensitive-Generation-of-Conversational-Responses-PaperWeekly/">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的这篇paper是旨在训练一个data driven open-domain的bot，在生成response的时候不仅仅考虑user message（query），而且考虑past history作为context。paper的题目是<a href="https://michaelauli.github.io/papers/chitchat.pdf" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>，作者来自蒙特利尔大学、乔治亚理工、facebook和微软研究院，本文最早发于2015年6月。</p>
<p>开放域的端到端response生成在今年已经不是什么新鲜事了，各种复杂的网络，考虑各种各样的信息，然而在去年的这个时候，本文就提出了一种data driven的解决方案，是一篇有开创性的paper。</p>
<p>bot的几大核心问题，包括：</p>
<p>1、response generation（或者selection）</p>
<p>2、dialogue state tracking</p>
<p>3、user modeling</p>
<p>不管是开域的还是闭域的bot都需要解决好以上三个问题才能做出一个高质量的bot。本文针对的问题是第一个，用的思路也是现在看来比较自然的一种，用语言模型来生成response。</p>
<p>考虑history utterances的responses生成问题，先定义一些参数，m表示message（query），c表示context，r表示response。本文要解决的其实是下面这个问题：</p>
<p><img src="media/1.png" alt="1"></p>
<p>1、Tripled Language Model </p>
<p>将c，m，r作为一句话来理解，给定c和m之后，不断地生成r的内容。<br>这个模型存在一个比较严重的问题是c如果过长的话，用BPTT训练不了RNNLM。（其实换作LSTM或者GRU单元就会好很多。）</p>
<p>2、Dynamic-Context Generative Model I </p>
<p><img src="media/2-1.png" alt="2"></p>
<p>将c和m用词袋模型表示，然后拼接起来，作为输入，通过一个简单的FNN，得到输出，即c和m vector representation。</p>
<p>3、Dynamic-Context Generative Model II</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>与2不同的地方在于，将c和m单独作为输入，通过一个简单的FNN，得到c和m的vector representation。</p>
<p>这篇paper针对的问题很有意义，history information的建模对于bot在解决实际工程应用的时候意义重大，会让你的bot看起来更加的智能，和分析了用户日志的web应用会带来更好的服务是一个道理。本文的将具体的context包含到了模型中，在真正应用的时候，离线系统根据user conversation logs build一个user profile会更加实用，因为确实不可能把所有的history都丢到模型中一起来算。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-15T04:44:07.000Z"><a href="/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/">2016-07-15</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/15/Incorporating-Unstructured-Textual-Knowledge-Sources-into-Neural-Dialogue-Systems-PaperWeekly/">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue Systems #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是Ubuntu Dialogue Corpus贡献者的一篇文章，是接着Ubuntu数据集benchmark的model继续改进了一下。本文的题目是<a href="http://media.wix.com/ugd/b6d786_137894b7b3a341a09ed0c0b45b46dbb6.pdf" target="_blank" rel="external">Incorporating Unstructured Textual Knowledge Sources into Neural Dialogue</a>。作者是来自麦吉尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>作者将bot任务定义为next utterance classification，有一点像question answering任务，给定一个context和一个response candidate list作为备选答案，通过context来从candidate list中选择正确的response。本文的贡献在于在context的基础上，引入了task相关的外部专业知识库，并且这个知识库是非结构化的。</p>
<p><img src="media/2.png" alt="2"></p>
<p>这个模型是ubuntu corpus中的baseline模型，称为dual encoder，一个rnn来encode context，一个rnn来encode response，然后综合起来做预测。</p>
<p><img src="media/1.png" alt="1"></p>
<p>本文模型相当于在dual encoder基础上增加了一个knowledge部分。模型是三个rnn encoder组成，一个rnn来encode context，一个rnn来encode response，还有一个rnn来encode knowledge，然后综合起来做预测，选出最合适的response。模型被称作knowledge encoder。</p>
<p>因为是ubuntu technical support相关的数据集，外部资源就选用了Ubuntu Manpages，各种命令的手册，通过从context中提取entity来匹配最相关的command manpage，为了快速定位manpage，用了hash的方法，先做了一个command entity hashtable和relation hashtable，一个是为了完全匹配，一个是为了相关匹配。得到相关的manpage之后，所包括的文本就是knowledge。效果如下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>本文定义的问题太过简单，与实际应用相去甚远。但本文用非结构化的外部知识来解决task-oriented bot问题的思路值得借鉴，不仅仅是bot问题，在问答系统中，外部知识如何应用，如何与神经网络模型结合起来使用都是一个非常重要的topic，也是真正可以用来解决实际问题的一种重要手段。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-14T13:00:30.000Z"><a href="/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/">2016-07-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/14/The-Ubuntu-Dialogue-Corpus-A-Large-Dataset-for-Research-in-Unstructured-Multi-Turn-Dialogue-Systems-PaperWeekly/">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的paper构建了一组大型非结构化的、多轮的对话系统语料，使用的原始数据来自<a href="https://irclogs.ubuntu.com/" target="_blank" rel="external">Ubuntu IRC Logs</a>，是一些关于Ubuntu的讨论组聊天数据。paper的题目是<a href="http://arxiv.org/pdf/1506.08909v3.pdf" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems</a>，作者是来自蒙特利尔大学的博士生<a href="http://cs.mcgill.ca/~rlowe1/" target="_blank" rel="external">Ryan Lowe</a>。</p>
<p>数据规模在100万左右，平均每组数据有8轮对话，最少包括3轮对话。之前的bot语料包括：Dialogue State Tracking Challenge(DSTC)、SwitchBoard这类结构化的数据和Twitter、Sina Weibo这种非结构化的数据，前者专注于预测用户的需求和状态，而后者数据中包括了一定数量的非“conversational in nature”，做bot的训练数据并不那么合适。本文构建的数据集是一个特定领域内的数据，ubuntu technical conversations，规模很大，对话轮数很多，质量很高，也是后续很多paper在研究bot response问题时常常采用的corpus。</p>
<p><img src="media/1.png" alt="1"></p>
<p>语料的构建非常有意义，大型的语料可以训练更加复杂的、偏向open domain的bot model，小型的语料可以解决具体的工程应用问题，如何从杂乱无章的unstructured data中提取出有用的信息，构造出一个适合训练、测试的数据集是一个很难却十分有意义的工作。</p>
<p>本文需要的数据是多轮的、两人的对话数据，但原始的数据是多人无序的对话数据，作者采用了一些小的技巧，并且忽略了一些不合适的数据，将原始数据处理成一个四元组：</p>
<p>(time,sender,recipient,utterance)</p>
<p>在构造模型的训练和测试集时，作者将上面的四元组处理成下面的三元组：</p>
<p>(context,response,flag)</p>
<p>context类似于用户输入，flag表示response是否是context相关联的，关联则为1，否则为0。</p>
<p>给定了数据集，下面就是作者提供的benchmark model，三个非常简单的model，tf-idf，rnn和lstm，目的是为了从response candidates中选择k个最适合context的response作为答案，然后计算相应的准确率。paper中给的方法是selection的方法，而不是generation，后面的很多研究都是generation，真正地从user query生成response。</p>
<p>本文提供的ubuntu dialogue corpus对于task-oriented、response generation的研究有着非常重要的意义，相比于华为给的微博数据，有更强的conversational in nature特征，更加适合对话生成的研究。本文作者的另外一篇survey文章<a href="http://arxiv.org/pdf/1512.05742.pdf" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>,系统地介绍了各大数据集。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-14T02:28:16.000Z"><a href="/2016/07/14/随笔/">2016-07-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/14/随笔/">随笔</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这篇文章的题目有些难产，一直想不出叫一个什么名字好。想写写最近看的东西的一点思考，也想写写一些别的东西，很纠结。以前写文章都喜欢用豆瓣fm推荐的第一首歌作为题目，然后开始写，虽然写的内容可能与题目毫无关系，但却不纠结。听着豆瓣fm，写着blog，是一种很多年的习惯了，习惯是一种可怕的东西，养成了之后就会一直这么做，一点都不能变，不然就会不舒服。</p>
<p>人之所以开心地活在这个世界上是因为大家有很多有意思的事情要做，人之所以害怕离开这个世界是因为很多有意思的事情还没做就结束了。不管现在的状况是怎样，心中充满希望就会不一样。有的人说生活不重要，家庭不重要，只有事业最重要，顾及儿女情长没有什么出息，实在不敢苟同，没有了坚实的地基，空中楼阁再漂亮又有何用？生活的目的就是生活本身，而不是虚伪地活给谁看，和谁比较，与谁相争，向谁证明。</p>
<p>我想用一个比喻来形容我遇到我的爱人可能会比较恰当。从前，有一只在一个无形的笼子里飞来飞去的鸟，他看着地上的人们心中总是有一种优越感，以为自己看得到整个世界，浑然不知自己身在牢笼中。后来来了另外一只鸟，一只特别好看的鸟，帮他打开了笼子，带着他飞向了一个真正广阔的天空，带着他到处飞翔，他才恍然大悟，原来世界可以这么大，于是他们开始了属于他们的旅途。世界很大，而我们很小，我们的格局很小，我们的心胸很小，我们看到的世界很小。世界很有趣，生活也不只是油盐酱醋，也不只是眼前的苟且，还有诗和远方。她用心准备婚礼的每一个细节，请帖用了一种古代西方信件的方式，用融化的蜡块来粘合信封，并且盖上我们俩专属的印章；回礼是一个精美的多肉植物，一盆一盆地种下、包好；喜糖是精心挑选的几种糖果，用一个手工纸袋包装好，过程很麻烦，但是她很享受，你要知道，可不是只做一份、十份，是要只做150份左右，她很享受这样的过程，因为她在用她的双手实现她感兴趣的事情，乐在其中。</p>
<p>世界可以灰暗，也可以很美好，决定于你是一个怎样的人，遇见一个怎样的人。很多人的生活每天都是在钱钱钱的争吵中度过的，永远没一个够，多少钱算多呢？人的欲望又能用多少钱来满足呢？生活可以很糟糕，也可以很美好，取决于你的追求，你所追求的是一种怎样的状态。欲望简单但不乏丰富多彩的生活才是真正高质量的生活，你内心保留地纯粹和纯真越多，生活质量就会越高，相反都会生活地很累，觉得生活都是负担。生活的目的就是生活本身，享受生活就是享受生活中的每一个细节，做一顿大餐，开一个小型音乐party，到录音棚录一首歌曲，看一场演唱会，听一场相声，看一场话剧，拍一些照片，吃一些好吃的垃圾食品，带着hare到处走走，吐槽一些烂剧，开始一场说走就走的旅行。生活中如果只有一个目的，只有工作这一件事情重要的话，那么生活本身就失去了意义，你赚钱也就失去了意义，有的人会说我不努力工作，不赚更多的钱怎么生活，完全可以40或50岁之后再开始享受生活。</p>
<p>最近看bot方面的paper，简单说一下对bot的一点naive的理解。bot火是不争的事实，也是一个必然的趋势，可能做成一个true ai的bot是一件遥不可及的事情，但做出一个能够解决实际问题，提升大家效率的bot是指日可待的事情。我觉得大家对bot的期许不应该是一个什么都能解决的通用工具或者通用技术，如果媒体地热炒加上民众过高的期待会造成新一轮的人工智能寒潮，对这个领域并不是好事。大家可以认为bot是一种新的交互方式，是一种新的操作入口，就像互联网，就像操作系统一样，是一种新的模式，在这种模式背后有大量先进的人工智能技术在做支撑。用户在任何一个地方都不再需要一个特定的终端来做一些常规的事情（不是所有的事情），只需要找一个联网的bot（可能是一个手机，可能是一面镜子，可能是一个电话亭，只要能联网并识别用户身份）就可以完成了，bot执行的过程不需要透明，只需要给出一个结果反馈就可以了，大家的生活围绕着各种各样垂直的bot来展开，只需要最简单的交互就可以完成之前需要复杂操作的事情，比如办个护照，买个机票。如果一个事情很难做的话，我们通常会将其分解成多个容易的事情，逐个攻破，不用期许过高，但相信bot一定会给大家的生活带来一次革命。</p>
<p>bot是一个很大的市场，如果真的能做成一个入口式的平台，相当于重新开辟了一个新的市场，重新定义了这个世界，任何的软件和应用都需要换一种形式，来为用户提供服务。bot确实是一个很美好的梦想，也不是那么遥不可及，但也不是那么容易，那么触手可及。还是需要大量的研究人员不断地努力，攻克难题。现在很多公司都在做bot领域的技术积累和市场占坑，以方便在日后新的一轮机会到来之时，分一杯羹。当前bot的平台有几家大企业在做，但整体来说还是将bot作为一种交互方式，将命令菜单化，并不是真正的对话，有一点iffft的感觉，但确实很多企业也在用这样的平台，大家都是在占坑。bot虽热，但并不是媒体热炒的那样，还是有很多的坑在里面，只有对其进行深入地思考和理解，保持一种冷静和独立地思考，才能真正地抓到痛点和需求，而不是一味地盲目跟随。技术的积累非常重要，因为真正要瓜分市场还是要很高门槛的，不是说你做一个简单的陪聊、逗乐用的机器人就掌握了bot核心技术，真的没有这么简单。周末的时候，准备对最近读bot paper的一些思考，写一篇survey。</p>
<p>美好的生活就是做喜欢的事情，比如亲手构建一个美好的世界，一个bot化的世界，一个更加简便、纯粹的世界。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-13T03:19:26.000Z"><a href="/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/">2016-07-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/13/A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues-PaperWeekly/">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的paper旨在解决语言模型生成部分存在的问题，并且以bot为应用背景进行了实验。paper的题目是<a href="https://arxiv.org/pdf/1605.06069v3.pdf" target="_blank" rel="external">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>，作者来自蒙特利尔大学和Maluuba公司，这家公司的研究水平非常地高，arxiv上常常可以刷出高质量的paper。</p>
<p>通常来讲，自然语言对话都会包含两个层次的结构，一个是utterance，由语言的局部统计信息来表征其含义，一个是topic，由一些随机的特征来表征。本文的工作就是对这些utterance中存在的随机特征进行建模，从而提高语言模型生成人类语言时的质量。本文认为，类似于RNNLM这样的语言模型在生成人话质量不高的根本原因在于，没有处理好隐藏在utterance中的随机feature或者说noise，从而在生成next token（short term goal）和future tokens（long term goal）效果一般。</p>
<p>本文的模型Latent Variable Hierarchical Recurrent Encoder Decoder(VHRED)，在生成过程中分为两步：</p>
<p>step 1 随机采样latent variables</p>
<p>step 2 生成输出序列</p>
<p>架构示意图见下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>在生成每一个utterance时，需要用到四个部分，encoder RNN、context RNN、latent variable、decoder RNN，按顺序依次输入和输出。这里的latent variable和IR中的LSI有一点异曲同工，latent表明我们说不清他们到底具体是什么，但可能是代表一种topic或者sentiment，是一种降维的表示。</p>
<p>实验部分，选择了bot作为应用背景，得到了不错的效果。见下图：</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文解决的不仅仅是bot领域对话生成的问题，而是整个seq2seq框架中decoder的问题，只要涉及到decoder生成的部分都可以采用本文的思想来解决问题。latent topic是一个非常有意思的东西，在LSI、推荐系统中都有非常重要的意义，矩阵分解之后得到两个降维之后的矩阵，从一组两个维度映射到了两组两个维度，也就是多了所谓的latent topic，说不清这些topic是什么，但的确可以将相似的东西聚到了一起。本文也是用latent topic来描述隐藏在utterance中那些说不清道不明的随机noise，得到了更好的效果。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-12T07:11:19.000Z"><a href="/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/">2016-07-12</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/12/A-Network-based-End-to-End-Trainable-Task-oriented-Dialogue-System-PaperWeekly/">A Network-based End-to-End Trainable Task-oriented Dialogue System #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>构建一个task-oriented的bot，比如订票，技术支持服务等等，是一件非常难的事情，因为对于特定任务，训练数据会非常非常有限。在学术界，bot领域现在最流行的解决方案之一是seq2seq，在一个非常庞大的open-domain数据集上进行训练，得到一些效果不错的模型，但难以应用到具体task中，因为这类模型无法做到与数据库交互以及整合其他有用的信息，从而生成实用的response。还有一种非常流行的方案是reinforcement learning，上一篇分享的paper<a href="http://rsarxiv.github.io/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">Deep Reinforcement Learning for Dialogue Generation</a>将两者有机地结合在了一起，增强学习可以使得response生成时考虑更长远的影响。</p>
<p>本文将分享的这篇paper，针对task-oriented的bot问题，平衡了两种流行方案的优缺点，提出了一套有参考价值的、具有实际意义的seq2seq解决方案。paper的题目是<a href="http://arxiv.org/pdf/1604.04562v2.pdf" target="_blank" rel="external">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>，本文于2016年5月20日发表于arxiv上，作者是来自剑桥大学Dialogue System Group的博士生<a href="http://mi.eng.cam.ac.uk/~thw28/" target="_blank" rel="external">Tsung-Hsien Wen</a>，该组专门研究chatbot相关技术，发表过大量与之相关的paper，后续会更多地关注该组的工作。</p>
<p><img src="media/1.png" alt="1"></p>
<p>上图是本文方案的架构示意图，分为五个部分。下面分别进行介绍：</p>
<p>1、Intent Network</p>
<p>这个部分可以理解为seq2seq的encoder部分，将用户的输入encode成一个vector z(t)。encoder部分分别用了lstm和cnn两种模型对该输入进行建模。这两种句子表示的方法在之前的文章中都有介绍。</p>
<p>2、Belief Trackers</p>
<p>这个部分又被称作是Dialogue State Tracking(DST)，是task-oriented bot的核心部件。本文的Belief Trackers具有以下的作用：</p>
<ul>
<li><p>支持各种形式的自然语言被映射成一个有限slot-value对集合中的元素，用于在数据库中进行query。</p>
</li>
<li><p>追踪bot的state，避免去学习那些没有信息量的数据。</p>
</li>
<li><p>使用了一种weight tying strategy，可以极大地减少训练数据的需求。</p>
</li>
<li><p>易扩展新的组件。</p>
</li>
</ul>
<p><img src="media/2.png" alt="2"></p>
<p>这个组件的输入时用户的input，输出是一个informable slot和requestable slot的概率分布，这里的informable slot是指food，price range和area（以订餐为例），用来约束数据库中的查询，requestable slot是指address，phone，postcode等一些可以被询问的值。这里会定义一个针对具体task的知识图谱，来表示这些slot之间的关系，每个slot都会定义一个tracker，tracker的模型如上图所示，包括一个CNN特征提取模块和一个Jordan型的RNN模块，CNN不仅仅对当前的input进行处理，还对上一轮的user input进行处理，综合起来作为RNN的输入。</p>
<p>这个组件的意义在于获取到预先定好的知识图谱中每个slot的分布，就是说弄清楚用户在这轮对话中的需求是哪个词或者词组。</p>
<p>3、Database Operator</p>
<p>数据库查询的输入来自于Belief Trackers的输出，即各种slot的概率分布，取最大的那个作为DB的输入，进行查询，获取到相应的值。</p>
<p>4、Policy Network</p>
<p>这个组件是像一个胶水，起到粘合其他上面三个组件的作用。输入是上面三个组件的输出，输出是一个向量。</p>
<p>5、Generation Network </p>
<p>最后一个组件是生成模型，本质上是一个语言模型，输入是Policy Network的输出，输出是生成的response，再经过一些处理之后可以返回给用户了。这里的处理主要是将response中的slot，比如s.food还原成真实的值。生成部分用简单的LSTM-LM可以做，用Attention Model也可以做，效果会更好。</p>
<p>数据的准备这部分，利用了众包进行收集，一共采用了680轮对话作为训练数据，数据库中保存了99个饭馆，3个informable slots和7个requestable slots。</p>
<p>训练分为两个阶段，第一阶段是训练belief trackers，得到模型之后，更新参数，对生成网络中的语言模型进行训练，得到full model，batch size取1。</p>
<p>bot模型自动评价这块是一个非常难的事情，本文选择了BLEU score、entity matching rate和objective task success rate，本文模型均取得了不错的结果。另外，通过人工评价对本文模型和rule-based进行了对比，结果看下图：</p>
<p><img src="media/3.png" alt="3"></p>
<p>最后paper给出了一种生成的句子向量的二维图，如下图：</p>
<p><img src="media/4.png" alt="4"></p>
<p>几乎同一类话都被聚集到了相似的位置上，验证了模型的有效性。</p>
<p>开放域的bot只是根据query生成一句response，虽然质量可以做到很高，但实用价值不大。面向具体业务的闭域bot一直难以应用seq2seq的解决方案在于，无法将大量的专业信息建模到模型中来，包括：历史信息，用户身份信息，业务信息等等，本文打开了一扇窗，就是将具体的业务信息和历史信息加到了模型中，并且通过将对话中的slot词转换为一些slot表示，就好比构建了很多的模板，降低了对训练数据的需求，避免了seq2seq在应用时存在的问题。如果再考虑上Jiwei Li的那篇<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>中对用户信息的建模，bot的实用价值就会更大，用data来解决真正的业务问题就会更进一步。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T08:47:50.000Z"><a href="/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/Deep-Reinforcement-Learning-for-Dialogue-Generation-PaperWeekly/">Deep Reinforcement Learning for Dialogue Generation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文将会分享一篇深度增强学习在bot中应用的文章，增强学习在很早的时候就应用于bot中来解决一些实际问题，最近几年开始流行深度增强学习，本文作者将其引入到最新的bot问题中。paper的题目是<a href="http://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="external">Deep Reinforcement Learning for Dialogue Generation</a>，作者是Jiwei Li，最早于2016年6月10日发在arxiv上。</p>
<p>现在学术界中bot领域流行的解决方案是seq2seq，本文针对这种方案抛出两个问题：</p>
<p>1、用MLE作为目标函数会导致容易生成类似于“呵呵呵”的reply，grammatical、safe但是没有营养，没有实际意义的话。</p>
<p>2、用MLE作为目标函数容易引起对话的死循环，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>解决这样的问题需要bot框架具备以下的能力：</p>
<p>1、整合开发者自定义的回报函数，来达到目标。</p>
<p>2、生成一个reply之后，可以定量地描述这个reply对后续阶段的影响。</p>
<p>所以，本文提出用seq2seq+增强学习的思路来解决这个问题。</p>
<p>说到增强学习，就不得不提增强学习的四元素：</p>
<ul>
<li>Action</li>
</ul>
<p>这里的action是指生成的reply，action空间是无限大的，因为可以reply可以是任意长度的文本序列。</p>
<ul>
<li>State</li>
</ul>
<p>这里的state是指[pi,qi]，即上一轮两个人的对话表示。</p>
<ul>
<li>Policy</li>
</ul>
<p>policy是指给定state之后各个action的概率分布。可以表示为：pRL(pi+1|pi, qi)</p>
<ul>
<li>Reward</li>
</ul>
<p>reward表示每个action获得的回报，本文自定义了三种reward。 </p>
<p>1、Ease of Answering</p>
<p>这个reward指标主要是说生成的reply一定是容易被回答的。本文用下面的公式来计算容易的程度：</p>
<p><img src="media/2.png" alt="2"></p>
<p>其实就是给定这个reply之后，生成的下一个reply是dull的概率大小。这里所谓的dull就是指一些“呵呵呵”的reply，比如“I don’t know what you are talking about”等没有什么营养的话，作者手动给出了这样的一个dull列表。</p>
<p>2、Information Flow</p>
<p>生成的reply尽量和之前的不要重复。</p>
<p><img src="media/3.png" alt="3"></p>
<p>这里的h是bot的reply表示，i和i+1表示该bot的前后两轮。这个式子表示同一个bot两轮的对话越像reward越小。</p>
<p>3、Semantic Coherence</p>
<p>这个指标是用来衡量生成reply是否grammatical和coherent。如果只有前两个指标，很有可能会得到更高的reward，但是生成的句子并不连贯或者说不成一个自然句子。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这里采用互信息来确保生成的reply具有连贯性。</p>
<p>最终的reward由这三部分加权求和计算得到。</p>
<p>增强学习的几个要素介绍完之后，接下来就是如何仿真的问题，本文采用两个bot相互对话的方式进行。</p>
<p><b>step 1</b> 监督学习。将数据中的每轮对话当做target，将之前的两句对话当做source进行seq2seq训练得到模型，这一步的结果作为第二步的初值。</p>
<p><b>step 2</b> 增强学习。因为seq2seq会容易生成dull reply，如果直接用seq2seq的结果将会导致增强学习这部分产生的reply也不是非常的diversity，从而无法产生高质量的reply。所以，这里用MMI(Maximum Mutual Information，这里与之前Jiwei Li的两篇paper做法一致)来生成更加diversity的reply，然后将生成最大互信息reply的问题转换为一个增强学习问题，这里的互信息score作为reward的一部分（r3）。用第一步训练好的模型来初始化policy模型，给定输入[pi,qi]，生成一个候选列表作为action集合，集合中的每个reply都计算出其MMI score，这个score作为reward反向传播回seq2seq模型中，进行训练。整个仿真过程如下图：</p>
<p><img src="media/5.png" alt="5"></p>
<p>两个bot在对话，初始的时候给定一个input message，然后bot1根据input生成5个候选reply，依次往下进行，因为每一个input都会产生5个reply，随着turn的增加，reply会指数增长，这里在每轮对话中，通过sample来选择出5个作为本轮的reply。</p>
<p>接下来就是评价的部分，自动评价指标一共两个：</p>
<p>1、对话轮数。<br><img src="media/6.png" alt="6"></p>
<p>很明显，增强学习生成的对话轮数更多。</p>
<p>2、diversity。<br><img src="media/7.png" alt="7"><br>增强学习生成的词、词组更加丰富和多样。</p>
<p>下图给出了一个MMI seq2seq与RL方法的对比结果：</p>
<p><img src="media/8.png" alt="8"><br>RL不仅仅在回答上一个提问，而且常常能够提出一个新的问题，让对话继续下去，所以对话轮数就会增多。原因是，RL在选择最优action的时候回考虑长远的reward，而不仅仅是当前的reward。</p>
<p>本文是一篇探索性的文章，将seq2seq与RL整合在一起解决bot的问题是一个不错的思路，很有启发性，尤其是用RL可以将问题考虑地更加长远，获得更大的reward。用两个bot相互对话来产生大量的训练数据也非常有用，在实际工程应用背景下数据的缺乏是一个很严重的问题，如果有一定质量的bot可以不断地模拟真实用户来产生数据，将deep learning真正用在bot中解决实际问题就指日可待了。</p>
<p>RL解决bot问题的文章在之前出现过一些，但都是人工给出一些feature来进行增强学习，随着deepmind用seq2seq+RL的思路成功地解决video games的问题，这种seq2seq的思想与RL的结合就成为了一种趋势，朝着data driven的方向更进一步。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T05:03:05.000Z"><a href="/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/Consensus-Attention-based-Neural-Networks-for-Chinese-Reading-Comprehension-PaperWeekly/">Consensus Attention-based Neural Networks for Chinese Reading Comprehension #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文分享的是今天刚刚刷出的一篇paper，是研究阅读理解的同学们的福音，因为要放出新的而且是中文的数据集。本文的题目是<a href="http://cn.arxiv.org/pdf/1607.02250" target="_blank" rel="external">Consensus Attention-based Neural Networks for Chinese Reading Comprehension</a>，作者均来自哈工大讯飞联合实验室。</p>
<p>对于机器阅读理解的基本内容就不作介绍了，感兴趣的同学可以参考之前写的一篇摘要<a href="http://rsarxiv.github.io/2016/06/18/%E6%95%99%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%98%85%E8%AF%BB/">教机器学习阅读</a>。本文最大的亮点在于构建了中文机器阅读语料，语料分为两个部分，一个是训练集和自测试集，一个是领域外的测试集，包括人工的提问和自动获取的提问两种。（<a href="http://hfl.iflytek.com/chinese-rc/" target="_blank" rel="external">语料地址</a>，可能过段时间会publish出来）</p>
<p>第一个部分是从人民日报获取的新闻语料，构建方法比较简单，先用POS工具对每篇新闻的词性进行标注，选择出现过两次以上的名词作为候选答案词。从候选词总随机选择一个词作为答案词，用包含答案词的句子作为问题query，剩下的部分作为document，从而构造出一个<document,query,answer>对。这种做法的好处是基于一个不太多的语料都可以构建出大量的<document,query,answer>对用来训练，这样也迎合了deep learning的需求。</document,query,answer></document,query,answer></p>
<p>第二个部分也是非常有意思的部分，就是提出了用一个训练数据领域外的数据集作为测试集，构造的方法分为两种，一种是自动的方法和第一部分相同，第二种是基于人工的提问，而且是对于机器来说难度较大的问题。之所以采用领域外的数据进行测试，是为了防止新闻数据中很多问题可以通过外部知识库来进行回答，导致问题变得简单，如果用一个儿童读物的数据作为测试集，就会将这个问题变得更加纯粹和有挑战性。</p>
<p>既然提出了新数据，baseline模型也省不了，本文提出的模型叫Consensus Attention Sum Reader，没有太多的新东西，效果也没有之前文章中Gate Attention Reader和Iterative Alternating Attention那么好，所以就不再介绍了。</p>
<p>训练数据的自动标注和生成是deep learning应用的关键，很多领域发展缓慢或者在工程中应用不好都是因为data的量不够多，且没有太多好的方法来生成或者标注。机器阅读这个领域，相对来说，dataset的自动构建还是很容易做的，操作也比较简单，抠掉一个核心词就可以。而bot，自动文摘，在实际的工程应用中都难以用流行的data driven方案来解决，因为代价太大了。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-11T03:06:42.000Z"><a href="/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/">2016-07-11</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/11/A-Diversity-Promoting-Objective-Function-for-Neural-Conversation-Models-PaperWeekly/">A Diversity-Promoting Objective Function for Neural Conversation Models #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本篇分享的文章是前一篇分享<a href="http://rsarxiv.github.io/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model</a>的pre-paper，题目是<a href="http://arxiv.org/pdf/1510.03055v1.pdf" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models</a>，作者是Jiwei Li，最早于2015年10月11日发在arxiv上。</p>
<p>本文针对的问题是seq2seq方案在解决bot问题上容易生成一些“呵呵”的reply，比如“I don’t know”之类的非常safe，grammatical的reply，但是营养太少，没有太多实际的意义。造成这种情况的原因是目标函数不合适，在最近流行的自然语言生成任务中一般都采用MLE作为目标函数，这个目标函数可以保证生成出最自然的语言，但diversity太差，当然如果在decoding部分生成大量的N-best list的话，也是有很多不错的reply但都排名很靠后。</p>
<p>本文就是针对这样的一个问题，提出了用Maximum Mutual Information（MMI）作为目标函数来提高reply的diversity和实用性。MMI这个目标函数在Jiwei Li的多篇文章中都出现过，他很喜欢用这个来代替MLE作为目标函数来解决问题。互信息的方程如下：</p>
<p><img src="media/1.png" alt="1"></p>
<p>经过简单的推导，可得出下式作为目标函数：</p>
<p><img src="media/2.png" alt="2"></p>
<p>而，一般的seq2seq采用MLE，如下式：</p>
<p><img src="media/4.png" alt="4"></p>
<p>本文方法比传统seq2seq多了后面的一项。</p>
<p>p(T)其实是一个语言模型，为了在目标中控制reply的多样性，添加一个惩罚系数，如下式：</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>这个式子记作(4)，经过简单的推导得到下式：</p>
<p><img src="media/5.png" alt="5"></p>
<p>记作(5)</p>
<p>作者根据式子(4)和(5)提出了两种MMI，分别是MMI-antiLM和MMI-bidi。</p>
<p>首先是antiLM，单看-log p(T)这一项，其实就是一个语言模型，anti表示反着的，因为有个负号。这一项不仅仅可以影响到你生成reply的diversity，同时也可以影响到你生成的reply是否是grammatical的，其实是一把双刃剑，需要做好控制，一般来说lambda小于1之后，后一项的影响相对较小了。</p>
<p>本文用一个带权重的语言模型U(T)来替换当前的p(T)，如下式：</p>
<p><img src="media/6.png" alt="6"></p>
<p>这里g(k)是权重，k是index，g(k)的特点是随着k的增加单调递减。这样做有两个目的：</p>
<p>1、decoding时对先生成的词的惩罚比后生成的词的惩罚对diversity的影响更大。</p>
<p>2、随着decoding部分的输入对后续生成影响的减弱，语言模型U(T)将会占主导地位，reply后面的部分也会非常grammatical。</p>
<p>bidi这个目标函数的思路是，先从第一项来生成N-Best List，然后用第二项对其进行排序，将diversity更好的reply放在前面。</p>
<p>在训练过程中，仍旧是采用MLE，但在测试的时候，用本文提到的MMI来做测试。</p>
<p>这个结果是由MMI-antiLM产生的：</p>
<p><img src="media/7.png" alt="7"></p>
<p>这个结果是MMI-bidi产生的：</p>
<p><img src="media/8.png" alt="8"></p>
<p>生成的reply确实seq2seq更加有营养。</p>
<p>本文解决问题的一个思路是很有借鉴意义的，正如abstractive summarization中有一篇paper用MRT来替换传统的MLE作为目标函数，将评价指标考虑进了目标函数中进行优化，起码在benchmark上得到非常好的结果。这其实是一条不错的路，就是将你当前的评价指标融入到你的优化目标中进行优化学习，自然会得到比单纯地用MLE来优化要好的多，也有很多的paper在用这样的思路解决问题。我们不仅仅满足于可以生成一个grammatical的reply，我们更需要的是有意义的、有实际使用价值的bot。另外就是具体到目标函数的建模，如果你希望目标中减小哪些因素对目标的影响，就增加一项惩罚项，这也是做优化时候的一般方案，但在解决具体问题时会非常有效。本文虽然针对的是bot reply的生成问题，其实可以推广到一般的自然语言生成问题上来，只是要涉及到MLE做生成都可以换成本文的方法来提升相应的指标。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-10T02:29:40.000Z"><a href="/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">2016-07-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/10/A-Persona-Based-Neural-Conversation-Model-PaperWeekly/">A Persona-Based Neural Conversation Model #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文将分享的paper在生成对话时考虑了user identity，解决了多轮对话中response不一致的问题，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>同样的问题，换一种问法之后得到了不同的答案，而且答案不一致。paper的题目是<a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a>，作者是来自斯坦福的博士生Jiwei Li，他是一个非常高产的作者，很多文章质量都非常不错。文章最早在2016年6月8日在arxiv上发出。</p>
<p>本文针对的问题是开头说的多轮对话中response不一致的问题，这个问题很关键，多轮对话在工程应用中的意义更大，一致性是一个基础问题，解决不好，效果就会非常地差。本文针对这个问题，将user identity（比如背景信息、用户画像，年龄等信息）考虑到model中，构建出一个个性化的seq2seq模型，为不同的user，以及同一个user对不同的对象对话生成不同风格的response。</p>
<p><img src="media/2.png" alt="2"></p>
<p>本文一共提出两个模型，一个是Speaker Model，一个是Speaker-Addressee Model。</p>
<p>上图是Speaker Model的架构示意图，是一个典型的seq2seq模型，不同的地方在于在decoding部分增加了一个speaker embedding，类似于word embedding，只是说对用户进行建模。因为无法对用户的信息显式地进行建模，所以用了一种embedding的方法，通过训练来得到speaker向量，下面左边的图是speaker向量在二维平面上的表示，具有相似背景信息的user就会很接近，与word向量一个道理。decoding部分计算lstm各个gate用下式，vi表示speaker embedding。</p>
<p><img src="media/3.png" alt="3"></p>
<p>第二个模型是Speaker-Addressee Model，这个模型与上一个模型思想是一致的，只是考虑了一种更加细致的情况，在多人多轮对话（电视剧）中，每个人对不同的人说话style是不同的，所以应该在这类问题中需要考虑说话的对象，用V(i,j)来表示speaker i和j之间的这种关系，decoding部分计算如下式：</p>
<p><img src="media/4.png" alt="4"></p>
<p>seq2seq模型在最后的生成过程中，经常遇到一个问题，就是生成一些“呵呵”的话，就是指一些常见的、安全的但没有什么营养的话。针对这个问题，本文用beam search生成一个的N-Best List，用一些规则来重新排序得到更好的结果。</p>
<p>训练语料这块，第一个模型主要是依靠Twitter的数据，第二个模型是依靠电视剧的剧本数据。关于语料这块，它是一个非常重要的问题，甚至是决定了你能够用deep learning技术来解决某个具体问题的关键。开放域的bot数据充分，但模型还有待提高；闭域的bot数据匮乏，虽然可以解决实际问题，但开发成本太高，而且横向扩展性很差，基本上都是针对一个客户做一个系统，可复用的地方并不多，大量的人工feature需要花费大量的人力、物力、财力来做，所以这个问题也是bot在实际应用中难以使用deep learning的最大原因。有一种思路是用增强学习来造数据，但前提是你得有一个质量不错的生成模型，才能不断地自学习，这个问题便成了一个先有鸡先有蛋的问题，是一个死循环。</p>
<p>下图展示了Speaker Model在解决多轮对话一致性问题上的突出表现，User1采用了本文模型，User2是普通的seq2seq模型。</p>
<p><img src="media/5.png" alt="5"></p>
<p>将用户信息建模是一个必要的部分，从本文的结果来看确实有更好的效果。多轮对话不仅仅是考虑用户信息，还要考虑大量的上下文信息，或者说是历史信息，尤其是对于具体的企业客服来说，历史信息和用户信息都非常重要。当然如果是娱乐用的机器人，用户的情绪也是一个非常有意思的信息，情感分析已经有不错的正确率，所以考虑人的情绪也是一件非常好玩的事情。本文用了类似于word embedding的思路，对user infomation进行建模表示，同样的思路可以用于情绪、上下文信息中。我相信context的建模应该也有很多人在做，后续的paper也一定会读到，届时再分享。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-09T12:42:57.000Z"><a href="/2016/07/09/A-Dataset-for-Research-on-Short-Text-Conversation-PaperWeekly/">2016-07-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/09/A-Dataset-for-Research-on-Short-Text-Conversation-PaperWeekly/">A Dataset for Research on Short-Text Conversation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是一篇2013年的bot文章，题目是<a href="http://staff.ustc.edu.cn/~cheneh/paper_pdf/2013/HaoWang.pdf" target="_blank" rel="external">A Dataset for Research on Short-Text Conversation</a>，作者来自中科大和华为诺亚方舟实验室。</p>
<p>本文最大的贡献在于release出一个大型短文本对话语料，并且提出了一种基于检索的对话生成模型。到底是否是第一个用检索的方式来解决bot问题我不得而知，可以确定的一点是很多现在活跃在市面上的“逗逼”bot都是基于这个模型做的。</p>
<p>语料的数据来自于新浪微博，大概的收集过程如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p>首先选择10个NLP领域比较活跃的用户，然后依次作为种子用户，进行爬取，直到获得3200与NLP和ML相关的用户，然后抓取每个用户的微博和下面的评论，时间跨度为2个月。这样定向爬取的好处是选择的用户和所发表的微博涉及的领域比较窄，而不至于天马行空什么都有。</p>
<p><img src="media/2.png" alt="2"></p>
<p>数据准备好了之后，就是模型部分。模型一共分为两步，第一步是选择出评论候选列表，第二步是在候选列表中进行排序。候选列表选择一共分为三个baseline模型，如下：</p>
<p>1、Post-Response Semantic Matching</p>
<p>根据微博和评论之间的语义匹配程度选择出10个候选评论。</p>
<p>2、Post-Response Similarity</p>
<p>根据微博和评论之间的相似度选择出10个候选评论。</p>
<p>3、Post-Post Similarity</p>
<p>根据微博和微博之间的相似度选择出10个候选评论，即用相似微博的评论作为候选评论。</p>
<p>给定一条微博之后，模型会通过三个baseline各选择10条评论，构成一个&lt;=30的评论候选列表，然后进行标注。标注工作是将评论分为两类，即suitable和unsuitable，即正样和负样。判断一个评论是否是suitable一共有三个准则：（1）semantic relevance，这个准则是判断微博和评论是否语义相关；（2）logic consistency，这个准则是判断微博和评论是否在逻辑上是一致的；（3）speech act alignment，这个准则是判断微博和评论在act方面是否是对齐的。</p>
<p>接下来就是通过标注数据进行排序，排序学习的目标是让正例的score比负例的score更大。</p>
<p>基于检索的bot解决方案是一种常见的方案，这种方案的重点在于知识库的质量，也就是那个database，一个query对应多个reply。如果只是简单的对话，效果会不错，而且如果知识库很有特点的话，reply经常会有一些意想不到的好玩的话，小黄鸡当年在人人网上火了好一阵子。但稍微复杂的问题，知识库的应变能力差的缺点就暴露出来了，比如query中有named entity，并且这个entity在知识库中没有出现过，这时reply就会出现牛头不对马嘴的情况，解决单轮对话都存在很大的缺陷，那么解决多轮对话就会更困难。虽然说，可以通过做query和reply、query和query之间语义层面相似度的计算，比如用一些成熟的deep learning技术来做。但根本上并没有解决这种方法的弊端，倒是非常垂直的闭域bot可以考虑用这个方案加上一些策略来解决，比如企业客服bot，因为知识库规模小，根据企业的资料和一些过往的用户对话数据可以建设一个质量不错的知识库，从而得到质量不错的bot。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-09T10:08:36.000Z"><a href="/2016/07/09/Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation-PaperWeekly/">2016-07-09</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/09/Sequence-to-Backward-and-Forward-Sequences-A-Content-Introducing-Approach-to-Generative-Short-Text-Conversation-PaperWeekly/">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>从今天开始后面的paper都与bot有关，除非arXiv刷出一些好玩的paper。本文是<a href="http://cn.arxiv.org/pdf/1607.00970" target="_blank" rel="external">Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation</a>，2016年7月4日发在arxiv上，作者是来自北京大学的博士生<a href="http://sei.pku.edu.cn/~moull12/" target="_blank" rel="external">Lili Mou</a>。</p>
<p>这里所讲的bot是指chat bot，也是当下研究领域最火的应用之一。在实际的工程应用中使用的方法可以分为两类，基于rule、template的和基于database query的，应用范围比较窄，比如垂直领域的客服机器人，解决的问题通常都是一个闭域的问题；而真正的AI是应该可以解决开域问题的，无论问什么样的问题，都会得到一个满意的答案，当然，现在的研究水平还难以达到这样的境界。最近几年随着深度学习技术的火热，nlp领域中很多任务都得到了长足的进步，现在最流行的解决方案是seq2seq，尤其是在自然语言生成任务中得到了广泛的应用。简单bot的问题可以理解为给定一个query，生成一个reply，这样的bot是single turn，研究意义大于应用意义。更多的实际问题都是一个multi turn问题，以客服bot为例，单轮对话很难解决了客户的疑问，一般都是通过多轮对话来帮助用户得到满意的答复。关于多轮bot的文章，后面会慢慢涉及到，今天分享的paper是关于单轮、短文本的对话生成。</p>
<p>生成式的bot比起基于rule、template和database query的bot具有更加灵活的特点，不仅仅拘泥于现有的rule、template和database，而是可以生成更加多样性的reply。但生成式的bot也有一个非常显著的问题，就是经常生成一些非常“呵呵”的reply，比如“我不知道”，“我也是”等等没有营养但绝对“安全”的话，导致了这种bot没有什么实用价值。产生这个问题可能有两个原因：一是在decoder部分以log概率最大为目标，而不是别的目标，所以容易生成一些没有意义的人类语言，因为训练语料中这样无意义的reply会经常出现，用deep learning从data中抓feature的时候就会出现这样的问题；二是query的信息量太少，encoder捕捉的意思有限，导致了生成“呵呵”的reply。</p>
<p>本文旨在提出一种叫做content introducing的方法来生成短文本reply，一共分为两个step，如下图：</p>
<p><img src="media/1.png" alt="1"></p>
<p><b>step 1</b> 给定query之后，预测一个keyword作为reply的topic，这个topic词性是名词，这里的keyword并不能捕捉复杂的语义和语法，而只是根据query的每个词来预估出一个PMI（Pointwise Mutual Information）最高的名词作为keyword，两个单词之间的PMI由下式计算：</p>
<p><img src="media/2.png" alt="2"></p>
<p>每个单词与query之间的PMI由下式计算：</p>
<p><img src="media/3-1.png" alt="3"></p>
<p>虽然数学上不太严谨，但后面的实验表明用这个来计算结果还是不错的。</p>
<p><b>step 2</b> 本文的模型叫做Sequence To Backward and Forward Sequences，首先进行backward step，给定一个query，用encoder表示出来得到一个context，decoder的部分首先给定keyword作为第一个词，然后进行decoding，生成的这部分相当于keyword词前面的部分；接下来进行的是forward step，也是一个典型的seq2seq，用encoder将query表示成context，然后给定backward生成的话和keyword作为decoder的前半部分，继续decoding生成后半部分。整个的流程这样简单描述下：</p>
<p>query + keyword =&gt; backward sequence</p>
<p>query + keyword + backward sequence(reverse) =&gt; forward sequence</p>
<p>reply = backward (reverse) sequence + keyword + forward sequence</p>
<p>传统的seq2seq模型都是从第一个词生成到最后一个词，无法生成指定词，而本文的模型可以生成指定词，并且该词可以出现在reply的任意位置。</p>
<p>数据集是从百度贴吧上爬下来的对话数据，规模有500k的query reply pairs，PMI统计是由100M的query reply paris。结果是与seq2seq进行比较，本文模型得到了更好的结果。下图展示了本文的example：</p>
<p><img src="media/4.png" alt="4"></p>
<p>本文用keyword来做topic的思路是一个很好的思路，会让算法生成的reply更加有营养，这个在单轮的应用背景下可以取得不错的结果。但是本文用topic的思路和处理方法太多简单，如果考虑到多轮对话的问题，我想用上下文信息来预测topic，而不是只考虑该句query的信息，而且不仅仅用一个单词来做topic，可能还会是短语，也可能是语义层面上的topic，而不仅仅是从一个候选列表中选择单词来作为topic。文章的思路很有启发性，我个人认为生成式的bot在闭域中应用是一个大趋势，传统的rule、template、database都会被替代，但真实应用场景中的bot需要将context做好处理，然后作为先验知识，来生成reply。其实难点也就在context的处理上，包括user profile，dialogue history，user current state等等各种context信息。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-08T13:35:03.000Z"><a href="/2016/07/08/生活毕竟不是一场秀/">2016-07-08</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/08/生活毕竟不是一场秀/">生活毕竟不是一场秀</a></h1>
  

    </header>
    <div class="entry">
      
        <p>生活毕竟是生活，生活的本质应该是生活本身，而不是一场秀。事业再好，终究还是为了有一个更好的生活，而家庭是生活中最重要的环节，永远都是应该是最重要的，抛去家庭来谈事业，简直滑稽。</p>
<p>为什么要伪装自己，在别人的面前表现出一个不同的自己？人与人为什么会不平等，就因为你现在处在更好的位置？一堆长者围着一个年轻人转，就因为年轻人是领导的秘书？说好的人生而平等呢？人的特征那么多，为什么只在乎地位这一个feature呢？才华、修养都是人的重要feature，为什么大家在地位面前都变得那么地低三下四呢？这不是生活的意义。</p>
<p>在酒桌之上，在领导面前，在地位和权势面前，为什么大家都变了一个模样？都在表演自己的人生，都在说一些虚伪的假话，都在迎合着一些人的需求。</p>
<p>忘了吗？每个人其实都是独立的，是一个活生生的个体，独立地活在这个世界上。难道家庭和事业比起来不重要吗？我一点都不认同，我觉得人都是平等的、独立的。</p>
<p>感谢我的妻子，我一直觉得自己就像是一只牢笼里的小鸟，在一个非常狭窄的区域内飞来飞去，我自以为我是在广阔的天空里，后来遇到了另外一只美丽的小鸟，带着一起飞，飞向了真正的天空，看到了更大的世界，明白了真正的人生。</p>
<p>我希望自己以后的孩子可以自由自在、不卑不亢地活在这个世界上，并不会因为自己的富有或贫穷而对这个世界和这个世界上的人产生偏见，我希望他爱读书，希望他可以看到更大的世界、真正的世界，而不是为了一个目的和身份苟活在这个世界上。</p>
<p>自由不只是身体上的自由，更是心灵的自由，一种真正的独立和平等，大家不论身份的高低都可以坐在一起进行平等地交流，没有半点虚伪，没有半点惶恐，只有最简单的纯真。</p>
<p>此刻，我想哭，因为有太多的无奈，但此刻，我也想笑，因为未来的生活会更加美好，因为我知道了美好的世界是可以通过自身的努力得来的，而不需要谁的恩赐和施舍。</p>
<p>生活毕竟不是一场秀，而是自己最真实、最纯粹、最华丽的人生。</p>
<p>献给那些生活在种种挣扎中的人们。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-06T09:16:17.000Z"><a href="/2016/07/06/关于创业的几点思考/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/关于创业的几点思考/">关于创业的几点思考</a></h1>
  

    </header>
    <div class="entry">
      
        <p>北京之行非常充实，白天上课，晚上和业界一线的创业者们交流，收获颇丰。自己之前对创业有一些朦胧的感觉和认识，但并不成熟，这次交流之后，有了一个更加清晰的认识，在这里做个总结。</p>
<p>1、SaaS（Software as a Service）+ B2B的模式确实很棒，这里讲的SaaS服务比较狭隘，特指用一些算法和模型来帮助中小企业解决他们解决不了的问题，并不包括工具类的SaaS。这种商业模式对创业团队的学习能力和研发能力有非常高的要求，团队短小精悍，可以快速对问题进行建模，快速开发出原型系统和产品。这种模式可以做成Private解决方案式的业务，此种业务对需求的分析和对自身的定位非常重要，一定要做的非常精和细，抓住企业用户的需求来展开业务；还有一种是做Public，提供算法API供企业用户调用，算是一种平台。SaaS+B2B最关键的是技术能力，不需要太多无关的人。SaaS是一种趋势，你公司中的很多业务其实都是不需要自己来打理，只需要找到做相应工作的SaaS公司即可，比如：会计和税务，报账，HR等等。他们做这个比你更加专业，也比你花钱雇人更加实惠。所以，这个世界是合作的，你做好、做精你的事情，其他耗时但有用的事情可以找专业的人来做，各赚各的钱。</p>
<p>2、创业最难的是人才，是如何招到靠谱的人才。创业公司太多了，而且创业都是在用时间赌未来，不一定会成功，所以对人才的吸引力不如成熟的大公司那么大。初期的招人很难，也很重要，基本上就是从熟人下手，从身边的人下手，或者找一些志同道合的人才。我个人觉得，如果你不是特别急着追一个所谓的创业机会的话，招人这事是宁缺毋滥，就和找女朋友类似，看条件合适不合适根本没用，创业是很实在的事情，合适的人比牛逼的人更加重要，因为牛的人性格一般都不会那么地随性，都是有个性的人，性格合适会让这个团队走向一个正确的方向，而不是说凑了几个大牛校或者海龟，大家听起来title都不错，但合作起来却问题百出。说道人才，我觉得不论什么出身，什么专业背景，只要是学习能力特别强，这里不是说你GPA多少，高考分多少之类的，而是给你一个新的topic，你能在多短的时间对这个topic有一个不错的理解；动手能力特别强，毕竟产品需要编程实现，模型系统也需要编程实现，纸上学来终觉浅嘛；沟通能力特别强，听得懂别人在说什么，也让别人听得懂自己在说什么，谦虚谨慎才会有利于沟通和交流，才会让团队更加高效。</p>
<p>3、创业环境，这一点颠覆了之前的认识。一直不喜欢北京，一个像吸血鬼一样的城市，一个没有生活质量的城市。但不得不说，是最好的创业城市，因为资源都在这里。深圳虽然好，但人才方面相对匮乏，软件创业环境不如北京，可能硬件够好一些吧，做机器人创业的比较适合在那里。和来自硅谷的创业咖聊过之后，感觉美国的创业环境更加规范，毕竟人家做了那么多年，体制机制都非常规范，不会像中国这样出现一些诓骗的事情，违法的成本太高，所以大家都规规矩矩在一个框架内做事情，环境比较纯粹一些。当然，硅谷也面临着招人的问题，创业公司太多，大家都想要最好的人，所以都很难。现在的创业支持和各种资源都非常充分，环境非常好，难的不是找投资，不是组建公司，因为现在有很多的孵化器，各个阶段的孵化器，他们会帮你解决好各种各样的事情，难是难在你自己到底有没有这个能力，做好这件事情。</p>
<p>4、创业方向，我个人关注的是自然语言处理技术，所以对这个方向观察和思考的多一些。首先说，bot热，大热，从arxiv上paper的数量也可以看得出，bot这个领域是最火的，从各大公司对bot研发的投入力度来看，bot是下一个big thing，facebook甚至希望将bot作为入口，代替现在的操作系统，想一想都觉得这个世界是多么地美好和神奇。bot这个大理想非常丰满，现实中nlp技术的不成熟却显得非常骨感，bot paper发的热火朝天，但在工程应用上却难以被用到，世界上最远的距离就是从research到engineering的距离。bot是大趋势，但技术确实不成熟，所以带来了大量的机会，每个有积累、有准备的人都是公平的，大家都有机会在下一个big thing上分一杯羹。让机器来理解和灵活应用人类语言是一件非常难的事情，也是实现true AI中非常关键的一步，所以我看好这个方向。当然，如果你着急开始赚钱，nlp并不适合你，因为nlp是未来。</p>
<p>5、是否该创业，这个问题如果你犹豫了，那么其实也就有了明确的答案。太多的顾虑是做不成一件事情的，不如安心地做好现在的工作，一步一步地在现在的地方踏踏实实地混下去，混到更高的title，直到退休。如果你在这个问题上不犹豫，那么恭喜你，你是天生的创业者，但这离创业成功还有十万八千里。那天问了谷哥（clickstone）为什么创业这个问题，他是这么回答我的，就是想按照自己的方式去努力做成一件事情，得到一个不错的回报，这里的回报更多的是成就感，而不只是money。可能，我们踏踏实实在一家大公司工作，或者在体制内工作，会为很多举世瞩目的事情做出贡献，但个人太微不足道了，在这样的环境中，自己做的事情太小了，能够决策的东西也太少了，就像一颗螺丝钉一样，事情成功了，也没有什么成就感。所以说，做爱做的事情，并且做成。</p>
<p>6、厚积薄发，打好基础，放平心态，不要急着去和谁比较。谷哥说他的同学有的都已经是教授级别了，但近况没那么理想吧，创业者要耐得住寂寞，不去和人比，因为每个人都不一样，拿同一标尺来衡量是很幼稚的事情。既然，选择了这条路，就是要一直走下去，而不是瞻前顾后、犹豫不决。你过去放弃的、现在放弃的种种都会在未来的某一个时间换一种形式回报给你的。</p>
<p>一点思考，欢迎交流。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-06T05:08:50.000Z"><a href="/2016/07/06/cips总结和思考/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/cips总结和思考/">cips总结和思考</a></h1>
  

    </header>
    <div class="entry">
      
        <p>前几天在北京参加了一个深度学习的“速成班”，由中文信息学会（cips）举办的。一共分为四天，上午由一名老师讲授理论和前沿技术的发展情况，下午由一名刚刚毕业的博士讲授用tensorflow来实现上午的部分内容。覆盖的范围包括神经网络与表示学习，以及应用于自然语言处理中的神经网络模型。都是国内一线的老师在讲，所以内容的质量非常高，来参加课程的同学也都非常的热情，去的晚了连个像样的座位都找不到，每次茶歇时间，老师都会被围得水泄不通。</p>
<p>深度学习非常火爆，很多人都在传言学会了深度学习就可以拿到高薪，甚至都可以to be someone，说的神乎其神，将深度学习等价于几十万、几百万的年薪。个人感觉这样的说法并不负责任，有点过度宣传的意思，与之相关的培训班也跟着水涨船高，且不论教学质量如何，确实涌现出了很多的教学、培训班来为学生们提供捷径，质量良莠不齐，学生们觉得上了你这个基础班、提高班之后就会有一份特别棒的工作和薪水。这样的事情有点像迷信神一样，传教士们将舆论造好，说的神乎其神，然后开始传教，让大家来信教，小白们本身就没有太多的判断力，只是单纯地相信传教士们，相信这个世界有捷径通往成功。其实，仔细想一想，怎么可能？不管火的是深度学习还是别的技术，让你能够找到一个不错的工作或者不错的薪水都是需要具备很强的数学基础和编程实现能力，以及超强的学习能力，从而跟得上技术的发展，而不是说跟着几个班学过之后，就能够如何如何。大家盲目地追逐捷径，却忽略了本质问题，实在是令人觉得可笑，微博上总能看到一些懂deep learning的人可以拿到多少多少薪水，会用什么工具或者开发过什么工具的人可以拿到多少多少薪水，这些言论会让大家变得浮躁。虽然说deep learning很火，大家也看的很热闹，那么到底有多少人可以从深层次的角度上或者说数学层面上理解了deep learning？</p>
<p>随波逐流不难，难的是坚持自我。tensorflow很火，所以大家都开始转tensorflow，mxnet在微博上被人转来转去，再加上“mxnet的主创人员都拿到了几百万的年薪”这一微博发出之后，有一种mxnet暗流涌动的感觉。这个问题，我是这么看的，流行确实有流行的原因，但公关的因素也不少，但是往往大家分不清真的好用还是大公司在公关，但工具毕竟是工具，选择了一个趁手的兵器就应该坚持用下去，而不是根据别人的言论而改变自己的初衷。因为工具只是工具，目的就是为了快速地实现模型，得到结果，torch、theano、tf、mxnet、caffee哪种用熟练了，用到了极致都是高手，不需要那么地盲目崇拜。</p>
<p>上面的言论是我自己的一些观点，并不针对特定的人和工具，世上没有偏见，只是角度不同、理解不同产生了偏见。对一个事物的认识和学习，都是要经历一个迷信和质疑的过程，所谓尽信书则不如无书，有自己的观点和态度不仅仅是一个严肃的媒体应该具备的特质，一个有独立思考能力的人都应该有自己的态度和认知。</p>
<p>这次的课程上午的内容都非常的棒，下午的内容个人觉得有一点鸡肋，用tf来实现一些model，像是编程实验课，但课时太短，大家没有太多动手和思考的时间，有一点点填鸭地感觉。编程从来都应该是一个实践课，编程能力都是自己一行一行写出来的，不是从谁那里听来的，从0开始学，照着docs和demo一边写一边学，遇到不懂的地方，在github上发起issue来讨论或者在其他的论坛上进行讨论，step by step地学习，或早或晚地一定会get到这个技能。我个人觉得下午的时间还不如将上午的内容进行更加深入地讲解，因为明显感觉地到上午老师讲的有一点点赶，讲的不够充分和透彻，时间快到了12点的时候，开始慌张地收尾，还真如下午继续讲呢。</p>
<p>学习这个事情，没有什么捷径，理解一个概念，理解一行代码，理解一个框架都需要你扎扎实实地去实践、去体会，不是谁能够给你的。这次所谓的“速成班”就是帮你打开一扇窗，让你在一个更大的空间里来理解这个世界，至于怎么理解和理解地怎么样都只有靠自己。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-07-06T03:49:03.000Z"><a href="/2016/07/06/Towards-Abstraction-from-Extraction-Multiple-Timescale-Gated-Recurrent-Unit-for-Summarization-PaperWeekly/">2016-07-06</a></time>
      
      
  
    <h1 class="title"><a href="/2016/07/06/Towards-Abstraction-from-Extraction-Multiple-Timescale-Gated-Recurrent-Unit-for-Summarization-PaperWeekly/">Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>前几天因为去北京参加中文信息学会组织的深度学习“速成班”，一直都没空更新博客。今天分享的paper是昨天刚刚刷出的一篇关于自动文摘的paper，题目是<a href="http://cn.arxiv.org/pdf/1607.00718v1" target="_blank" rel="external">Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization</a>。</p>
<p>用seq2seq的思路来解决文本摘要问题仍停留在short text的生成水平上，最多到paragraph level。原因也比较简单，rnn也好，gru、lstm也罢，终究都面临着一个长程依赖的问题，虽然说gru、lstm等技术用gate机制在一定程度上缓解了长程依赖和梯度消失、爆炸的问题，但终究文本过长的话，神经网络的深度就会随之变得非常深，训练起来难度就会随之增加。所以，这也是为什么document level或者说multi document level的abstractive式的摘要生成问题至今都是一个难以解决的问题。确实，short text的理解、表示在一定程度上有了很大的突破，也可以在工程上有不错的应用，比如机器翻译。但text变了之后，一篇很长的文章如何更加准确地理解和表示是一个非常难的问题，attention是一个不错的解决方案，在decoder的部分不需要考虑encoder的全部，只需确定需要注意的几个点就可以了，其实人在看一篇长文的时候也是这样一种机制，从某种角度上来讲，attention在decoder时提供了一种降维的手段，让model更能捕捉到关键的信息。</p>
<p>对于document level的abstractive摘要问题，人是怎么做的呢？比如我写了一篇paper，最后写abstract的部分，基本上是从每个section中提炼出key sentences，组成一段abstract，其实这里有一点extractive的意思，但人和extractive不同的地方在于可以轻松地将each sentence连贯地表达出来，看起来不那么僵硬，更加地顺畅，当然也不会出现指示代词找不到实体的情况。本文的思路正是借鉴了人类在解决这个问题时所采用的一般思路，数据源是arxiv paper中的introduction和abstract部分。</p>
<p><img src="media/2.png" alt="2"></p>
<p>将document分解成多个paragraph，然后从每个paragraph中extract出key sentence作为该paragraph的target summary，每个document可以构造出多个(paragraph,key sentence) pair作为seq2seq的训练数据。生成摘要的过程正好相反，将document分解成paragraph，对每个paragraph用model生成summary，将所有的summary拼接起来形成abstract，然后与paper自身的abstract作对比。</p>
<p>这里从paragraph中提取key sentence用了最简单的TF-IDF来打分排序，当然给n个句子排序有很多的方法，比如textrank。(paragraph,key sentence) pair的训练是通过一个叫Multi Timescale Gated Recurrent Unit(MTGRU)模型来做的，这个模型乍一看好新鲜，其实是N年前一个叫做MTRNN模型将RNN替换为GRU的成果，gru、lstm的变种非常的多，本文的这个模型是其中一个，之所以选择用这个模型来解决问题，是因为多个timescale可以在收敛速度上有更大的优势，并且在自然语言这种层次性的问题上有天然的优势。model的结构如下图</p>
<p><img src="media/1.png" alt="1"></p>
<p>在GRU的基础上增加一个时间项tao，用来控制gru的时间尺度，tao越大，表示model可以越好地捕捉序列数据中的slow features，不知道理解的对比对，这里的slow features是不是可以理解为更大的context window，控制着context的颗粒度。MTGRU可以看作是GRU的一般表示，当tao=1时，自动退化为GRU。</p>
<p>与传统的GRU进行了对比实验，证明了该model在speed和performance上均有更好的表现。下图展示了生成的一些结果：</p>
<p><img src="media/3.png" alt="3"></p>
<p>输入的是本文的introduction部分，输出的是每段生成的summary。</p>
<p><img src="media/4.png" alt="4"></p>
<p>这个是本文算法生成的摘要和纯extractive方法的对比，明显比extractive的方法概括地更加全面。</p>
<p>本文是一篇占坑的文章，内容并不完整，提出了MTGRU model来替换一般的GRU，但并不是full data driven，用了一些extractive的手段来辅助进行训练，在文章的future work这部分作者也提到了下一步要做成一个真正的data driven的model，每个paragraph的target summary也是data driven的，而不是用extractive的提取出来的，我在想，是否可以构造一个hierarchy model，一个维度在训练paragraph到sentence的mapping，一个维度在训练document到abstract的mapping，这个idea可以认真琢磨下，也欢迎大家讨论。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-29T02:54:35.000Z"><a href="/2016/06/29/教机器学习表示/">2016-06-29</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/29/教机器学习表示/">教机器学习表示</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>让机器来理解人类语言一直都是人工智能的梦想，从词、短语、句子、段落到文档，每个层次的文本都承载着语义，机器对各个层次文本的理解都需要先对文本进行表示，用机器看的明白的形式来表示。那么，今天就来分享一篇关于表示的综述文章。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>从人类理解文本的角度来看，理解一篇文档需要理解其中的每个段落，而理解段落需要理解每个段落的每句话，理解每句话就得理解每句话中的每个词。所以，表示一篇文档，需要从表示一个词、一句话开始。关于词的表示，在之前很长一段时间都流行的是one-hot模型，每一个词都用一个词表大小的向量表示，向量中该词所在的位置是1，其余都是0，而句子或者文档的表示，以前都是用bag-of-words模型，该文本用一个词表大小的向量表示，向量中的元素表示对应位置的词的个数。这两种经典的模型用了很久，有一些非常明显的缺点，比如：规模太大，太过稀疏，没有考虑词序信息，而词序又是一种非常有用的信息。</p>
<p>终于，在神经网络语言模型的帮助下，词向量（word embedding）出现了[1]，最初词向量是语言模型的一个副产物，后来随着word2vec的热潮，词向量几乎成了NLP中模型的标配，紧接着就是sentence2vec，document2vec，everything2vec，整个世界都被vector表示了。词向量与之前的one-hot模型不同，用了一些低维的、稠密的实数向量来表示，虽然说不清每个维度都表示什么，但用起来效果就是棒。</p>
<p>本文要探讨的问题是如何学习用低维的、稠密的实数向量来表示词、句子和文档。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>对于监督学习来说，需要找到一些分好类的语料进行训练，比如情感分析、新闻分类之类的数据。</p>
<p>对于无监督学习来说，只需要找到大量的文本进行训练即可。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>关于词、句子表示的模型实在是太多了，本文只选择PaperWeekly中读过的paper里的模型。</p>
<p>首先介绍的是词表示模型。</p>
<p><img src="media/14672414619993.png" alt=""></p>
<p>1、CBOW模型[2]</p>
<p>1、2都是word2vec的模型，整体的思路差不多，都是用context来预测word（skip-gram是用word来预测context，把context和word的概念对等交换一下都一样的。），典型的语言模型。之前Bengio[1]的文章提出用词向量来表示一个词，通过前面的n个词来预测下一个词，重点关注的是词的生成情况，并没有对词向量本身进行探讨。而word2vec的作者Tomas Mikolov重点研究的是词向量，并不在意语言模型的部分，所以这里在各种先前研究成果的基础上进行了大量地“偷工减料”，以达到快速求解词向量的目的。</p>
<p>如左图，该模型将每个词赋以一个n维向量初值，将context中的每个词向量求和来表示context，拿来预测目标词，不断地训练得到最终的词向量。</p>
<p>2、SKIP-GRAM模型[2]</p>
<p>如右图，该模型与CBOW类似，只是用word来预测context。</p>
<p>3、GloVe模型[3]</p>
<p>该模型的思路是将全局词-词共现矩阵进行分解，训练得到词向量。整体上的思路和推荐系统当年横扫Netflix百万美元比赛的LFM模型类似，也和信息检索中LSI的思路类似。不同的地方是，本文采用的词-词共现矩阵比起词-文档矩阵更加稠密，模型中对低频词和高频词的影响做了一定地弱化处理。模型的目标函数如下：<br><img src="media/14672420569666.png" alt=""></p>
<p>这里的f(x)是一个权重函数，具有以下的特点：</p>
<p>(a) f(0) = 0</p>
<p>(b) f(x)是增函数，这样低频词不会被over weight。</p>
<p>(c) 当x很大时，f(x)相对小一些，这样高频词也不会被over weight。</p>
<p>根据以上的特点，作者构造了下面的函数：</p>
<p><img src="media/14672421669446.png" alt=""></p>
<p>其次介绍的是句子表示模型。</p>
<p>1、PV-DM模型[4]</p>
<p><img src="media/14672421910018.png" alt=""></p>
<p>句子模型1和2是word2vec作者的进一步工作，乍一看模型和CBOW很像。不同的地方在于，输入中多了一个paragraph vector，可以看做是一个word vector，作用是用来记忆当前上下文所缺失的信息，或者说表征了该段落的主题。这里，所有的词向量在所有段落中都是共用的，而paragraph vector只在当前paragraph中做训练时才相同。后面的过程与word2vec无异。</p>
<p>2、PV-DBOW模型[4]</p>
<p><img src="media/14672422824272.png" alt=""></p>
<p>这个模型看着雨SKIP-GRAM很像。这两个模型都是无监督学习模型，在准备数据时需要给每个paragraph定义一个id，以区分不同的paragraph。</p>
<p>3、Skip Thought Vectors模型[5]</p>
<p><img src="media/14672423416074.png" alt=""></p>
<p>本模型是一个无监督句子表示模型，借鉴了word2vec中skip-gram模型，通过一句话来预测这句话的上一句和下一句。模型采用了当下流行的seq2seq框架，通过搜集了大量的小说作为训练数据集，将得到的模型中encoder部分作为feature extractor，可以给任意句子生成vector。</p>
<p>4、Sequence AutoEncoder LSTM模型[9]</p>
<p><img src="media/14672434462899.png" alt=""></p>
<p>该模型利用自编码器来进行sentence表示，从图中可以看得出是一种端到端的学习，只不过这里的input和target是同一句话。模型中用LSTM来对文本进行建模，整个过程和之前分享的seq2seq并无区别，属于比较简单的模型。</p>
<p>5、Hierarchical Attention AutoEncoder模型[8]</p>
<p><img src="media/14672435940204.png" alt=""></p>
<p>这个模型在模型4的基础上，用了分层和注意力的思想，更加复杂。在encoder部分，对每一个word进行表示，同时也对每一个sentence进行表示，用每句话最后一个词的state作为该句子的state，并且将每句话的表示综合起来作为整个输入的输出，也就是context。在decoder部分，生成词的时候会使用attention机制，在确定和input中哪句话的关系更加密切。</p>
<p>6、CNN模型[6]</p>
<p><img src="media/14672428840879.png" alt=""></p>
<p>这个模型是CNN在NLP中得到应用的一个比较早的模型，也是一个有监督模型。用一个k维向量表示一个词之后，很容易将一句话表示成一个矩阵，矩阵中的每一行都是一个词向量。那么既然得到了矩阵表示，很容易套用CNN在二维图像中的处理方法，一层层地堆叠起来，得到sentence的表示。只是说卷积窗口的选择，有两种思路，一种是窗口大小就是k，每一次卷积其实就相当于从n-gram中提取feature；另外一种思路是窗口大小小于k，和CNN处理图像类似的思路，从几个词的不同部分来提取feature。本模型采用的是第一种方式。</p>
<p>7、RCNN模型[7]</p>
<p><img src="media/14672425700988.png" alt=""></p>
<p>该模型是一个RNN和CNN的组合模型，CNN的卷积层用一个双向RNN模型来做，既用双向RNN弥补了CNN模型卷积窗口大小固定的问题，又利用了CNN提取feature的强大能力。这个模型也非常好地体现了deep learning模型的灵活性和组合性，不同类型的single模型通过一定的方式进行组合，可以衍生出多种多样的模型，很难从理论上讲哪个模型会更好，因为single模型都各有各的优点和缺点。该模型是一个有监督模型。</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>本文只对比一下各个sentence表示模型的结果。</p>
<ul>
<li>Stanford Sentiment Treebank Dataset<br><img src="media/fig3.png" alt="fig3"></li>
</ul>
<p>在这个数据集上，居然是无监督的Paragraph Vector模型效果最好，虽然也好不到哪里去，但至少不比有监督学习的模型差。</p>
<ul>
<li><p>多种分类数据集<br><img src="media/fig2-1.png" alt="fig2"><br>这里的评价指标是分类正确率，从结果上看CNN作为一个有监督学习的模型好于另外两个无监督的模型，仅仅在SUBJ这个数据集上稍落后于skip thought vectors模型。</p>
</li>
<li><p>对比CNN和RCNN[7]<br><img src="media/fig1.png" alt="fig1"><br>这个对比结果来自RCNN模型的paper，很显然RCNN在作者选的几个数据集上都由于CNN，可以大胆推测一下，RCNN应该在第二类数据集上也能优于无监督模型。</p>
</li>
</ul>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>词表示、句子表示等各种层次上的表示有着各种各样的模型，几乎在arxiv上每天都可以刷出一篇文章是做这方面的，都说自己的模型是state-of-the-art。对于这个领域，我有下面几点思考：</p>
<p>1、关于对比结果的事情。数据集的不同、数据规模的不同、模型的不同、模型超参数的不同都会导致不同的结果和结论，在对比的过程中，我们往往是用尽浑身解数调出最好的参数给出一个最好结果，而对于对比的模型，往往就没有这么上心了，复现别人的模型或者用别人开源的代码来对比的时候，可能很难调出该作者模型的最优参数，所以每篇paper的结果也总是有一些出入，从上面的结果中也能看得出，同一个数据集，在不同paper作者复现下结果也是不同的。而且，对比的结果与所选的数据集也有很大的关系，有的模型在某一些数据集上表现非常好，然而在另外一些上就不那么尽如人意了，这也是一个对比的技巧吧，但真正在工程应用上，还是需要在自己的数据上做对比实验，而不是用所谓的“理论”来剖析哪种模型更牛逼。因为毕竟deep learning是data driven的模型，效果的好坏与数据有着直接的关系。</p>
<p>2、读了一些paper之后，看过很多别人的思路和model，有一个感觉就是思维一定要更宽一些。单模型效果一般的时候，可以考虑试一下组合模型，比如RCNN，可以考虑下端到端模型，比如Autoencoder和skip thought vector，可以考虑下分层模型，比如Hierarchical Autoencoder。无监督模型效果一般的时候，可以考虑用无监督作初值，代入到有监督模型中进行训练，一般来说会比纯粹的有监督或者无监督模型效果更好一些。模型看多了，就会有一种感觉，做什么事情的时候，可选的东西就会特别多，思路就会特别多，所谓精神病人思路广吧。</p>
<p>3、词向量的用法，得到一个好的词表示之后，可以用来做什么呢？首先可以继续表示句子，段落，然后做分类也好，计算相似度也罢；其次，可能会有一些比较好玩的东西，比如我用word2vec给自己之前写的应用rsarxiv（一个arxiv paper的推荐系统）做了一个paper knowledge graph，把author，subject，keywords连成了一张大图，在推荐paper的同时可以推荐其他的一些metadata，带来了更好的用户体验。同样的道理，有的人用这个来做app推荐，也有不错的效果。所以，我在想，一个模型其实不仅仅是一个用于特定事情的模型，如果你有很强的抽象问题的能力，你可以看得穿问题的本质，就可以很容易地将特定领域的模型应用于其他领域，有可能还会形成突破。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1301.3781v3.pdf" target="_blank" rel="external">Efficient Estimation of Word Representations in Vector Space</a></p>
<p>[3] <a href="http://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="external">GloVe: Global Vectors for Word Representation</a></p>
<p>[4] <a href="http://cn.arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="external">Distributed Representations of Sentences and Documents</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1506.06726v1.pdf" target="_blank" rel="external">Skip-Thought Vectors</a></p>
<p>[6] <a href="http://cn.arxiv.org/pdf/1408.5882.pdf" target="_blank" rel="external">Convolutional Neural Networks for Sentence Classification</a></p>
<p>[7] <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9745/9552" target="_blank" rel="external">Recurrent Convolutional Neural Networks for Text Classification</a></p>
<p>[8] <a href="http://arxiv.org/pdf/1506.01057.pdf" target="_blank" rel="external">A Hierarchical Neural Autoencoder for Paragraphs and Documents</a></p>
<p>[9] <a href="http://arxiv.org/pdf/1511.01432.pdf" target="_blank" rel="external">Semi-supervised Sequence Learning</a></p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-28T08:40:40.000Z"><a href="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/">2016-06-28</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/">Deep Reinforcement Learning with a Natural Language Action Space #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文继续分享一篇深度增强学习在NLP中应用的paper，题目是<a href="http://arxiv.org/pdf/1511.04636v5.pdf" target="_blank" rel="external">Deep Reinforcement Learning with a Natural Language Action Space</a>，作者是来自微软的<a href="http://washington.academia.edu/JiHe" target="_blank" rel="external">Ji He</a>博士，文章最早于2015年11月发在arxiv上，2016年6月8号update。</p>
<p>通过前两篇文章的介绍，基本对DQN在NLP中应用有了一个清晰的认识，与DQN之前应用不同的地方在于两个方面：</p>
<p>1、actions的量级很大。</p>
<p>2、transition tuple的具体形式随着模型来变化。</p>
<p>本文也是以text games为研究背景，将输入从state变为(state,action)对，提出了Deep Reinforcement Relevant Network(DRRN)模型。</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig1.png" width="600" height="600">
<p>上图中，前两个是baseline模型，第三个是本文模型，理解起来都比较简单。</p>
<p>(a) Max-action DQN</p>
<p>该模型适用于每一个transition中actions的最大数量是已知的情况，将每个transition中state和actions拼接成一个向量作为输入，通过一个Deep Network得到每个action的Q值。</p>
<p>(b) Per-action DQN</p>
<p>该模型将每一对(state,action)拼接成一个向量作为输入，通过network得到每个action的Q值。</p>
<p>(c) DRRN</p>
<p>本文模型分别将每对(state,action)中的state和action单独构建network，分别学习出不同的表示，然后用一种逐元素操作方法得到Q值，比如对两个向量作内积。这里，state往往是一个比较长的文本，可能是几句话，而action一般来说是一个动词短语，通过不同的网络结构进行学习，得到相同维度的表示，然后做内积，内积就是相似度的一种表征，也就是本文模型中的relevant。</p>
<p>其实，对比着看不同DRL paper，只需要仔细对比看算法流程图，就知道哪些地方不同了，本文的如下图：</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig2.png" width="600" height="600">
<p>本文算法中还有一个不同的地方在于，在策略选择上的trade-off，一般的方法均采用ε-greedy策略，本文用了一种softmax selection的方法来做exploration（对应着ε）策略，根据下面计算出的概率来进行选择：</p>
<img src="/2016/06/28/Deep-Reinforcement-Learning-with-a-Natural-Language-Action-Space-PaperWeekly/fig3.png" width="200" height="200">
<p>本文模型最大的优点在于可以处理比较复杂的action，不像<a href="http://rsarxiv.github.io/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/">Language Understanding for Text-based Games using Deep Reinforcement Learning</a>文章中只能处理一个action word加一个object word组成的command。</p>
<p>本文考虑问题的角度不同，不是传统RL给定一个state，然后通过一个最优的Q来确定一个最优的action，而是将state和action放在一个层面上来做计算，虽然最后也是通过最优的Q来选择action，但通过用action和state的相关性来计算Q，使得其具有更广的应用前景。</p>
<p>这是DQN在NLP中应用系列的最后一篇文章，文章数量比较少，所以不写综述了。整体的感觉是，应用还不太多，也没有看到特别惊艳的表现。不过，可以无穷无尽地构造训练用的样本是一个非常大的优点。三篇文章有两篇是研究text games的，只有一篇是做text generation的，并且DQN的痕迹很重，都是依着同一个框架进行修改和适应，并没有很多特别的地方。很期待，后面的研究可以将Deep Reinforcement Learning在NLP的各个任务中进行应用，像seq2seq+attention模型那样横扫整个NLP任务。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-28T02:19:32.000Z"><a href="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/">2016-06-28</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/">Generating Text with Deep Reinforcement Learning #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>上一篇介绍了DQN在文字游戏中的应用，本文将分享一篇DQN在文本生成中的应用，将一个领域的知识迁移到其他领域应用的时候，都需要做概念上的等效替换，比如context可以替换为state，被预测的word可以替换为action。本文分享的题目是<a href="http://arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a>，作者是来自National Research Council of Canada的<a href="http://www.site.uottawa.ca/~hguo028/mainpage.htm" target="_blank" rel="external">Hongyu Guo</a>研究员，文章最早于2015年10月30日submit在arxiv上。</p>
<p>语言模型往往用来生成文本，在很多例子中都有应用，比如：自动文摘、bot、机器翻译、QA等等。本文想要做的事情是用DQN来生成文本，起到一个语言模型的作用，并且这是第一次尝试用DQN来生成文本。仔细想想，DQN在解决video games时遇到的情况和现在不同，state可能还好，可生成的action数量远远大于游戏中action的数量，所以，如何解决action的问题对于DQN在NLP中的应用前景至关重要。目前来看，读此类的paper，需要关注的有两个部分：</p>
<p>1、action规模的问题如何解决？</p>
<p>2、DQN中每条数据集包含的元素与NLP问题中各个元素的对应关系。</p>
<p>本文解决第一个问题采用的方法是，用传统的语言模型decoder来为DQN的action生成candidated actions，虽然这个actions集合是动态，但对于每一条数据来说，action的数量只有很少了，与video games差不太多了。</p>
<p>NLP不像video games直接可以用游戏画面作为输入，用多层CNN提取feature进行action选择，因为text不仅仅是一个序列，而且是变长度的，所以一般来说也都是RNN来处理。本文模型如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig1.png" width="600" height="500">
<p>首先，回答关心的第二个问题，DQN中各元素的对应关系（transition tuple）。</p>
<p>DQN中：(s(t),a(t),r(t),s(t+1))<br>本文：([EnSen(t),DeSen(t)],y(t),r(t),[EnSen(t),DeSen(t+1)])</p>
<p>整个模型是一个迭代decoding的过程，通过LSTM decoder生成最初的DeSen(t)之后，开始不断地迭代。在decoder的每一个time step，DQN会从DeLSTM使用的词表中选择一个可以获得最大reward的action作为该time step新生成的词，用这个新词来代替之前的旧词，生成新的状态DeSen(t+1)，依次迭代下去，每一次迭代都只生成一个新词来代替旧词，直到最后一个新词被生成。这里的reward r(t)是计算target sentence和DeSen(t+1)的相似度得来的。</p>
<p>本文在这个模型的基础上，尝试了在decoder部分用双向的LSTM来表示，并且用一个光滑的BLEU来做reward。这一点与<a href="http://rsarxiv.github.io/2016/05/17/%E8%87%AA%E5%8A%A8%E6%96%87%E6%91%98%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89/">Neural Headline Generation with Minimum Risk Training</a>这篇文章从某一个角度来说有一点点类似，本文是用最终的评价指标BLEU作为reward，而那篇文章是用ROUGE指标作为优化函数，最终取得了非常令人满意的结果。</p>
<p>整个算法流程大体上都是遵循DQN的框架，只是细节有一些不同，如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig2.png" width="600" height="600">
<p>实验部分，用了10000个sentences作为训练集，source和target是一样的，是一个autoencoder问题，对比了只用LSTM decoder和本文模型的结果，如下表：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig3.png" width="300" height="300">
<p>验证了本文方法的有效性。</p>
<p>本文较前一篇文字游戏的文章更难的一点是处理大量actions的方法，上一篇其实仍旧是个游戏，actions的数量在一个非常有限的范围内，本篇是做语言模型的，actions和词汇表一样大，这是DQN在NLP中应用最头疼的问题。本文用了DeLSTM在每个time step中使用的Top N个词作为候选actions，很好地解决了这个问题，那么到底有没有更好的方法来减少actions呢？有没有不需要用这么复杂的模型来做处理呢？想到一个idea，用char-level来做语言模型，用到的vocabulary size远远小于word-level，对于DQN来说，actions集合非常固定，并且非常小，只是增大了state的表示。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-27T00:30:10.000Z"><a href="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/">2016-06-27</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/">Language Understanding for Text-based Games using Deep Reinforcement Learning #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>继上上周的机器阅读理解和上周的自动文摘分享之后，本周开始分享几篇Deep Reinforcement Learning在NLP中应用的paper。在网上看到过这样的言论，一些大牛认为深度增强学习是人工智能研究的未来，是真正的AI，还给出了一个这样的公式：DL+RL=AI。其实，增强学习一直都是机器学习中常用的一种无监督学习方法，随着deepmind公司的一些好玩的成果，比如：用程序来玩简单的video games，AlphaGo战胜李世乭等等，深度增强学习随之兴起。今天将分享的paper是<a href="http://arxiv.org/pdf/1506.08941v2.pdf" target="_blank" rel="external">Language Understanding for Text-based Games using Deep Reinforcement Learning</a>，作者是来自麻省理工学院的博士生<a href="http://people.csail.mit.edu/karthikn/" target="_blank" rel="external">Karthik Narasimhan</a>和<a href="http://tejask.com/" target="_blank" rel="external">Tejas Kulkarni</a>，文章最早于2015年6月30日刊在arxiv上。</p>
<p>在介绍深度增强学习在NLP中的应用之前，需要简单介绍下增强学习和深度增强学习。</p>
<img src="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/fig1.png" width="600" height="500">
<p>上图来自于deepmind David Silver的slide。</p>
<p>图中的大脑可以理解为一个agent，并且这个agent有一个action集合，地球可以理解为environment，并且environment每个time step都有一个状态state。增强学习想要做的一件事情是agent在某一个time step中接收来自environment的state，执行一个action，然后从environment中得到一个reward，根据state和reward继续选择一个action，目标是使得reward最大。整个过程是一个不断交互和反馈的控制过程，通过引入值函数Q(s,a)来计算当前state和action对应的未来所有reward的期望，这里涉及到一些细节，推荐看<a href="https://zhuanlan.zhihu.com/intelligentunit" target="_blank" rel="external">智能单元知乎专栏</a>的系列博客《DQN从入门到放弃》，包括Bellman Equation、多种增强学习模型、ε-greedy policy等等内容。</p>
<p>深度增强学习，这里专指DQN（Deep Q-Network），是将深度学习模型引入到了传统的Q-Network中，用深度神经网络来近似Q函数，构造输入和输出数据，进行端到端的训练来学习这个问题。deepmind那两篇有名的paper，<a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank" rel="external">Playing Atari with Deep Reinforcement Learning</a>和<a href="https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf" target="_blank" rel="external">Human-level control through deep reinforcement learning</a>，第一篇最早提出了DQN的方法，另一篇提升了第一篇的模型，并且发表在了nature上，deepmind做的事情都是用计算机程序来玩video games，并且在多个游戏中取得了比人类玩家更好的成绩。由于都需要处理游戏画面，所以encoder部分都是采用多层CNN提取feature。</p>
<p>简单介绍了一些预备的内容之后，下面来介绍本文的内容。本文是基于一个文字游戏来展开的，通过text state，通常是一段比较长的介绍性文字，来给出一个合适的action进入下一个state。如下图：</p>
<img src="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/fig2.png" width="400" height="400">
<p>上图中从state1 <b>The old bridge</b>通过选择<b>Go east</b>这个动作进入了state 2 <b>Ruined gatehouse</b>。</p>
<p>如果对DQN的相关东西有所了解的话，本文的模型就显得非常简单了。</p>
<img src="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/fig3.png" width="400" height="400">
<p>模型分为两个部分，第一部分是representation generator，将state中的text用lstm处理，每个word对应一个time step，然后将所有time step的向量做一次平均池化处理，得到该状态的表示。video games因为输入的是游戏图像，所以用cnn来处理，而text games都是文字，用rnn来处理也最合适不过的了。另外一点是，本文也考虑过用lstm的last hidden state作为state的表示，但收敛速度没有平均池化快。</p>
<p>第二部分是action scorer，就是一个多层的神经网络，用state的表示作为输入，得到的输出是集合中每个action的score，而不是每一对action-state的score，这样的计算效率更高一些。</p>
<p>由此用神经网络模型近似得到了Q函数。本文特点强调了一点，为了保证计算效果，只选取游戏命令是一个action（比如：go）和一个object（比如：east）的组合，当然这一类命令也占据了游戏命令的绝大多数。从模型图中可以看出，计算action和object是同样的结构，最终该命令的Q值由action和object的Q值由两者的平均值来代替。</p>
<p>关于训练方法，和DQN也区别不大。最关键的一点是构造训练数据集，每一条数据格式是(s(t-1),a(t-1),r(t-1),s(t))，每次进行游戏的时候，都会有一个当前的state、action和reward，执行完action之后会得到一个新的state，将这四个元素保存为一条数据，积累大量的类似的数据，保存到一个数据池中，每次训练的时候从池中sample出，这个池是一个FIFO的队列。具体可看下面的流程图：</p>
<img src="/2016/06/27/Language-Understanding-for-Text-based-Games-using-Deep-Reinforcement-Learning-PaperWeekly/fig4.png" width="600" height="600">
<p>这里简单地说一下ε-greedy是怎么一回事。ε通常是一个非常小的值，这种策略一般被称为exploration，探索性的策略，面对未知的情况，随机选择一个action进行执行，探索一下会有什么情况发生，这种策略容易更新Q值；greedy策略，通常称为exploitation，利用性的策略，选择令Q值最大的action，不利于更新出更好的Q值，但可以得到相对更好的测试结果。</p>
<p>训练的目标函数是target与近似函数的差的平方，用一般的优化方法就可以训练了。其中，近似函数是我们需要学习的模型，target是通过Bellman方程来进行计算的（这里面涉及到的概念可以参考前面提到的智能单元的博客来学习）。</p>
<p>读完本文，有几点思考，分享一下：</p>
<p>1、增强学习看着也挺像监督学习的，到底有什么优势和区别吗？</p>
<p>我想它最大的优势是不是在于那个动态的、大型的数据池，可以源源不断地提供样本，可以说是无穷无尽的样本，这一点比一般的监督学习更加厉害，因为毕竟监督学习需要给定一个自带标签的数据集。通过不断的学习，来得到一个不错的模型。</p>
<p>2、DQN和经典的增强学习相比优势在哪里？</p>
<p>其实这个问题从某个角度上来看可以等同于Deep Learning与经典的机器学习相比，优势在哪里？一方面是神经网络模型强大地非线性函数近似，另一方面就是不需要人工feature，所有的feature都是从data中学习来的，典型的data-driven。</p>
<p>3、DQN在NLP中的应用，相比于DQN几乎没有什么新的东西，只是做了一些概念的替换。比如：在生成问题上，都是计算一个P(word|context)，这里将DQN中的state理解为context，将word理解为action。不过非常不同的一点是，nlp中的action space会非常大，因为对于生成问题来说，词汇表会变得非常大。这个问题该如何解决呢？大家可以期待明天的分享<a href="http://arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a>。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-25T02:59:44.000Z"><a href="/2016/06/25/教机器学习摘要/">2016-06-25</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/25/教机器学习摘要/">教机器学习摘要</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>文本摘要是自然语言处理中比较难的一个任务，别说是用机器来做文摘了，就连人类做文摘的时候都需要具备很强的语言阅读理解能力和归纳总结能力。新闻的摘要要求编辑能够从新闻事件中提取出最关键的信息点，重新组织语言来写摘要；paper的摘要需要作者从全文中提取出最核心的工作，然后用更加精炼的语言写成摘要；综述性的paper需要作者通读N篇相关topic的paper之后，用最概括的语言将每篇文章的贡献、创新点写出来，并且对比每篇文章的方法各有什么优缺点。自动文摘本质上做的一件事情是信息过滤，从某种意义上来说，和推荐系统的功能有一点像，都是为了让大家更快地找到感兴趣的东西，只是用了不同的手段而已。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>文本摘要问题按照文档数量可以分为单文档摘要和多文档摘要问题，按照实现方式可以分为提取式（extractive）和摘要式（abstractive）。摘要问题的特点是输出的文本要比输入的文本少很多很多，但却蕴藏着非常多的有效信息在内。有一点点感觉像是主成分分析（PCA），作用也与推荐系统有一点像，都是为了解决信息过载的问题。现在绝大多数应用的系统都是extractive的，这个方法比较简单但存在很多的问题，简单是因为只需要从原文中找出相对来说重要的句子来组成输出即可，系统只需要用模型来选择出信息量大的句子然后按照自然序组合起来就是摘要了。但是摘要的连贯性、一致性很难保证，比如遇到了句子中包含了代词，简单的连起来根本无法获知代词指的是什么，从而导致效果不佳。研究中随着deep learning技术在nlp中的深入，尤其是seq2seq+attention模型的“横行”，大家将abstractive式的摘要研究提高了一个level，并且提出了copy mechanism等机制来解决seq2seq模型中的OOV问题。</p>
<p>本文探讨的是用abstractive的方式来解决sentence-level的文本摘要问题，问题的定义比较简单，输入是一个长度为M的文本序列，输出是一个长度为N的文本序列，这里M&gt;&gt;N，并且输出文本的意思和输入文本的意思基本一致，输入可能是一句话，也可能是多句话，而输出都是一句话，也可能是多句话。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>这里的语料分为两种，一种是用来训练深度学习模型的大型语料，一种是用来参加评测的小型语料。</p>
<p>1、<a href="http://duc.nist.gov/" target="_blank" rel="external">DUC</a></p>
<p>这个网站提供了文本摘要的比赛，2001-2007年在这个网站，2008年开始换到这个网站<a href="http://www.nist.gov/tac/" target="_blank" rel="external">TAC</a>。很官方的比赛，各大文本摘要系统都会在这里较量一番，一决高下。这里提供的数据集都是小型数据集，用来评测模型的。</p>
<p>2、<a href="https://catalog.ldc.upenn.edu/LDC2003T05" target="_blank" rel="external">Gigaword</a></p>
<p>该语料非常大，大概有950w篇新闻文章，数据集用headline来做summary，即输出文本，用first sentence来做input，即输入文本，属于单句摘要的数据集。</p>
<p>3、CNN/Daily Mail</p>
<p>该语料就是我们在机器阅读理解中用到的语料，该数据集属于多句摘要。</p>
<p>4、Large Scale Chinese Short Text Summarization Dataset（<a href="http://icrc.hitsz.edu.cn/Article/show/139.html" target="_blank" rel="external">LCSTS</a>）[6]</p>
<p>这是一个中文短文本摘要数据集，数据采集自新浪微博，给研究中文摘要的童鞋们带来了福利。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本文所说的模型都是abstractive式的seq2seq模型。nlp中最早使用seq2seq+attention模型来解决问题的是machine translation领域，现如今该方法已经横扫了诸多领域的排行榜。</p>
<p>seq2seq的模型一般都是如下的结构[1]：</p>
<img src="/2016/04/24/自动文摘（五）/model.png" width="600" height="800">
<p>encoder部分用单层或者多层rnn/lstm/gru将输入进行编码，decoder部分是一个语言模型，用来生成摘要。这种生成式的问题都可以归结为求解一个条件概率问题p(word|context)，在context条件下，将词表中每一个词的概率值都算出来，用概率最大的那个词作为生成的词，依次生成摘要中的所有词。这里的关键在于如何表示context，每种模型最大的不同点都在于context的不同，这里的context可能只是encoder的表示，也可能是attention和encoder的表示。decoder部分通常采用beam search算法来做生成。</p>
<p>1、Complex Attention Model[1]</p>
<img src="/2016/04/24/自动文摘（五）/complex.png" width="400" height="650">
<p>模型中的attention weights是用encoder中每个词最后一层hidden layer的表示与当前decoder最新一个词最后一层hidden layer的表示做点乘，然后归一化来表示的。</p>
<p>2、Simple Attention Model[1]</p>
<img src="/2016/04/24/自动文摘（五）/simple.png" width="400" height="650">
<p>模型将encoder部分在每个词最后一层hidden layer的表示分为两块，一小块用来计算attention weights的，另一大块用来作为encoder的表示。这个模型将最后一层hidden layer细分了不同的作用。</p>
<p>3、Attention-Based Summarization(ABS)[2]</p>
<p>这个模型用了三种不同的encoder，包括：Bag-of-Words Encoder、Convolutional Encoder和Attention-Based Encoder。Rush是HarvardNLP组的，这个组的特点是非常喜欢用CNN来做nlp的任务。这个模型中，让我们看到了不同的encoder，从非常简单的词袋模型到CNN，再到attention-based模型，而不是千篇一律的rnn、lstm和gru。而decoder部分用了一个非常简单的NNLM，就是Bengio[10]于2003年提出来的前馈神经网络语言模型，这一模型是后续神经网络语言模型研究的基石，也是后续对于word embedding的研究奠定了基础。可以说，这个模型用了最简单的encoder和decoder来做seq2seq，是一次非常不错的尝试。</p>
<p>4、ABS+[2]</p>
<p>Rush提出了一个纯数据驱动的模型ABS之后，又提出了一个abstractive与extractive融合的模型，在ABS模型的基础上增加了feature function，修改了score function，得到了这个效果更佳的ABS+模型。</p>
<p>5、Recurrent Attentive Summarizer(RAS)[3]</p>
<p>这个模型是Rush的学生提出来的，输入中每个词最终的embedding是各词的embedding与各词位置的embedding之和，经过一层卷积处理得到aggregate vector：</p>
<img src="/2016/04/30/自动文摘（六）/formula21.png" width="300" height="400">
<p>根据aggregate vector计算context（encoder的输出）：</p>
<img src="/2016/04/30/自动文摘（六）/formula22.png" width="300" height="400">
<p>其中权重由下式计算：</p>
<img src="/2016/04/30/自动文摘（六）/formula23.png" width="300" height="400">
<p>decoder部分用RNNLM来做生成，RNNLM是在Bengio提出的NNLM基础上提出的改进模型，也是一个主流的语言模型。</p>
<p>6、big-words-lvt2k-1sent模型[4]</p>
<p>这个模型引入了large vocabulary trick(LVT)技术到文本摘要问题上。本方法中，每个mini batch中decoder的词汇表受制于encoder的词汇表，decoder词汇表中的词由一定数量的高频词构成。这个模型的思路重点解决的是由于decoder词汇表过大而造成softmax层的计算瓶颈。本模型非常适合解决文本摘要问题，因为摘要中的很多词都是来自于原文之中。</p>
<p>7、words-lvt2k-2sent-hieratt模型[4]</p>
<img src="/2016/05/07/自动文摘（七）/Pointer.png" width="600" height="800">
<p>文本摘要中经常遇到这样的问题，一些关键词出现很少但却很重要，由于模型基于word embedding，对低频词的处理并不友好，所以本文提出了一种decoder/pointer机制来解决这个问题。模型中decoder带有一个开关，如果开关状态是打开generator，则生成一个单词；如果是关闭，decoder则生成一个原文单词位置的指针，然后拷贝到摘要中。pointer机制在解决低频词时鲁棒性比较强，因为使用了encoder中低频词的隐藏层表示作为输入，是一个上下文相关的表示，而仅仅是一个词向量。这个pointer机制和后面有一篇中的copy机制思路非常类似。</p>
<p>8、feats-lvt2k-2sent-ptr模型[4]</p>
<img src="/2016/05/07/自动文摘（七）/Attention.png" width="600" height="800">
<p>数据集中的原文一般都会很长，原文中的关键词和关键句子对于形成摘要都很重要，这个模型使用两个双向RNN来捕捉这两个层次的重要性，一个是word-level，一个是sentence-level，并且该模型在两个层次上都使用attention，权重如下：</p>
<img src="/2016/05/07/自动文摘（七）/formula1.png" width="300" height="300">
<p>9、COPYNET[8]</p>
<img src="/2016/05/18/自动文摘（十三）/fig2.png" width="600" height="600">
<p>encoder采用了一个双向RNN模型，输出一个隐藏层表示的矩阵M作为decoder的输入。decoder部分与传统的Seq2Seq不同之处在于以下三部分：</p>
<ul>
<li><b>预测</b>：在生成词时存在两种模式，一种是生成模式，一种是拷贝模式，生成模型是一个结合两种模式的概率模型。</li>
<li><b>状态更新</b>：用t-1时刻的预测出的词来更新t时刻的状态，COPYNET不仅仅词向量，而且使用M矩阵中特定位置的hidden state。</li>
<li><b>读取M</b>：COPYNET也会选择性地读取M矩阵，来获取混合了内容和位置的信息。</li>
</ul>
<p>这个模型与第7个模型思想非常的类似，因为很好地处理了OOV的问题，所以结果都非常好。</p>
<p>10、MRT+NHG[7]</p>
<p>这个模型的特别之处在于用了Minimum Risk Training训练数据，而不是传统的MLE（最大似然估计），将评价指标包含在优化目标内，更加直接地对评价指标做优化，得到了不错的结果。</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>评价指标是否科学可行对于一个研究领域的研究水平有着直接的影响，目前在文本摘要任务中最常用的评价方法是ROUGE(Recall-Oriented Understudy for Gisting Evaluation)。ROUGE受到了机器翻译自动评价方法BLEU的启发，不同之处在于，采用召回率来作为指标。基本思想是将模型生成的摘要与参考摘要的n元组贡献统计量作为评判依据。</p>
<p>在英文数据集DUC-2004上进行评测，结果如下：</p>
<img src="/2016/06/25/教机器学习摘要/fig1.png" width="500" height="500">
<p>在中文数据集LCSTS上进行评测，结果如下：</p>
<img src="/2016/06/25/教机器学习摘要/fig2.png" width="500" height="500">
<p>不管是中文数据集还是英文数据集上，最好的结果都是来自于模型10[7],并且该模型只是采用最普通的seq2seq+attention模型，都没有用到效果更好的copy机制或者pointer机制。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>自动文摘是我关注的第一个nlp领域，早期了很多相关的paper，从方方面面都有所了解，也有一些比较浅薄的想法，现在总结一下。</p>
<p>1、为什么MRT那篇文章的结果会比其他各种各样的模型都要好呢？因为他直接将ROUGE指标包含在了待优化的目标中，而不是与其他模型一样，采用传统的MLE来做，传统的目标评价的是你的生成质量如何，但与我们最终评价的指标ROUGE并无直接关系。所以说，换了一种优化目标，直接定位于评价指标上做优化，效果一定会很好。这点不仅仅在自动文摘中出现过，我记得在bot相关的paper中还有机器阅读理解相关的paper中都有出现，只是具体的评价指标不同而已。这一点很有启发性，如果在文章[7]中采用copy机制来解决OOV问题，会不会有更加惊人的效果呢？我们拭目以待。</p>
<p>2、OOV(out of vocabulary)的问题。因为文本摘要说到底，都是一个语言生成的问题，只要是涉及到生成的问题，必然会遇到OOV问题，因为不可能将所有词都放到词表中来计算概率，可行的方法是用选择topn个高频词来组成词表。文章[4]和[8]都采用了相似的思路，从input中拷贝原文到output中，而不仅仅是生成，这里需要设置一个gate来决定这个词是copy来还是generate出来。显然，增加了copy机制的模型会在很大程度上解决了OOV的问题，就会显著地提升评价结果。这种思路不仅仅在文摘问题上适用，在一切生成问题上都适用，比如bot。</p>
<p>3、关于评价指标的问题。一个评价指标是否科学直接影响了这个领域的发展水平，人工评价我们就不提了，只说自动评价。ROUGE指标在2003年就被Lin提出了[9]，13年过去了，仍然没有一个更加合适的评价体系来代替它。ROUGE评价太过死板，只能评价出output和target之间的一些表面信息，并不涉及到语义层面上的东西，是否可以提出一种更加高层次的评价体系，从语义这个层面来评价摘要的效果。其实技术上问题不大，因为计算两个文本序列之间的相似度有无数种解决方案，有监督、无监督、半监督等等等等。很期待有一种新的体系来评价摘要效果，相信新的评价体系一定会推动自动文摘领域的发展。</p>
<p>4、关于数据集的问题。LCSTS数据集的构建给中文文本摘要的研究奠定了基础，将会很大程度地推动自动文摘在中文领域的发展。现在的互联网最不缺少的就是数据，大量的非结构化数据。但如何构建一个高质量的语料是一个难题，如何尽量避免用过多的人工手段来保证质量，如何用自动的方法来提升语料的质量都是难题。所以，如果能够提出一种全新的思路来构建自动文摘语料的话，将会非常有意义。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://cn.arxiv.org/pdf/1512.01712" target="_blank" rel="external">Generating News Headlines with Recurrent Neural Networks</a></p>
<p>[2] <a href="http://cn.arxiv.org/pdf/1509.00685.pdf" target="_blank" rel="external">A Neural Attention Model for Abstractive Sentence Summarization</a></p>
<p>[3] <a href="http://harvardnlp.github.io/papers/naacl16_summary.pdf" target="_blank" rel="external">Abstractive Sentence Summarization with Attentive Recurrent Neural Networks</a></p>
<p>[4] <a href="http://cn.arxiv.org/pdf/1602.06023" target="_blank" rel="external">Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond</a></p>
<p>[5] <a href="http://cn.arxiv.org/pdf/1604.00125v1.pdf" target="_blank" rel="external">AttSum: Joint Learning of Focusing and Summarization with Neural Attention</a></p>
<p>[6] <a href="http://cn.arxiv.org/pdf/1506.05865" target="_blank" rel="external">LCSTS: A Large Scale Chinese Short Text Summarization Dataset</a></p>
<p>[7] <a href="http://cn.arxiv.org/pdf/1604.01904.pdf" target="_blank" rel="external">Neural Headline Generation with Minimum Risk Training</a></p>
<p>[8] <a href="http://cn.arxiv.org/pdf/1603.06393v2.pdf" target="_blank" rel="external">Incorporating Copying Mechanism in Sequence-to-Sequence Learning Training</a></p>
<p>[9] <a href="http://research.microsoft.com/en-us/people/cyl/naacl2003.pdf" target="_blank" rel="external">Automatic Evaluation of Summaries Using N-gram Co-Occurrence Statistics</a></p>
<p>[10] <a href="http://jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a></p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-23T03:19:43.000Z"><a href="/2016/06/23/如果我也做一家公司/">2016-06-23</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/23/如果我也做一家公司/">如果我也做一家公司</a></h1>
  

    </header>
    <div class="entry">
      
        <img src="/2016/06/23/如果我也做一家公司/1.jpg" width="800" height="800">
<p>内心一直有一种去创业的情怀，一直想追逐一个属于自己的事业，想开一家很棒的公司。如果我也做一家公司的话，可能是下面的样子：</p>
<p>1、人数一定不会很多，少而精，因为我有密集恐惧症，受不了很多人在我面前。其实，人少并不代表战斗力差，很多东西都不需要自己公司去做，很多业务都可以外包给质量更高的专业公司来做，我们只需要做好最核心的东西。人少有太多的好处，交流和沟通的效率会非常高，不会被每天大量的、无聊的、低效率的会议占据了时间。</p>
<p>2、技术一定要新，且不断地尝试新的东西，不断地推出好玩的产品，这个需要我们具备非常好地学习能力和动手能力。可以跟上最新的研究成果，比如从最新的paper中汲取新方法，可以用最新、最牛的技术高效地解决难题。不管是硕士还是博士地学习，我觉得最重要的都不是知识上的积累，而是思考问题和学习解决问题的能力地锻炼，知识上的积累只是一个附带的成果，最直接、最重要的成果应该是你通过学习具备了解决各种各样未知问题的能力。</p>
<p>3、不是利益驱动，而是快乐或者别的与利益无关的东西在驱动。我们做什么事情采用什么样的方法，从根本上决定于你的目标是什么，你要达到一个什么样的程度。你是为了赚钱，还是为了满足自己的一些情怀，还是为了得到一些肯定和声望？不同的目标或者说不同的驱动模式，会直接影响你的心态以及做事情的方式。可能国内的环境容易让大家背离初心，变得更加实用，更加地浮躁，更加地急躁，更加地利益化，衡量一切成功或失败的唯一标准变成了是否赚钱，而不是说你做出了什么有意义或者伟大的事情。最终，企业将只是一个为了养家糊口的企业了，那么和你找一份工作有什么本质上的区别呢？如果只是为了养家糊口。</p>
<p>4、我关注nlp，也看好nlp在将来的应用会比现在更加地智能，可以更好地服务于大众。因为自然语言是与每一个人类息息相关的东西，也是人类在表达情感以及各种各样情绪的最根本的东西，人类每天都需要阅读、写作文字，大量的与文字相关的东西有朝一日都可以用nlp技术来辅助、帮忙甚至替代。这一点都不危言耸听。</p>
<p>5、工作时间一定是弹性的，因为人少所以容易管理，其实也不需要管理，基本上处于一种高度自觉的、无组织的状态，但这并不意味着偷懒或者低效。因为人少，既然能一起做这样的事情，一定具有相似的三观和基本条件，所以不需要什么强制性的制度来约束大家。最自由的状态反而是最高效的状态，企业嘛，效率是一切行动的基础和生命力，很多大厂都模仿美国的公司搞一些软性的公司待遇，比如吃不完的零食、带宠物、弹性工作等等都是为了让大家更高效地工作，然后在不知不觉中更加充分地剥削其剩余价值。而且我不反对远程办公，相反我很喜欢远程办公，一切以高效地做好事情为最终目标。</p>
<p>说了这么多，我想可能最合适的企业模式是当下也很流行的SaaS+2B，类似的企业有很多也有很多种，比如国内的face++做人脸识别，比如国外的Maluuba做bot和机器阅读。尤其是bot的兴起，大量的企业开始做bot API。这种企业有一个特点，就是赚其他需要该技术的企业的钱，也就是2B(To Business)，提供服务的形式一般都是给API接口，都是将后台的算法封装好，通过web协议供企业用户来调用，按次收费。</p>
<p>这种类型的企业需要有非常有竞争力的技术和持续学习的能力，不需要前期的资本涌入来烧钱，靠自身就可以实现盈利，企业模式的框架比较简单清晰，核心的东西在于算法。整个模式正是非常适合我上述想法的，那么说这么多，我自己现在具备什么以及还差什么？</p>
<p>1、实现一个SaaS+2B门户网站以及算法接口问题不大，php、python开发一个网站非常容易，实现具体的算法也实践了很多，封装成接口也没有问题。毕竟之前开发的rsarxiv网站、微信公众号、ios app都用到了这些技术，有了一定的积累。（rsarxiv是一个arxiv paper的推荐系统）</p>
<p>2、跟上最新的paper，从中汲取新方法和新思路。这一点正在做，每天都在做，每天的PaperWeekly就是在做这样的事情，在不断地积累，在不断学习，同时也在用torch实现着，前几天刚刚开源了一个完整的seq2seq+attention的代码。当然，这一块是核心的东西，因为算法是你的生命力，是你立足于市场的最根本的东西，所以还需要更深地积累，毕竟厚积薄发嘛。</p>
<p>3、团队。我理想中的团队不要很多的人，因为我习惯了一个人，也不喜欢和志不同道不合的人说太多的话。所以，找团队不能急，就像你找女朋友一样，都是缘分，缘分到了自然会有合适的人来加入，不可勉强，也不可速求。希望慢慢地可以遇到三观相符的有缘人。</p>
<p>4、一些必备的能力还有所欠缺。比如推销自己的能力，这一点非常重要，也是我一直忽视的能力。如何在现有的条件下最大地将自己推销出去是一件很难的事情。在网上看过一个帖子，说印度人在美国的公司比中国人更容易得到升迁的机会，一个很重要的原因在于他们更善于推销自己，而且美国就是一个重视这种事情的国家。这一点，我非常佩服自己的导师，他对待任何事情都非常认真，比如昨天准备一个评奖的ppt，愣是几天几夜不休息，一直在认认真真地准备着，这一点非常打动我，让我感到肃然起敬。也让我深深地从他身上学到了一点，怎样在一个20分钟的ppt里尽可能多地推销自己，为自己争取到更多的机会。再比如，推销产品的能力，也就是销售，换句话说就是怎么去忽悠企业来用你的服务，这个能力需要好好地锻炼，也许我的爱人可以帮助我。</p>
<p>创业对于我来说一直都是一个情怀，也是一个梦想。有的梦想在不正确时间将很那被实现，但我会选择将其珍藏起来，有朝一日来努力实现它。今年27岁，这个梦从初中看盗版的比尔盖茨传开始就播下了种子，我想现在该拿出来，开始好好琢磨琢磨了。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-19T12:56:21.000Z"><a href="/2016/06/19/My-first-open-source-code-in-deep-learning/">2016-06-19</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/19/My-first-open-source-code-in-deep-learning/">My first open source code in deep learning</a></h1>
  

    </header>
    <div class="entry">
      
        <p>前面的博客中有提到过要开源最近写的code，<a href="https://github.com/rsarxiv/seq2seq-attention" target="_blank" rel="external">seq2seq-attention</a>，今天正式开源了，欢迎各路大神来fork和star。这是我从5月中旬开始决定用torch框架来写deep learning code以来写的第一个完整的program，在写的过程中走过不少弯路，尤其是在选择demo进行学习的过程中，被HarvardNLP组的<a href="https://github.com/harvardnlp/seq2seq-attn" target="_blank" rel="external">seq2seq-attn</a>难以阅读的代码搞得非常崩溃，差一点就放弃了Torch。后来从<a href="https://github.com/oxford-cs-ml-2015/practical6" target="_blank" rel="external">oxford的课程代码</a>和<a href="https://github.com/karpathy/char-rnn" target="_blank" rel="external">char-rnn</a>中慢慢找到了Torch写code的感觉。本文简单介绍下踩过的坑和一些感受。</p>
<p>1、最开始想要用的框架是theano，因为之前一直用python写代码，而且theano的开源demo很多，并且有二次封装的框架keras，非常简单易用。但后来在写的时候总是报一些难以定位的错误，就放弃了。接下来，摆在我面前的剩下了两个选择，一个是tensorflow，一个是torch。这里为什么没有其他的上层框架呢？（比如keras等二次框架）因为，我觉得灵活性是我对框架的第一要求，大家都知道框架封装越友好，越高级，灵活性就会越差，在实现自己的model时大多数会捉襟见肘，难以胜任；但如果你选择了一个非框架的方案，也就是说用c/c++来写，虽然运行效率很高，但实现效率就会太低了，时间成本是最贵的成本，绝对不要浪费时间在一些很成熟的东西上面。</p>
<p>接着说，二选一怎么做选择。tensorflow其实是刚刚发布不久的，而且是python系的，但太新了，存在很多不稳定的地方或者不成熟的地方，而torch已经在facebook、deepmind等公司被使用了很久，尤其是facebook肩负起了维护和开发torch的重任，迷信了权威，选择了更加成熟的torch，尽管用torch先得过lua这关，我也认了。后来，在微博上每天都出现大量tensorflow的分享，有那么一丝动摇，但最终仍然坚持了torch。这个过程和我做PaperWeekly都给我带来了一样的感受和力量，那就是<code>坚持就会让你变得不一样</code>，我特别信这句话。</p>
<p>2、torch做数据预处理是一个坑，一个很大的坑，用python几行搞定的事情，在torch这里需要大量的代码，十分恶心。所以，就换了一种思路，用python做预处理，将处理好的结果扔到hdf5中，用torch读入hdf5中的数据。其实这里，用hdf5也行，用普通的文本文件也行，毕竟只是一个交换数据的媒介，但hdf5更加高效一些。</p>
<p>3、demo的问题，忘了是哪个大神说过torch的缺点，之一就是找不到一个特别规范的demo来引导新手，于是我在google上搜到了所有与之相关的torch代码来看，从最简单的开始，后来发现oxford的课程代码和char-rnn很好懂，就靠这个入了门。其实这两个代码做的是同一件事情，都是char-level的语言模型，只不过oxford更加简单，功能没有那么全面，而char-rnn是github上一个知名的code，与karpathy博士的blog配合一起十分有名，殊不知他的很多code都是从oxford的课程中来的，但好像oxford有一些代码是从一个叫<a href="https://github.com/wojciechz/learning_to_execute" target="_blank" rel="external">learning_to_execute</a>的code中来的，大家纷纷继承了优秀的功能代码，在此基础上写自己model这一部分。因为lua是函数式编程语言，函数是第一公民，各种各样的闭包令人难以阅读，这一点让学demo和继承demo的代码变得困难了。</p>
<p>4、nngraph，代码中所有的model都是用nngraph来写的，刚刚开始用nngraph的时候，总是会出现莫名其妙的错误，告诉你定义的节点并没有被使用。后来慢慢地找到了感觉，这个过程其实就是model的forward过程，特别需要注意的是每个节点的定义是什么，自己一定要标识好，在train的过程中调用时，输入一定要给对，顺序到一定不能错。但如果你踩过了那个坑之后，就会发现用torch写deep learning的model就会很简单了，把整个forward过程梳理清楚，用nngraph写出来，基本上具有你自己特色的model就ok了。</p>
<p>5、forward、backward函数，这两个函数构成了torch框架的整个计算过程，训练无非就是正向预测、反向梯度传播更新参数，循环往复罢了。使用这两个函数可以自动完成计算，非常地方便。在train的过程中，就是不断地将你的data丢入到model中forward然后backward，直到获得满意的误差。</p>
<p>6、GPU的使用，这一点也是非常地简单和方便，只需要把整个过程中的torch变量变为cutorch或者cltorch即可。</p>
<p>7、不建议开始就用高级的库，比如rnn或者dp，而是从最基本的rnn、lstm、gru这些开始写起，对概念、对整个计算流程都会有更深入地理解，同样是解决了问题，从更低层次的东西做起会了解到更多的细节，在灵活性上也有更好的优势。</p>
<p>这次开源的代码是端到端+注意力模型，用了当下流行的bot来做demo，包括数据预处理，训练，测试，部署到本地服务器等一些功能。欢迎大家多fork，一起改进它，也是一个促进我进步的机会。如果您想交流，可以make一个issue或者直接发邮件给我，mcgrady150318@gmail.com。</p>
<p><b>推荐</b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">
<p>知乎专栏也是<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">PaperWeekly</a>，欢迎大家关注。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-18T02:20:27.000Z"><a href="/2016/06/18/教机器学习阅读/">2016-06-18</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/18/教机器学习阅读/">教机器学习阅读</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="引"><a href="#引" class="headerlink" title="引"></a>引</h1><p>机器学会阅读将是人工智能在处理和理解人类语言进程中一个里程碑式的事件，是一个真正AI必须达到的标准。最近一家叫做<a href="http://www.maluuba.com/" target="_blank" rel="external">Maluuba</a>的科技公司，号称开发了目前最领先的机器阅读理解系统EpiReader[10]，成为了业界的领跑者，也被媒体盛赞。本文是一篇机器阅读理解的综述文章，系统地总结和对比一下最近阅读过的相关paper。</p>
<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>首先定义下机器阅读理解问题的数学模型。</p>
<p>问题可以表述为一个三元组(d,q,a)，这里d是指原文document，q是指问题query或者question（不同的paper可能称呼不同，但指的是同一回事），a是answer，即问题的答案。这个答案是来自一个固定大小的词汇表A中的一个词。我们要解决的问题就变成了：给定一个document-query对(d,q)，从A中找到最合适的答案a。</p>
<p>经常听到这么一句话，没有分类解决不了的问题。虽然有一点夸张，但这个问题是一个典型的多分类问题，预测候选列表中每个word或者entity的条件概率，最大的那个就是正确答案。其实很多问题也都是这样，尤其是在生成问题上，给定context，来predict每一个word的概率。</p>
<p>这里不同的paper在词汇表A中有些不同，有的paper将A定义为document和query中的所有词，而有的将A定义为所有的entity，而有的将会附带一个包括正确答案在内的10个候选答案，并且每个答案的词性都一致。</p>
<h1 id="语料"><a href="#语料" class="headerlink" title="语料"></a>语料</h1><p>语料对于NLP的研究有着十分重要的基础作用，尤其是大规模的语料为研究相关任务带来了革命性的变化。前些年的语料都非常小，比如MCTest。从2015年开始，出现了两大主流的大型数据集。</p>
<p>1、CNN/Daily Mail[9]</p>
<p>数据集构建基本的思路是受启发于自动文摘任务，从两个大型的新闻网站CNN和Daily Mail中获取数据源，用abstractive的方法生成每篇新闻的summary，用新闻原文作为document，将summary中去掉一个entity作为query，被去掉的entity作为answer，从而得到阅读理解的数据三元组(document,query,answer)。这里存在一个问题，就是有的query并不需要联系到document，通过query中的上下文就可以predict出answer是什么，也就失去了阅读理解的意义。因此，本文提出了用一些标识替换entity和重新排列的方法将数据打乱，防止上面现象的出现。处理之后的效果见下图：</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig1.png" width="600" height="600">
<p>2、Children’s Book Test(CBT)[3]</p>
<p>CBT的数据均来自Project Gutenberg，使用了其中的与孩子们相关的故事，这是为了保证故事叙述结构的清晰，从而使得上下文的作用更加突出。每篇文章只选用21句话，前20句作为document，将第21句中去掉一个词之后作为query，被去掉的词作为answer，并且给定10个候选答案，每个候选答案是从原文中随机选取的，并且这10个答案的词性是相同的，要是名词都是名词，要是命名实体都是实体，要是动词都是动词。例子看下图：</p>
<img src="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/fig1.png" width="600" height="600">
<p>左图为电子书的原文，右图为构建成数据集之后的几个元素，document、query、answer和candidate。数据集根据词性一共分为四类，第一类是Named Entity，第二类是Nouns，第三类是Verbs，第四类是Preposition。其实阅读理解问题的难度在于前两种词性，后面的两种用语言模型通过query的上下文就可以预测出来，不需要借助于document的信息。这个数据集并没有像CNN那样做替换和重排的处理，反而是鼓励大家用更少的信息来做阅读理解。</p>
<p>说完最流行的两个数据集，接下来介绍一下昨天刚刚在arxiv上submit的一个数据集。</p>
<p>3、Stanford Question Answering Dataset(SQuAD)[1]</p>
<p>该数据集的构建分为三个步骤：</p>
<ul>
<li><p>在Wikipedia中选取质量排名在10000以内的article，（这里用了 Project Nayuki’s Wikipedia’s internal PageRanks来做rank），从每篇文章中提取出paragraph，经过一系列处理之后得到了23215个paragraph，涉及了很宽泛的话题。</p>
</li>
<li><p>然后雇佣了crowdworkers给每个paragraph提问和回答，而且鼓励workers用自己的话来提问。（这一点和CNN中用abstractive的思路很像，只不过是用了人工来做。）</p>
</li>
<li><p>第三步是让crowdworkers来用原文中的text（word或者是span）来回答这个问题，如果无法用原文回答的话，直接提交问题。</p>
</li>
</ul>
<p>这个数据集的答案类型非常丰富，看下表：</p>
<img src="/2016/06/18/教机器学习阅读/fig1.png" width="400" height="400">
<p>4、LAnguage Modeling Broadened to Account for Discourse Aspects(LAMBADA)[11]</p>
<p>该数据集的paper于2016年6月20日于arxiv上，特补充在此。</p>
<p>这个数据集的数据源来自Book Corpus，一共包括10022个passage，平均每个passage包括4.6句话+1句target，每个passage大约75个单词。在选择数据的过程用了很多的人力来做，按照以下的过程：</p>
<ul>
<li><p>第一个人阅读全文之后来猜target word，如果猜对了。</p>
</li>
<li><p>第二个人继续阅读全文来猜target word，如果猜对了。</p>
</li>
<li><p>更多人不让阅读全文，只能读target sentence来猜target word，直到猜对或者达到猜的人数上限，比如说10.如果没有人猜的对，就将该数据归入LAMBADA中。</p>
</li>
</ul>
<p>这种方法很费时费力，但从质量上得到了保证，所获得的数据集都可以保证通过阅读全文之后一定会得到正确结果，不阅读全文一定找不到结果，避免了语言模型通过分析target sentence直接生成target word这种情况，给研究者提供了一个质量更高的数据集。</p>
<h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>本文所说的模型是指neural模型，人工features的模型就不介绍了。</p>
<p>1、Deep LSTM Reader / Attentive Reader / Impatient Reader[9]</p>
<p>这个模型是配套CNN/Daily Mail数据集的模型，只是作为后面研究的baseline，所以效果不会太好。</p>
<ul>
<li>Deep LSTM Reader</li>
</ul>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig2.png" width="400" height="400">
<p>看上图，其实非常简单，就是用一个两层LSTM来encode query|||document或者document|||query，然后用得到的表示做分类。</p>
<ul>
<li>Attentive Reader</li>
</ul>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig3.png" width="400" height="400">
<p>这个模型将document和query分开表示，其中query部分就是用了一个双向LSTM来encode，然后将两个方向上的last hidden state拼接作为query的表示，document这部分也是用一个双向的LSTM来encode，每个token的表示是用两个方向上的hidden state拼接而成，document的表示则是用document中所有token的加权平均来表示，这里的权重就是attention，权重越大表示回答query时对应的token的越重要。然后用document和query的表示做分类。</p>
<ul>
<li>Impatient Reader</li>
</ul>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig4.png" width="400" height="400">
<p>这个模型在Attentive Reader模型的基础上更细了一步，即每个query token都与document tokens有关联，而不是像之前的模型将整个query考虑为整体。感觉这个过程就好像是你读query中的每个token都需要找到document中对应相关的token。这个模型更加复杂一些，但效果不见得不好，从我们做阅读理解的实际体验来说，你不可能读问题中的每一个词之后，就去读一遍原文，这样效率太低了，而且原文很长的话，记忆的效果就不会很好了。</p>
<p>2、Attention Sum Reader[6]</p>
<img src="/2016/06/14/Text-Understanding-with-the-Attention-Sum-Reader-Network-PaperWeekly/fig1.png" width="600" height="600">
<p><b>step 1</b> 通过一层Embedding层将document和query中的word分别映射成向量。</p>
<p><b>step 2</b> 用一个单层双向GRU来encode document，得到context representation，每个time step的拼接来表示该词。</p>
<p><b>step 3</b> 用一个单层双向GRU来encode query，用两个方向的last state拼接来表示query。</p>
<p><b>step 4</b> 每个word vector与query vector作点积后归一化的结果作为attention weights，就query与document中的每个词之前的相关性度量。</p>
<p><b>step 5</b> 最后做一次相同词概率的合并，得到每个词的概率，最大概率的那个词即为answer。</p>
<p>3、Memory Networks[3][5]</p>
<img src="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/fig2.png" width="600" height="600">
<p>模型将document中的每一个word保存为一个memory m(i)，每个memory本质上就是一个向量，这一点与embedding是一回事，只是换了一个名词。另外每个word还与一个输出向量c(i)相关联。可以理解为每个word表示为两组不同的embedding A和C。同样的道理，query中的每个单词可以用一个向量来表示，即对应着另一个embedding B。</p>
<p>在Input memory表示层，用query向量与document中每个单词的m(i)作内积，再用softmax归一化得到一组权重，这组权重就是attention，即query与document中每个word的相关度，与昨天的AS Reader模型有些类似。</p>
<p>接下来，将权重与document中的另一组embedding c(i)作加权平均得到Output memory的表示。</p>
<p>最后，利用query的表示和output memory的表示去预测answer。</p>
<p>然后，介绍下右图的多层模型。根据单层模型的结构，非常容易构造出多层模型。每一层的query表示等于上一层query表示与上一层输出memory表示的和。每一层中的A和C embedding有两种模式，第一种是邻接，即A(k+1) = C(k)，依次递推；第二种是类似于RNN中共享权重的模式，A(1) = A(2) = … = A(k),C(1) = C(2) = … = C(k)。其他的过程均和单层模型无异。</p>
<p>本文模型的特点是易于构造更多层的模型，从而取得更好的效果。后面Gate Attention Reader模型正式借助了这个思想。</p>
<p>4、Dynamic Entity Representation[7]</p>
<img src="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/fig1.png" width="400" height="400">
<p>计算出entity的动态表示之后，通过attention mechanism计算得到query与每个entity之间的权重，然后计算每个entity在document和query条件下的概率，找到最终的answer。</p>
<p>query向量的计算与动态entity计算过程类似，这里需要填空的地方记作placeholder，也是包括四个部分，其中两个是表示placeholder上下文的last hidden state，另外两个是表示placeholder的hidden state。</p>
<p>模型的整个计算过程就是这样。如果遇到一个entity在document中出现多次的情况，该entity就会会有不同的表示，本文采用CNN中常用的max-pooling从各个表示中的每个维度获取最大的那一个组成该entity最终的表示，这个表示包括了该entity在document中各种context下的信息，具有最全面的信息，即原文中所说的accumulate information。如下图：</p>
<img src="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/fig2.png" width="400" height="400">
<p>5、Gate Attention Reader[8]</p>
<img src="/2016/06/12/Gated-Attention-Readers-for-Text-Comprehension-PaperWeekly/fig1.png" width="600" height="600">
<p><b>step 1</b> document和query通过一个Lookup层，使得每个词都表示成一个低维向量。</p>
<p><b>step 2</b> 将document中的词向量通过一个双向GRU，将两个方向的state做拼接获得该词的新表示。同时也将query通过一个双向GRU，用两个方向上的last hidden state作为query的表示。</p>
<p><b>step 3</b> 将document中每个词的新表示与query的新表示逐元素相乘得到下一个GRU层的输入。</p>
<p><b>step 4</b> 重复step 2和3，直到通过设定的K层，在第K层时，document的每个词向量与query向量做内积，得到一个最终的向量。</p>
<p><b>step 5</b> 将该向量输入到softmax层中，做概率归一化。</p>
<p><b>step 6</b> 因为document中有重复出现的词，聚合之后得到最终的分类结果，即确定应该填哪个词。</p>
<p>6、Iterative Alternating Attention[2]</p>
<img src="/2016/06/18/教机器学习阅读/fig2.png" width="600" height="600">
<p><b>step 1</b> 将document和query通过一个Lookup层，使得每个词都表示成一个低维向量。</p>
<p><b>step 2</b> 将document和query中的词向量通过一个双向GRU，将两个方向的state拼接获得该词的新表示。</p>
<p><b>step 3</b> 这一步文章中称为Iterative Alternating Attention，1）根据前一个inference状态s(t-1)来计算query的attention，得到query glimpse q(t)，对应图中的1;2)根据前一个状态s(t-1)和当前的query glimpse q(t)来计算document的attention，得到document glimpse d(t)，对应图中的2；3)用GRU来将前一个状态s(t-1)和当前的query glimpse q(t)和当前的document glimpse d(t)做处理得到当前的状态s(t)。</p>
<p><b>step 4</b> 重复step 3 直到t达到给定的T为止。</p>
<p><b>step 5</b> 用最后得到的每个词向量进行归一化，并且聚合相同的词概率，得到预测结果。</p>
<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>所有模型都是在两大主流数据集上进行对比[2][8]，结果如下：</p>
<img src="/2016/06/18/教机器学习阅读/fig3.png" width="600" height="600">
<p>Maluuba公司的模型在CBT数据集上是最好的，在CNN/Daily Mail数据集上并没有最测试，而Gate Attention Reader占据了CNN数据集上的头把交椅。</p>
<p>model ensemble可以将single model的效果提升很多，是一种非常有效的技术。从第一个模型Attentive Reader到最后一个模型Iterative Alternating Attention时间跨度大概是半年左右的时间，阅读理解的正确率提升了近20个百分点。</p>
<p>CBT数据集上包含了人工测试的结果，最高的准确率为81.6%，而目前计算机可以达到的最高正确率是72%，离人类仍有不小的差距，需要更多更牛的model涌现出来。</p>
<h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>读了一周的Machine Reading Comprehension paper，有几点思考：</p>
<p>1、大规模语料的构建是nlp领域研究进步的重要基础和保证，深度学习模型尤其是端到端+注意力模型利用大规模的语料进行训练和学习，极大地提升了计算机阅读理解的效果。而且每出现一个新的数据集，都会弥补之前数据集存在的问题，对模型提出了更高的要求，从而提高了该领域的研究水平。同时，也给很多需要毕业的童鞋提供了一个新的刷榜平台。</p>
<p>2、模型的提出应该更多地联系人类是如何解决这个问题的，比如attention、copy mechanism等等优秀的模型。attention借助了人类观察一个事物的时候，往往第一眼会先注意那些重要的部分，而不是全部这个行为方式。copy mechanism而是受启发于当人类不了解一个事物或者该事物只是一个named entity，而又需要表达它的时候，需要“死记硬背”，需要从context中copy过来。模型Dynamic Entity Representation用一种变化的眼光和态度来审视每一个entity，不同的context会给同样的entity带来不同的意义，因此用一种动态的表示方法来捕捉原文中entity最准确的意思，才能更好地理解原文，找出正确答案。实际体会中，我们做阅读理解的时候，最简单的方法是从问题中找到关键词，然后从原文中找到同样的词所在的句子，然后仔细理解这个句子最终得到答案，这种难度的阅读理解可能是四、六级的水平，再往高一个level的题目，就需要你联系上下文，联系关键词相关联的词或者句子来理解原文，而不是简单地只找到一个句子就可以答对题目。</p>
<p>3、[4]和[6]中用简单的模型反而会得到更好的结果，[9]中用了非常复杂的注意力机制反而并没有太好的结果。[2][8]都证明了用多层结构比单层结构更优秀。那么，是不是多层简单的模型会有更好的效果？这是一个需要动手实践来研究的问题。</p>
<p>4、当前的这些模型都是纯粹的data-driven，并没有考虑人工features进来。我一直坚信，如果做一个准确率非常高的系统的话，neural models+features是必须的，针对具体的问题，做具体的分析；但是如果是对于学术界研究model的话，提出更牛的neural models比纯粹的刷榜更有意义。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="http://cn.arxiv.org/pdf/1606.05250v1" target="_blank" rel="external">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a></p>
<p>[2] <a href="http://arxiv.org/pdf/1606.02245v3.pdf" target="_blank" rel="external">Iterative Alternating Neural Attention for Machine Reading</a></p>
<p>[3] <a href="https://arxiv.org/pdf/1511.02301.pdf" target="_blank" rel="external">THE GOLDILOCKS PRINCIPLE: READING CHILDREN’S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS</a></p>
<p>[4] <a href="http://arxiv.org/pdf/1606.02858v1.pdf" target="_blank" rel="external">A Thorough Examination of the CNN Daily Mail Reading Comprehension Task</a></p>
<p>[5] <a href="http://arxiv.org/pdf/1503.08895v5.pdf" target="_blank" rel="external">End-To-End Memory Networks</a></p>
<p>[6] <a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="external">Text Understanding with the Attention Sum Reader Network</a></p>
<p>[7] <a href="http://www.cl.ecei.tohoku.ac.jp/publications/2016/kobayashi-dynamic-entity-naacl2016.pdf" target="_blank" rel="external">Dynamic Entity Representation with Max-pooling Improves Machine Reading</a></p>
<p>[8] <a href="http://cn.arxiv.org/pdf/1606.01549v1" target="_blank" rel="external">Gated-Attention Readers for Text Comprehension</a></p>
<p>[9] <a href="http://rsarxiv.github.io/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/">Teaching Machines to Read and Comprehend</a></p>
<p>[10] <a href="http://cn.arxiv.org/pdf/1606.02270.pdf" target="_blank" rel="external">Natural Language Comprehension with the EpiReader</a></p>
<p>[11] <a href="http://cn.arxiv.org/pdf/1606.06031" target="_blank" rel="external">The LAMBADA dataset:Word prediction requiring a broad discourse context</a></p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-17T03:13:56.000Z"><a href="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/">2016-06-17</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/">Dynamic Entity Representation with Max-pooling Improves Machine Reading #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是机器阅读理解系列的第六篇文章，paper的题目是<a href="http://www.cl.ecei.tohoku.ac.jp/publications/2016/kobayashi-dynamic-entity-naacl2016.pdf" target="_blank" rel="external">Dynamic Entity Representation with Max-pooling Improves Machine Reading</a>，作者是来自日本东北大学的老师<a href="http://www.sc.isc.tohoku.ac.jp/~koba/" target="_blank" rel="external">Sosuke Kobayashi</a>，文章发表在<a href="http://naacl.org/naacl-hlt-2016/" target="_blank" rel="external">NAACL HLT 2016</a>。本文的代码开源在<a href="https://github.com/soskek/der-network" target="_blank" rel="external">Github</a>。</p>
<p>本文模型之前的模型都是用一个静态的向量来表示一个entity，与上下文没有关系。而本文最大的贡献在于提出了一种动态表示entity（Dynamic Entity Representation）的模型，根据不同的上下文对同样的entity有不同的表示。</p>
<p>模型还是采用双向LSTM来构建，这时动态entity表示由四部分构成，包括两个方向上的hidden state，以及表示该entity所在句子的last hidden state，也就是该entity所在的上下文表示。如下图所示：</p>
<img src="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/fig1.png" width="400" height="400">
<p>计算出entity的动态表示之后，通过attention mechanism计算得到query与每个entity之间的权重，然后计算每个entity在document和query条件下的概率，找到最终的answer。</p>
<p>query向量的计算与动态entity计算过程类似，这里需要填空的地方记作placeholder，也是包括四个部分，其中两个是表示placeholder上下文的last hidden state，另外两个是表示placeholder的hidden state。</p>
<p>模型的整个计算过程就是这样。如果遇到一个entity在document中出现多次的情况，该entity就会会有不同的表示，本文采用CNN中常用的max-pooling从各个表示中的每个维度获取最大的那一个组成该entity最终的表示，这个表示包括了该entity在document中各种context下的信息，具有最全面的信息，即原文中所说的accumulate information。如下图：</p>
<img src="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/fig2.png" width="400" height="400">
<p>本文的实验在CNN数据上对模型进行了对比，效果比之前的Attentive Reader好很多，验证了本文的有效性。（当然结果没法和GA Reader比）</p>
<p>最后，作者给出了一个example，来说明用max-pooling的作用，见下图：</p>
<img src="/2016/06/17/Dynamic-Entity-Representation-with-Max-pooling-Improves-Machine-Reading-PaperWeekly/fig3.png" width="400" height="400">
<p>由于用了max-pooling模型比起不用它的话，可以关注到第二句和第三句话，因为本文模型可以捕捉到entity0（Downey）和entity2（Iron Man）是关联的（Robert Downey Jr.是Iron Man的扮演者），然后就会注意到entity2出现过的几个句子，而不仅仅是query中entity0出现过的几个句子，这一点帮助了模型找到了最终的正确答案entity26（在第二句中）。</p>
<p>本文模型的一个好玩之处在于用了一种变化的眼光和态度来审视每一个entity，不同的context会给同样的entity带来不同的意义，因此用一种动态的表示方法来捕捉原文中entity最准确的意思，才能更好地理解原文，找出正确答案。实际体会中，我们做阅读理解的时候，最简单的方法是从问题中找到关键词，然后从原文中找到同样的词所在的句子，然后仔细理解这个句子最终得到答案，这种难度的阅读理解可能是四、六级的水平，再往高一个level的题目，就需要你联系上下文，联系关键词相关联的词或者句子来理解原文，而不是简单地只找到一个句子就可以答对题目。本文的动态表示正是有意在更加复杂的阅读理解题目上做文章，是一个非常好的探索。</p>
<p>另外，如何衡量阅读理解语料中题目的难度？是否可以按难度分类进行对比测试？如果说现在最好的系统可以做到75%左右的正确率，是否可以给出一些更加有难度的题目来做？比如英语考试中真正的阅读理解或者完形填空。不同的模型具有不同的特点，可以考虑用不同难度的题目来验证模型的适用性。</p>
<p>本文是这个系列文章在本周的最后一篇单文，周末的时间会整理出本周分享的模型的思路、研究动机和实验结果等各个方面来写一篇综述文章，对机器阅读理解这个点进行一个较系统地总结，敬请期待！（后续还会继续关注这个方向，读更多的paper来分享）</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-15T23:38:23.000Z"><a href="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/">2016-06-16</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/">THE GOLDILOCKS PRINCIPLE: READING CHILDREN’S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是机器阅读理解系列的第五篇文章，将会分享的题目是<a href="https://arxiv.org/pdf/1511.02301.pdf" target="_blank" rel="external">THE GOLDILOCKS PRINCIPLE: READING CHILDREN’S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS</a>，作者是来自剑桥大学的博士生<a href="http://www.cl.cam.ac.uk/~fh295/" target="_blank" rel="external">Felix Hill</a>，本文的工作是在Facebook AI Research完成的，文章最早于2016年4月1日submit在arxiv上，后来发表在ICLR 2016会议上。</p>
<p>本文的贡献主要是两点：一是构建了一个新的语料，Children’s Book Test（CBT），丰富了机器阅读理解任务的数据源；二是将Facebook提出的Memory Network框架应用到了机器阅读理解任务中，并取得了不错的结果。</p>
<p>首先，来介绍CBT。CBT的数据均来自<a href="https://www.gutenberg.org/" target="_blank" rel="external">Project Gutenberg</a>，使用了其中的与孩子们相关的故事，这是为了保证故事叙述结构的清晰，从而使得上下文的作用更加突出。每篇文章只选用21句话，前20句作为document，将第21句中去掉一个词之后作为query，被去掉的词作为answer，并且给定10个候选答案，每个候选答案是从原文中随机选取的，并且这10个答案的词性是相同的，要是名词都是名词，要是命名实体都是实体，要是动词都是动词。例子看下图：</p>
<img src="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/fig1.png" width="600" height="600">
<p>左图为电子书的原文，右图为构建成数据集之后的几个元素，document、query、answer和candidate。数据集根据词性一共分为四类，第一类是Named Entity，第二类是Nouns，第三类是Verbs，第四类是Preposition。这里，用LSTM RNNLM从query本身出发就可以非常准确地预测出Verbs和Preposition，不需要借助过多的document context，但是对于前两类却束手无策。因此本文提出了用Memory Network来解决这个问题。</p>
<p>Memory Network是Facebook提出的框架，在nlp的很多任务中都表现出色，比如语言模型。</p>
<img src="/2016/06/16/THE-GOLDILOCKS-PRINCIPLE-READING-CHILDREN’S-BOOKS-WITH-EXPLICIT-MEMORY-REPRESENTATIONS-PaperWeekly/fig2.png" width="600" height="600">
<p>原文中没有模型结构图，该图来自于文章<a href="http://arxiv.org/pdf/1503.08895v5.pdf" target="_blank" rel="external">End-To-End Memory Networks</a>。左图是一个单层的Memory Network，右图是一个多层的Network。</p>
<p>首先，介绍下单层模型。</p>
<p>模型将document中的每一个word保存为一个memory m(i)，每个memory本质上就是一个向量，这一点与embedding是一回事，只是换了一个名词。另外每个word还与一个输出向量c(i)相关联。可以理解为每个word表示为两组不同的embedding A和C。同样的道理，query中的每个单词可以用一个向量来表示，即对应着另一个embedding B。</p>
<p>在Input memory表示层，用query向量与document中每个单词的m(i)作内积，再用softmax归一化得到一组权重，这组权重就是attention，即query与document中每个word的相关度，与昨天的AS Reader模型有些类似。</p>
<p>接下来，将权重与document中的另一组embedding c(i)作加权平均得到Output memory的表示。</p>
<p>最后，利用query的表示和output memory的表示去预测answer。</p>
<p>然后，介绍下右图的多层模型。根据单层模型的结构，非常容易构造出多层模型。每一层的query表示等于上一层query表示与上一层输出memory表示的和。每一层中的A和C embedding有两种模式，第一种是邻接，即A(k+1) = C(k)，依次递推；第二种是类似于RNN中共享权重的模式，A(1) = A(2) = … = A(k),C(1) = C(2) = … = C(k)。其他的过程均和单层模型无异。</p>
<p>本文模型的特点是易于构造更多层的模型，从而取得更好的效果。我们之前分享过的一篇文章<a href="http://rsarxiv.github.io/2016/06/12/Gated-Attention-Readers-for-Text-Comprehension-PaperWeekly/">Gated-Attention Readers for Text Comprehension</a>就是借鉴了其中的思想，从而获得了目前来说最棒的结果。前面的文章给我的启示是，简单的模型反而会得到更好的结果，而本文给我的一个感觉是，如果你用了更多的layer也可能会获得不错的结果。如果你用了很多层非常简单的模型会不会得到更好的结果呢？这是一个需要思考和认真实践的问题。</p>
<p>明天将会继续介绍一篇机器阅读理解的单文，周末将会写一篇类似综述的文章，系统地对比下各种模型和结果。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-14T13:31:36.000Z"><a href="/2016/06/14/Text-Understanding-with-the-Attention-Sum-Reader-Network-PaperWeekly/">2016-06-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/14/Text-Understanding-with-the-Attention-Sum-Reader-Network-PaperWeekly/">Text Understanding with the Attention Sum Reader Network #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本文是机器阅读系列的第四篇文章，本文的模型常出现在最新的机器阅读paper中related works部分，也是很多更好的模型的基础模型，所以很有必要来看下这篇paper，看得远往往不是因为长得高，而是因为站得高。本文的题目是<a href="https://arxiv.org/pdf/1603.01547.pdf" target="_blank" rel="external">Text Understanding with the Attention Sum Reader Network</a>，作者是来自IBM Watson的研究员Rudolf Kadlec，paper最早于2016年3月4日submit在arxiv上。</p>
<p>本文的模型被称作Attention Sum Reader，具体见下图：</p>
<img src="/2016/06/14/Text-Understanding-with-the-Attention-Sum-Reader-Network-PaperWeekly/fig1.png" width="600" height="600">
<p><b>step 1</b> 通过一层Embedding层将document和query中的word分别映射成向量。</p>
<p><b>step 2</b> 用一个单层双向GRU来encode document，得到context representation，每个time step的拼接来表示该词。</p>
<p><b>step 3</b> 用一个单层双向GRU来encode query，用两个方向的last state拼接来表示query。</p>
<p><b>step 4</b> 每个word vector与query vector作点积后归一化的结果作为attention weights，就query与document中的每个词之前的相关性度量。</p>
<p><b>step 5</b> 最后做一次相同词概率的合并，得到每个词的概率，最大概率的那个词即为answer。</p>
<p>模型在CNN/Daily Mail和CBT的Nouns、Named Entity数据集上进行了测试，在当时的情况下都取得了领先的结果。并且得到了一些有趣的结论，比如：在CNN/Daily Mail数据集上，随着document的长度增加，测试的准确率会下降，而在CBT数据集上得到了相反的结论。从中可以看得出，两个数据集有着不同的特征，构造方法也不尽相同，因此同一个模型会有着不同的趋势。</p>
<p>本文的模型相比于Attentive Reader和Impatient Reader更加简单，没有那么多繁琐的attention求解过程，只是用了点乘来作为weights，却得到了比Attentive Reader更好的结果，从这里我们看得出，并不是模型越复杂，计算过程越繁琐就效果一定越好，更多的时候可能是简单的东西会有更好的效果。</p>
<p>另外，在这几篇paper中的related works中，都会提到用Memory Networks来解决这个问题。接下来的文章将会分享Memory Networks在机器阅读理解中的应用，大家敬请关注。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-14T00:36:02.000Z"><a href="/2016/06/14/A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task-PaperWeekly/">2016-06-14</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/14/A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task-PaperWeekly/">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>本篇是reading comprehension系列的第三篇，文章于2016年6月9号submit在arxiv上，比之前介绍的<a href="http://rsarxiv.github.io/2016/06/12/Gated-Attention-Readers-for-Text-Comprehension-PaperWeekly/">Gated-Attention Readers for Text Comprehension</a>更晚地出现，但尴尬的是本文的模型结果不如GA Reader。6月7号submit的一篇<a href="http://arxiv.org/pdf/1606.02245v3.pdf" target="_blank" rel="external">Iterative Alternating Neural Attention for Machine Reading</a>，用了和GA非常类似的方法，得到了稍微差一点的结果。确实最近在arxiv上常常可以刷出reading comprehension的paper，可以看得出这个领域当前多么地火热。同时火热的还有dialogue generation任务，今天凌晨的wwdc2016大会中，苹果宣布打造更加智能的siri，几大科技巨头纷纷表示要将聊天机器人作为智能的未来，由此可见与其相关的研究将会越来越热。本文的作者是来自斯坦福大学的博士生<a href="http://cs.stanford.edu/people/danqi/" target="_blank" rel="external">Danqi Chen</a>，本科毕业于清华的姚班。</p>
<p>虽然本文并没有比GA模型有更好的效果，但作为了解整个Reading Comprehension研究的发展以及模型的思路还是很有意义的。本文最大的贡献在于提出了一种基于人工特征的分类器模型和一个改进版的端到端模型（这里是基于<a href="http://rsarxiv.github.io/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/">Teaching Machines to Read and Comprehend</a>的Attentive Reader模型）。</p>
<p>第一个模型，是典型的人工特征模型，通过提取了八个特征构建特征空间，通过使得正确答案entity比其他entity获得更高的得分来训练得到模型参数。包含的特征有：该entity是否出现在原文中，该entity是否出现在问题中，出现过几次，第一次出现的位置等等八个特征。</p>
<p>第二个模型，基本思路与<a href="http://rsarxiv.github.io/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/">Attentive Reader</a>接近。看下图：</p>
<img src="/2016/06/14/A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task-PaperWeekly/fig1.png" width="600" height="600">
<p>这里只介绍不同的地方：</p>
<p>1、在计算query和document的注意力权重时，没有采用非线性的tanh，而是采用了bilinear。</p>
<p>2、得到注意力权重之后，计算context的输出，然后直接用输出进行分类预测，而Attentive Reader是用输出与query又做了一次非线性处理之后才预测的。</p>
<p>3、词汇表中只包括entity，而不是所有的单词。</p>
<p>模型上的改进只有第一点算是吧，后两点只是做了一些简单的优化。</p>
<p>虽然模型简单了，但效果却比Attentive Reader好很多，提升了约5%的效果，我们不管其模型有没有什么亮点，这些简化处理反而得到非常好的效果，这一点很引人深思。</p>
<p>结果这部分，作者分析了八个特征分别对模型结果的影响，其中影响最大的是n-gram match（entity和placeholder是否有相似的上下文），其次是entity出现的频率，具体见下表：</p>
<img src="/2016/06/14/A-Thorough-Examination-of-the-CNN-Daily-Mail-Reading-Comprehension-Task-PaperWeekly/fig2.png" width="400" height="400">
<p>端到端模型比Attentive Reader效果好很多，但和最近的GA来比还是差了很多。看过本文之后，只有一个疑问，简化后的模型为什么比稍微复杂一点的模型好那么多呢？</p>
<p>最后作者总结了下Reading Comprehension任务中常用的数据集：</p>
<p>1、CNN/Daily Mail</p>
<p>2、MCTest</p>
<p>3、Children Book Test（CBT）</p>
<p>4、bAbI</p>
<p>本周末计划将本周看过的几篇reading comprehension写成一篇综述，好好做一次系统地对比和总结。敬请期待。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-13T02:57:22.000Z"><a href="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/">2016-06-13</a></time>
      
      
  
    <h1 class="title"><a href="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/">Teaching Machines to Read and Comprehend #PaperWeekly#</a></h1>
  

    </header>
    <div class="entry">
      
        <p>昨天的文章text comprehension系列的第一篇，是最近刚刚submit的文章，今天分享一篇去年的文章，也是一篇非常经典的文章。我记得Yoshua Bengio在Quora Session一个问题中推荐这篇文章。本文的题目是<a href="http://arxiv.org/pdf/1506.03340.pdf" target="_blank" rel="external">Teaching Machines to Read and Comprehend</a>，作者是来自Google DeepMind的科学家<a href="http://www.karlmoritz.com/" target="_blank" rel="external">Karl Moritz Hermann</a>，是Oxford的博士后，两家机构的合作好多，很多文章都是一起写的。</p>
<p>本文的贡献主要有两点：一是提出了一种构建用于监督学习的阅读理解大型语料的方法，并开源在<a href="https://github.com/deepmind/rc-data" target="_blank" rel="external">Github</a>上，并且给出了两个大型语料，CNN和Daily Mail；二是提出了三种用于解决阅读理解任务的神经网络模型。</p>
<p>首先，聊一聊语料的构建方法。基本的思路是受启发于自动文摘任务，从两个大型的新闻网站中获取数据源，用abstractive的方法生成每篇新闻的summary，用新闻原文作为document，将summary中去掉一个entity作为query，被去掉的entity作为answer，从而得到阅读理解的数据三元组(document,query,answer)。这里存在一个问题，就是有的query并不需要联系到document，通过query中的上下文就可以predict出answer是什么，这也就失去了阅读理解的意义。因此，本文提出了用entity替换和重新排列的方法将数据打乱，防止上面现象的出现。这两个语料在成为了一个基本的数据集，后续的很多研究都是在数据集上进行训练、测试和对比。处理前和后的效果见下图：</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig1.png" width="600" height="600">
<p>接下来，介绍下本文的三个模型：</p>
<p>用神经网络来处理阅读理解的问题实质上是一个多分类的问题，通过构造一些上下文的表示，来预测词表中每个单词的概率，概率最大的那个就是所谓的答案。说起这一点，不禁想起了一个有趣的说法，任何nlp任务都可以用分类的思路来解决。</p>
<p>1、Deep LSTM Reader</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig2.png" width="400" height="400">
<p>看上图，其实非常简单，就是用一个两层LSTM来encode query|||document或者document|||query，然后用得到的表示做分类。</p>
<p>2、Attentive Reader</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig3.png" width="400" height="400">
<p>这个模型将document和query分开表示，其中query部分就是用了一个双向LSTM来encode，然后将两个方向上的last hidden state拼接作为query的表示，document这部分也是用一个双向的LSTM来encode，每个token的表示是用两个方向上的hidden state拼接而成，document的表示则是用document中所有token的加权平均来表示，这里的权重就是attention，权重越大表示回答query时对应的token的越重要。然后用document和query的表示做分类。</p>
<p>3、Impatient Reader</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig4.png" width="400" height="400">
<p>这个模型在Attentive Reader模型的基础上更细了一步，即每个query token都与document tokens有关联，而不是像之前的模型将整个query考虑为整体。感觉这个过程就好像是你读query中的每个token都需要找到document中对应相关的token。这个模型更加复杂一些，但效果不见得不好，从我们做阅读理解的实际体验来说，你不可能读问题中的每一个词之后，就去读一遍原文，这样效率太低了，而且原文很长的话，记忆的效果就不会很好了。</p>
<p>实验部分，作者选了几个baseline作为对比，其中有两个比较有意思，一是用document中出现最多的entity作为answer，二是用document中出现最多且在query中没有出现过的entity作为answer。这个和我们在实际答题遇到不会做的选择题时的应对策略有一点点异曲同工，所谓的不会就选最长的，或者最短的，这里选择的是出现最频繁的。</p>
<p>最终的结果，在CNN语料中，第三种模型Impatient Reader最优，Attentive Reader效果比Impatient Reader差不太多。在Daily Mail语料中，Attentive Reader最优，效果比Impatient Reader好了多一些，见下表：</p>
<img src="/2016/06/13/Teaching-Machines-to-Read-and-Comprehend-PaperWeekly/fig5.png" width="400" height="400">
<p>开始在看语料构建方法的时候，我在想应该是用extractive的方法从原文中提取一句话作为query，但看到paper中用的是abstractive的方法。仔细想了一下，可能是因为extractive的方法经常会提取出一些带有指示代词的句子作为摘要，没有上下文，指示代词就会非常难以被理解，从而给后面的阅读理解任务带来了困难，而用abstractive的方法做的话就会得到质量更高的query。本文的最大贡献我认为是构建了该任务的大型语料，并且配套了三个神经网络模型作为baseline，以方便后面的研究者进行相关的研究，从很大地程度上推进了这个领域的发展。</p>
<p><b>工具推荐</b></p>
<p><code>RSarXiv</code> <b>一个好用的arxiv cs paper推荐系统</b> <a href="http://rsarxiv.science/web" target="_blank" rel="external">网站地址</a> <b>ios App下载：App Store 搜索rsarxiv即可获得 </b></p>
<p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="350" height="350">

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/" class="alignleft prev">上一页</a>
  
  
    <a href="/page/3/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>110</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>128</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/创业/">创业</a><small>1</small></li>
  
    <li><a href="/tags/招聘/">招聘</a><small>1</small></li>
  
    <li><a href="/tags/推荐系统/">推荐系统</a><small>2</small></li>
  
    <li><a href="/tags/综述/">综述</a><small>1</small></li>
  
    <li><a href="/tags/自动文摘/">自动文摘</a><small>16</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>