<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Generating Text with Deep Reinforcement Learning #PaperWeekly# | PaperWeekly</title>
  
  
  <meta name="description" content="上一篇介绍了DQN在文字游戏中的应用，本文将分享一篇DQN在文本生成中的应用，将一个领域的知识迁移到其他领域应用的时候，都需要做概念上的等效替换，比如context可以替换为state，被预测的word可以替换为action。本文分享的题目是Generating Text with Deep Rei">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Generating Text with Deep Reinforcement Learning #PaperWeekly#"/>
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-06-28T02:19:32.000Z"><a href="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/">2016-06-28</a></time>
      
      
  
    <h1 class="title">Generating Text with Deep Reinforcement Learning #PaperWeekly#</h1>
  

    </header>
    <div class="entry">
      
        <p>上一篇介绍了DQN在文字游戏中的应用，本文将分享一篇DQN在文本生成中的应用，将一个领域的知识迁移到其他领域应用的时候，都需要做概念上的等效替换，比如context可以替换为state，被预测的word可以替换为action。本文分享的题目是<a href="http://arxiv.org/pdf/1510.09202v1.pdf" target="_blank" rel="external">Generating Text with Deep Reinforcement Learning</a>，作者是来自National Research Council of Canada的<a href="http://www.site.uottawa.ca/~hguo028/mainpage.htm" target="_blank" rel="external">Hongyu Guo</a>研究员，文章最早于2015年10月30日submit在arxiv上。</p>
<p>语言模型往往用来生成文本，在很多例子中都有应用，比如：自动文摘、bot、机器翻译、QA等等。本文想要做的事情是用DQN来生成文本，起到一个语言模型的作用，并且这是第一次尝试用DQN来生成文本。仔细想想，DQN在解决video games时遇到的情况和现在不同，state可能还好，可生成的action数量远远大于游戏中action的数量，所以，如何解决action的问题对于DQN在NLP中的应用前景至关重要。目前来看，读此类的paper，需要关注的有两个部分：</p>
<p>1、action规模的问题如何解决？</p>
<p>2、DQN中每条数据集包含的元素与NLP问题中各个元素的对应关系。</p>
<p>本文解决第一个问题采用的方法是，用传统的语言模型decoder来为DQN的action生成candidated actions，虽然这个actions集合是动态，但对于每一条数据来说，action的数量只有很少了，与video games差不太多了。</p>
<p>NLP不像video games直接可以用游戏画面作为输入，用多层CNN提取feature进行action选择，因为text不仅仅是一个序列，而且是变长度的，所以一般来说也都是RNN来处理。本文模型如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig1.png" width="600" height="500">
<p>首先，回答关心的第二个问题，DQN中各元素的对应关系（transition tuple）。</p>
<p>DQN中：(s(t),a(t),r(t),s(t+1))<br>本文：([EnSen(t),DeSen(t)],y(t),r(t),[EnSen(t),DeSen(t+1)])</p>
<p>整个模型是一个迭代decoding的过程，通过LSTM decoder生成最初的DeSen(t)之后，开始不断地迭代。在decoder的每一个time step，DQN会从DeLSTM使用的词表中选择一个可以获得最大reward的action作为该time step新生成的词，用这个新词来代替之前的旧词，生成新的状态DeSen(t+1)，依次迭代下去，每一次迭代都只生成一个新词来代替旧词，直到最后一个新词被生成。这里的reward r(t)是计算target sentence和DeSen(t+1)的相似度得来的。</p>
<p>本文在这个模型的基础上，尝试了在decoder部分用双向的LSTM来表示，并且用一个光滑的BLEU来做reward。这一点与<a href="http://rsarxiv.github.io/2016/05/17/%E8%87%AA%E5%8A%A8%E6%96%87%E6%91%98%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89/">Neural Headline Generation with Minimum Risk Training</a>这篇文章从某一个角度来说有一点点类似，本文是用最终的评价指标BLEU作为reward，而那篇文章是用ROUGE指标作为优化函数，最终取得了非常令人满意的结果。</p>
<p>整个算法流程大体上都是遵循DQN的框架，只是细节有一些不同，如下图：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig2.png" width="600" height="600">
<p>实验部分，用了10000个sentences作为训练集，source和target是一样的，是一个autoencoder问题，对比了只用LSTM decoder和本文模型的结果，如下表：</p>
<img src="/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/fig3.png" width="300" height="300">
<p>验证了本文方法的有效性。</p>
<p>本文较前一篇文字游戏的文章更难的一点是处理大量actions的方法，上一篇其实仍旧是个游戏，actions的数量在一个非常有限的范围内，本篇是做语言模型的，actions和词汇表一样大，这是DQN在NLP中应用最头疼的问题。本文用了DeLSTM在每个time step中使用的Top N个词作为候选actions，很好地解决了这个问题，那么到底有没有更好的方法来减少actions呢？有没有不需要用这么复杂的模型来做处理呢？想到一个idea，用char-level来做语言模型，用到的vocabulary size远远小于word-level，对于DQN来说，actions集合非常固定，并且非常小，只是增大了state的表示。</p>
<p>如果大家觉得有写的不够清楚的地方或者错误的地方，欢迎留言交流。</p>
<h1 id="工具推荐"><a href="#工具推荐" class="headerlink" title="工具推荐"></a>工具推荐</h1><p>PaperWeekly，每周会分享N篇nlp领域好玩的paper，旨在用最少的话说明白paper的贡献，欢迎大家扫码关注。</p>
<img src="/2016/05/13/Paper翻译列表/qrcode.jpg" width="650" height="650">
<p>知乎专栏<a href="https://zhuanlan.zhihu.com/paperweekly" target="_blank" rel="external">paperweekly</a></p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/nlp/">nlp</a>, <a href="/tags/PaperWeekly/">PaperWeekly</a>, <a href="/tags/DQN/">DQN</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">留言</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://rsarxiv.github.io/2016/06/28/Generating-Text-with-Deep-Reinforcement-Learning-PaperWeekly/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>110</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>128</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/创业/">创业</a><small>1</small></li>
  
    <li><a href="/tags/招聘/">招聘</a><small>1</small></li>
  
    <li><a href="/tags/推荐系统/">推荐系统</a><small>2</small></li>
  
    <li><a href="/tags/综述/">综述</a><small>1</small></li>
  
    <li><a href="/tags/自动文摘/">自动文摘</a><small>16</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>