<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>cs.CL weekly 2016.10.31-2016.11.04 | PaperWeekly</title>
  
  
  <meta name="description" content="一周值得读Neural Machine Translation in Linear Time【机器翻译】本文提出了一种新的encoder-decoder模型ByteNet。它是由两个扩张（dilated）卷积神经网络堆叠起来的。ByteNet的优势在于时间复杂度是线性的。工作来自deepmind。建">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="cs.CL weekly 2016.10.31-2016.11.04"/>
  <meta property="og:site_name" content="PaperWeekly"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="PaperWeekly" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77933764-1', 'auto');
	ga('send', 'pageview');

</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">PaperWeekly</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/atom.xml">Rss</a></li>
    
      <li><a href="/about/index.html">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-11-05T01:40:05.000Z"><a href="/2016/11/05/cs-CL-weekly-2016-10-31-2016-11-04/">2016-11-05</a></time>
      
      
  
    <h1 class="title">cs.CL weekly 2016.10.31-2016.11.04</h1>
  

    </header>
    <div class="entry">
      
        <h1 id="一周值得读"><a href="#一周值得读" class="headerlink" title="一周值得读"></a>一周值得读</h1><h2 id="Neural-Machine-Translation-in-Linear-Time"><a href="#Neural-Machine-Translation-in-Linear-Time" class="headerlink" title="Neural Machine Translation in Linear Time"></a><a href="https://arxiv.org/pdf/1610.10099v1.pdf" target="_blank" rel="external">Neural Machine Translation in Linear Time</a></h2><p>【机器翻译】本文提出了一种新的encoder-decoder模型ByteNet。它是由两个扩张（dilated）卷积神经网络堆叠起来的。ByteNet的优势在于时间复杂度是线性的。工作来自deepmind。建议研究机器翻译以及使用MT模型做其他任务的童鞋精读。</p>
<h2 id="Dual-Learning-for-Machine-Translation"><a href="#Dual-Learning-for-Machine-Translation" class="headerlink" title="Dual Learning for Machine Translation"></a><a href="https://arxiv.org/pdf/1611.00179v1.pdf" target="_blank" rel="external">Dual Learning for Machine Translation</a></h2><p>【机器翻译】【增强学习】本文解决的问题是机器翻译中双语训练语料需求过多的问题，旨在通过一种手段来减少数据标注工作。作者采用的方法是现在重新流行的增强学习方法，翻译通常是一个对偶过程，比如：英翻法和法翻英。整个学习过程可以简单的描述如下：对偶的两个翻译任务可以当做是两个agent A和B，通过少量的双语标注数据可以学习出一个初级的翻译模型，同时通过大量的单语数据（无需标注）来学习出相应的语言模型；A将单语数据翻译成B，B通过自身的语言模型对A的翻译结果进行误差反馈，A进行学习；同理，B也可以向A学习，直到收敛。整个学习过程中，训练了A-&gt;B和B-&gt;A两个翻译模型，但是用到的双语标注数据就会比较少。</p>
<h2 id="End-to-End-Reading-Comprehension-with-Dynamic-Answer-Chunk-Ranking"><a href="#End-to-End-Reading-Comprehension-with-Dynamic-Answer-Chunk-Ranking" class="headerlink" title="End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking"></a><a href="https://arxiv.org/pdf/1610.09996v2.pdf" target="_blank" rel="external">End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking</a></h2><p>【机器阅读】本文研究的问题是最近一年非常流行的机器阅读理解问题，给定一段文本和一个问题，输出一个答案（选择、生成）。本文提出了一种新的模型，相比之前模型来说，改进的地方是可以给出变长度的答案。在之前模型的基础上，添加了一个entity表示模块，并且对候选的entity进行排序，得到正确答案。本文在SQuAD上进行了测试，拿到了最好的结果。建议研究QA和机器阅读的童鞋来精读这篇文章，并且开始新一轮SQuAD刷榜。</p>
<h2 id="Knowledge-Questions-from-Knowledge-Graphs"><a href="#Knowledge-Questions-from-Knowledge-Graphs" class="headerlink" title="Knowledge Questions from Knowledge Graphs"></a><a href="https://arxiv.org/pdf/1610.09935v2.pdf" target="_blank" rel="external">Knowledge Questions from Knowledge Graphs</a></h2><p>【问题生成】【知识图谱】本文研究的内容是从知识图谱中自动生成一些具有一定难度且答案唯一的问题，用于教育或评估。问题的第一个难点在于如何确保从图谱中选择的答案具有唯一性，第二个难点是如何评价所生成问题的难度。这个任务非常有趣，也是知识图谱在实际中的一个应用场景。任务本身比文章的模型和方法更值得思考。还是说回chatbot，QA chatbot，都说缺少数据，已构建好的知识图谱本身就是一个很大的数据源，如何利用它，如何将其更好地用于生成有用的训练数据，本文的任务也许会带来一些启发。这个任务也不算首创，之前KBQA的工作都有通过知识库出发来生成问题，且通过平行语料扩展，包括Percy liang等不少大牛的工作都考虑了这点，这里相当于延续，量化了难度确保了答案唯一性等</p>
<h2 id="LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Networks"><a href="#LightRNN-Memory-and-Computation-Efficient-Recurrent-Neural-Networks" class="headerlink" title="LightRNN: Memory and Computation-Efficient Recurrent Neural Networks"></a><a href="https://arxiv.org/pdf/1610.09893v1.pdf" target="_blank" rel="external">LightRNN: Memory and Computation-Efficient Recurrent Neural Networks</a></h2><p>【新RNN】本文提出了一种新的思路来提高RNN的效果，包括时间和空间上的。最核心的点在于构建了一种全新的word embedding表示方式，传统的方法是词表中的每个词都用一个向量表示。将每个词都放入到一张二维表中，表中的每个词都有其所在的行向量和列向量共同表示，如图1所示。从而将词表示的规模从|V|个向量降到了2*sqrt(V)。本文还针对这种表示方法，构建了一种新的RNN模型LightRNN，并在大型数据集上进行了语言模型任务的评测，验证了本文方法在时间和空间上的性能提升。 </p>
<h2 id="Chinese-Poetry-Generation-with-Planning-based-Neural-Network"><a href="#Chinese-Poetry-Generation-with-Planning-based-Neural-Network" class="headerlink" title="Chinese Poetry Generation with Planning based Neural Network"></a><a href="https://arxiv.org/pdf/1610.09889v1.pdf" target="_blank" rel="external">Chinese Poetry Generation with Planning based Neural Network</a></h2><p>【诗词生成】本文研究的任务非常有趣，通过神经网络模型来生成唐诗，类似地可以开展宋词等任务。端到端地训练、学习具有很强的应用性，只要能够给定输入序列和输出序列，打开脑洞，做任何好玩的任务都有可能。</p>
<h2 id="MusicMood-Predicting-the-mood-of-music-from-song-lyrics-using-machine-learning"><a href="#MusicMood-Predicting-the-mood-of-music-from-song-lyrics-using-machine-learning" class="headerlink" title="MusicMood: Predicting the mood of music from song lyrics using machine learning"></a><a href="https://arxiv.org/pdf/1611.00138v1.pdf" target="_blank" rel="external">MusicMood: Predicting the mood of music from song lyrics using machine learning</a></h2><p>【音乐推荐系统】本文研究内容为通过机器学习方法从歌词中来预测音乐的情绪，算是自然语言处理在音乐中的应用。这种简单的应用，可以为音乐推荐系统提供一些特征，现有的音乐推荐系统可以做参考。</p>
<h2 id="Detecting-Context-Dependent-Messages-in-a-Conversational-Environment"><a href="#Detecting-Context-Dependent-Messages-in-a-Conversational-Environment" class="headerlink" title="Detecting Context Dependent Messages in a Conversational Environment"></a><a href="https://arxiv.org/pdf/1611.00483v2.pdf" target="_blank" rel="external">Detecting Context Dependent Messages in a Conversational Environment</a></h2><p>【chatbot】【上下文】chatbot的难点之一在于如何准确理解“人话”，“人话”有个显著的特点是简短而且非正式，常见的NLP分析方法，词性标注、句法分析等都不好用。理解“人话”需要结合上下文。那么，第一个问题来了，理解某句话应该取哪几句history作为上下文，第二个问题是如何理解上下文？本文旨在解决第一个问题，这个问题研究空间比较大，本文做了初步尝试。对chatbot感兴趣的童鞋，不管是学术界还是工业界的童鞋都可以读一下本文，或许会带来一些启发和思考。</p>
<h2 id="Natural-Parameter-Networks-A-Class-of-Probabilistic-Neural-Networks"><a href="#Natural-Parameter-Networks-A-Class-of-Probabilistic-Neural-Networks" class="headerlink" title="Natural-Parameter Networks: A Class of Probabilistic Neural Networks"></a><a href="https://arxiv.org/pdf/1611.00448v1.pdf" target="_blank" rel="external">Natural-Parameter Networks: A Class of Probabilistic Neural Networks</a></h2><p>【NIPS2016】本文提出了一类概率神经网络（贝叶斯），旨在解决现有神经网络在数据规模小的时候容易过拟合的问题。</p>
<h2 id="Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks"><a href="#Collaborative-Recurrent-Autoencoder-Recommend-while-Learning-to-Fill-in-the-Blanks" class="headerlink" title="Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks"></a><a href="https://arxiv.org/pdf/1611.00454v1.pdf" target="_blank" rel="external">Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in the Blanks</a></h2><p>【推荐系统】本文的亮点在于将RNN和协同过滤无缝结合起来。</p>
<h1 id="一周资源"><a href="#一周资源" class="headerlink" title="一周资源"></a>一周资源</h1><h2 id="聊天机器人资料汇总"><a href="#聊天机器人资料汇总" class="headerlink" title="聊天机器人资料汇总"></a><a href="https://www.52ml.net/20510.html" target="_blank" rel="external">聊天机器人资料汇总</a></h2><p>来自52ml汇总的聊天机器人资料</p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/nlp/">nlp</a>, <a href="/tags/PaperWeekly/">PaperWeekly</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">留言</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://rsarxiv.github.io/2016/11/05/cs-CL-weekly-2016-10-31-2016-11-04/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:rsarxiv.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Autoencoder/">Autoencoder</a><small>1</small></li>
  
    <li><a href="/tags/CNN/">CNN</a><small>2</small></li>
  
    <li><a href="/tags/DQN/">DQN</a><small>4</small></li>
  
    <li><a href="/tags/Memory-Network/">Memory Network</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>2</small></li>
  
    <li><a href="/tags/PaperWeekly/">PaperWeekly</a><small>110</small></li>
  
    <li><a href="/tags/RNN/">RNN</a><small>1</small></li>
  
    <li><a href="/tags/RNNLM/">RNNLM</a><small>1</small></li>
  
    <li><a href="/tags/ROUGE/">ROUGE</a><small>1</small></li>
  
    <li><a href="/tags/RSarXiv/">RSarXiv</a><small>1</small></li>
  
    <li><a href="/tags/Reading-Comprehension/">Reading Comprehension</a><small>6</small></li>
  
    <li><a href="/tags/Representation/">Representation</a><small>1</small></li>
  
    <li><a href="/tags/Text-Comprehension/">Text Comprehension</a><small>1</small></li>
  
    <li><a href="/tags/api-ai/">api.ai</a><small>1</small></li>
  
    <li><a href="/tags/arXiv/">arXiv</a><small>2</small></li>
  
    <li><a href="/tags/arxiv/">arxiv</a><small>2</small></li>
  
    <li><a href="/tags/attention/">attention</a><small>3</small></li>
  
    <li><a href="/tags/bot/">bot</a><small>21</small></li>
  
    <li><a href="/tags/chatbot/">chatbot</a><small>2</small></li>
  
    <li><a href="/tags/dataset/">dataset</a><small>1</small></li>
  
    <li><a href="/tags/deep-learning/">deep learning</a><small>1</small></li>
  
    <li><a href="/tags/deeplearning/">deeplearning</a><small>1</small></li>
  
    <li><a href="/tags/language-model/">language model</a><small>1</small></li>
  
    <li><a href="/tags/nlp/">nlp</a><small>128</small></li>
  
    <li><a href="/tags/open-source/">open source</a><small>1</small></li>
  
    <li><a href="/tags/paper/">paper</a><small>7</small></li>
  
    <li><a href="/tags/paperweekly/">paperweekly</a><small>2</small></li>
  
    <li><a href="/tags/reading-comprehension/">reading comprehension</a><small>1</small></li>
  
    <li><a href="/tags/reinforcement-learning/">reinforcement learning</a><small>1</small></li>
  
    <li><a href="/tags/sentence-representations/">sentence representations</a><small>1</small></li>
  
    <li><a href="/tags/seq2seq/">seq2seq</a><small>17</small></li>
  
    <li><a href="/tags/text-comprehension/">text comprehension</a><small>1</small></li>
  
    <li><a href="/tags/torch/">torch</a><small>1</small></li>
  
    <li><a href="/tags/word-embedding/">word embedding</a><small>2</small></li>
  
    <li><a href="/tags/word-embeddings/">word embeddings</a><small>1</small></li>
  
    <li><a href="/tags/word2vec/">word2vec</a><small>1</small></li>
  
    <li><a href="/tags/创业/">创业</a><small>1</small></li>
  
    <li><a href="/tags/招聘/">招聘</a><small>1</small></li>
  
    <li><a href="/tags/推荐系统/">推荐系统</a><small>2</small></li>
  
    <li><a href="/tags/综述/">综述</a><small>1</small></li>
  
    <li><a href="/tags/自动文摘/">自动文摘</a><small>16</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>4</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- rsarxiv -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7417238904018690"
     data-ad-slot="4681057960"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2017 PaperWeekly
  
</div>
<div class="clearfix"></div>
<!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_xiaoyou"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END --></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>